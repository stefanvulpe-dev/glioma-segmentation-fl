{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM4J2YDWDx4r"
      },
      "source": [
        "**<h1>Enhancing Brain Disease Diagnosis<h1>**\n",
        "\n",
        "**<h2>Federated Learning for Multi-Center Medical Imaging<h2>**\n",
        "\n",
        "**<h3>AI for Trustworthy Decision Making<h3>**\n",
        "\n",
        "- Poață Andrei-Cătălin\n",
        "\n",
        "- Vulpe Ștefan\n",
        "\n",
        "- Vișan Ionuț\n",
        "\n",
        "*github: https://github.com/stefanvulpe-dev/brain-disease-diagnosis*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj5tPAuEKUbY"
      },
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdQ3QSV1oqyq",
        "outputId": "f1471f73-c6ae-4fca-b089-3b795a3658c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/AITDM_Stuff/Preprocessed-Data.zip /content/Preprocessed-Data.zip\n",
        "!cp /content/drive/MyDrive/AITDM_Stuff/client.zip /content/client.zip\n",
        "!cp /content/drive/MyDrive/AITDM_Stuff/cleaned_df.pkl /content/cleaned_df.pkl\n",
        "!cp /content/drive/MyDrive/AITDM_Stuff/labels_list.pkl /content/labels_list.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXlb41oIJqYa",
        "outputId": "1f96f441-f7a8-4e31-8687-c29e924a2b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (11.3.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (0.7.0)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (1.0.24)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8->segmentation_models_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8->segmentation_models_pytorch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2026.1.4)\n",
            "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: segmentation_models_pytorch\n",
            "Successfully installed segmentation_models_pytorch-0.5.0\n",
            "Collecting torchio\n",
            "  Downloading torchio-0.21.1-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated>=1.2 (from torchio)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.12/dist-packages (from torchio) (0.8.1)\n",
            "Requirement already satisfied: humanize>=0.1 in /usr/local/lib/python3.12/dist-packages (from torchio) (4.15.0)\n",
            "Requirement already satisfied: nibabel>=3 in /usr/local/lib/python3.12/dist-packages (from torchio) (5.3.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from torchio) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from torchio) (25.0)\n",
            "Requirement already satisfied: rich>=10 in /usr/local/lib/python3.12/dist-packages (from torchio) (13.9.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.12/dist-packages (from torchio) (1.16.3)\n",
            "Collecting simpleitk!=2.0.*,!=2.1.1.1,>=1.3 (from torchio)\n",
            "  Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.12/dist-packages (from torchio) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.40 in /usr/local/lib/python3.12/dist-packages (from torchio) (4.67.1)\n",
            "Requirement already satisfied: typer>=0.1 in /usr/local/lib/python3.12/dist-packages (from torchio) (0.21.1)\n",
            "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated>=1.2->torchio) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from nibabel>=3->torchio) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10->torchio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10->torchio) (2.19.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (3.20.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->torchio) (3.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.1->torchio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.1->torchio) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10->torchio) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9->torchio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9->torchio) (3.0.3)\n",
            "Downloading torchio-0.21.1-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: simpleitk, deprecated, torchio\n",
            "Successfully installed deprecated-1.3.1 simpleitk-2.5.3 torchio-0.21.1\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation_models_pytorch\n",
        "!pip install torchio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYFrmuebJtzx"
      },
      "outputs": [],
      "source": [
        "!unzip -qo /content/client.zip -d /content/client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a1acYv0Ju3C"
      },
      "outputs": [],
      "source": [
        "!unzip -qo /content/Preprocessed-Data.zip -d /content/Preprocessed-Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_K1UZo4RoWi",
        "outputId": "c73dd80f-3cf2-4edc-a45e-4b0820140382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.4 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.4 which is incompatible.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q \"flwr[simulation]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nw80ekO7R0i"
      },
      "source": [
        "# **Main Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "FfrU4Wyh7bv6",
        "outputId": "5da861ad-2923-46b3-cca3-c40882ce5c5d"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2572841789.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "class GliomaDataset(Dataset):\n",
        "    def __init__(self, metadata_df_path, labels_path, transform=None):\n",
        "        with open(metadata_df_path, 'rb') as f:\n",
        "            self.metadata_df = pickle.load(f)\n",
        "\n",
        "        self.metadata_df = self.metadata_df[self.metadata_df['Patient_ID'] != 'PatientID_0191']\n",
        "        with open(labels_path, 'rb') as f:\n",
        "            self.labels = pickle.load(f)\n",
        "\n",
        "        self.data_root = \"/content/drive/MyDrive/PKG - MU-Glioma-Post/Preprocessed-Data\"\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "        self.useful_columns = [\n",
        "            'Patient_ID', 'Sex at Birth', 'Race', 'Age at diagnosis',\n",
        "            'Primary Diagnosis', 'H3-3A mutation', 'PTEN mutation',\n",
        "            'CDKN2A/B deletion', 'TP53 alteration', 'Other mutations/alterations',\n",
        "            'Previous Brain Tumor', 'Type of previous brain tumor',\n",
        "            'Report', 'Age Range', 'Top 5 Regions'\n",
        "        ]\n",
        "\n",
        "        self.categorical_cols = [\n",
        "            'Sex at Birth', 'Race', 'Primary Diagnosis',\n",
        "            'Previous Brain Tumor', 'Type of previous brain tumor', 'Age Range'\n",
        "        ]\n",
        "\n",
        "        self.code_maps = {}\n",
        "\n",
        "        for col in self.categorical_cols:\n",
        "            cat = pd.Categorical(self.metadata_df[col])\n",
        "            self.metadata_df[col + '_code'] = cat.codes\n",
        "            self.code_maps[col] = dict(enumerate(cat.categories))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.metadata_df.iloc[idx]\n",
        "\n",
        "        patient_id = row['Patient_ID']\n",
        "\n",
        "        sex = row['Sex at Birth_code']\n",
        "        race = row['Race_code']\n",
        "        primary_diagnosis = row['Primary Diagnosis_code']\n",
        "        previous_brain_tumor = row['Previous Brain Tumor_code']\n",
        "        type_of_previous_brain_tumor = row['Type of previous brain tumor_code']\n",
        "        age_range = row['Age Range_code']\n",
        "\n",
        "        age = row['Age at diagnosis']\n",
        "        h3_3a_mutation = row['H3-3A mutation']\n",
        "        pten_mutation = row['PTEN mutation']\n",
        "        CDKN2A_B_deletion = row['CDKN2A/B deletion']\n",
        "        TP53_alteration = row['TP53 alteration']\n",
        "        other_mutations_alterations = row['Other mutations/alterations']\n",
        "        report = row['Report']\n",
        "        top_5 = [self.labels.index(elem) for elem in row['Top 5 Regions']]\n",
        "\n",
        "        target_regions = np.zeros(len(self.labels))\n",
        "        for i in top_5:\n",
        "          target_regions[i] = 1\n",
        "\n",
        "        mri = np.load(self.data_root + f'/{patient_id}/{patient_id}_mri.npy')\n",
        "        regions = np.load(self.data_root + f'/{patient_id}/{patient_id}_regions.npy')\n",
        "        tumor = np.load(self.data_root + f'/{patient_id}/{patient_id}_tumor.npy')\n",
        "\n",
        "        if self.transform:\n",
        "            mri = self.transform(mri)\n",
        "            regions = self.transform(regions)\n",
        "            tumor = self.transform(tumor)\n",
        "\n",
        "        dict_output = {\n",
        "            'mri': mri,\n",
        "            'regions': regions,\n",
        "            'tumor': tumor,\n",
        "            'sex': sex,\n",
        "            'race': race,\n",
        "            'age': age,\n",
        "            'primary_diagnosis': primary_diagnosis,\n",
        "            'h3_3a_mutation': h3_3a_mutation,\n",
        "            'pten_mutation': pten_mutation,\n",
        "            'CDKN2A_B_deletion': CDKN2A_B_deletion,\n",
        "            'TP53_alteration': TP53_alteration,\n",
        "            'other_mutations_alterations': other_mutations_alterations,\n",
        "            'previous_brain_tumor': previous_brain_tumor,\n",
        "            'type_of_previous_brain_tumor': type_of_previous_brain_tumor,\n",
        "            'report': report,\n",
        "            'age_range': age_range,\n",
        "            'target_regions': target_regions,\n",
        "        }\n",
        "\n",
        "        return dict_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def glioma_collate_fn(batch):\n",
        "    mri_batch = torch.stack([torch.tensor(item['mri']) for item in batch])\n",
        "    regions_batch = torch.stack([torch.tensor(item['regions']) for item in batch])\n",
        "    tumor_batch = torch.stack([torch.tensor(item['tumor']) for item in batch])\n",
        "\n",
        "    sex_batch = torch.tensor([item['sex'] for item in batch], dtype=torch.long)\n",
        "    race_batch = torch.tensor([item['race'] for item in batch], dtype=torch.long)\n",
        "    age_batch = torch.tensor([item['age'] for item in batch], dtype=torch.float)\n",
        "    primary_diagnosis_batch = torch.tensor([item['primary_diagnosis'] for item in batch], dtype=torch.long)\n",
        "    h3_3a_mutation_batch = torch.tensor([item['h3_3a_mutation'] for item in batch], dtype=torch.float)\n",
        "    pten_mutation_batch = torch.tensor([item['pten_mutation'] for item in batch], dtype=torch.float)\n",
        "    CDKN2A_B_deletion_batch = torch.tensor([item['CDKN2A_B_deletion'] for item in batch], dtype=torch.float)\n",
        "    TP53_alteration_batch = torch.tensor([item['TP53_alteration'] for item in batch], dtype=torch.float)\n",
        "    previous_brain_tumor_batch = torch.tensor([item['previous_brain_tumor'] for item in batch], dtype=torch.long)\n",
        "    type_of_previous_brain_tumor_batch = torch.tensor([item['type_of_previous_brain_tumor'] for item in batch], dtype=torch.long)\n",
        "    age_range_batch = torch.tensor([item['age_range'] for item in batch], dtype=torch.long)\n",
        "    target_regions_batch = torch.from_numpy(np.array([item['target_regions'] for item in batch])).float()\n",
        "\n",
        "    other_mutations_batch = [item['other_mutations_alterations'] for item in batch]\n",
        "    report_batch = [item['report'] for item in batch]\n",
        "\n",
        "    return {\n",
        "        'mri': mri_batch,\n",
        "        'regions': regions_batch,\n",
        "        'tumor': tumor_batch,\n",
        "        'sex': sex_batch,\n",
        "        'race': race_batch,\n",
        "        'age': age_batch,\n",
        "        'primary_diagnosis': primary_diagnosis_batch,\n",
        "        'h3_3a_mutation': h3_3a_mutation_batch,\n",
        "        'pten_mutation': pten_mutation_batch,\n",
        "        'CDKN2A_B_deletion': CDKN2A_B_deletion_batch,\n",
        "        'TP53_alteration': TP53_alteration_batch,\n",
        "        'other_mutations_alterations': other_mutations_batch,\n",
        "        'previous_brain_tumor': previous_brain_tumor_batch,\n",
        "        'type_of_previous_brain_tumor': type_of_previous_brain_tumor_batch,\n",
        "        'report': report_batch,\n",
        "        'age_range': age_range_batch,\n",
        "        'target_regions': target_regions_batch,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpymGCI37dOS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "dataset = GliomaDataset(\"/content/drive/MyDrive/PKG - MU-Glioma-Post/cleaned_df.pkl\", \"/content/drive/MyDrive/PKG - MU-Glioma-Post/labels_list.pkl\")\n",
        "\n",
        "test_size = int(0.2 * len(dataset))\n",
        "train_size = len(dataset) - test_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=glioma_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=glioma_collate_fn)\n",
        "\n",
        "print(f\"Train loader length = {len(train_loader)}\")\n",
        "print(f\"Test loader length = {len(test_loader)}\")\n",
        "\n",
        "for batch in train_loader:\n",
        "    print(\"Train batch:\", batch)\n",
        "    break\n",
        "\n",
        "for batch in test_loader:\n",
        "    print(\"Test batch:\", batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTXIvQSS7esg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "class BioBERTMultiLabelClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        x = self.dropout(pooled_output)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Tokenizer (Bio_ClinicalBERT e foarte bun)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Functie de procesare rapoarte\n",
        "def tokenize_reports(reports, tokenizer, max_len=512):\n",
        "    return tokenizer(\n",
        "        reports,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def plot_and_save_history(history, save_dir=\"/content/drive/MyDrive/PKG - MU-Glioma-Post/Graphs\"):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    epochs = len(history['train_loss'])\n",
        "    epochs_range = range(1, epochs + 1)\n",
        "\n",
        "    # Loss\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, history['train_loss'], label='Train Loss')\n",
        "    plt.plot(epochs_range, history['test_loss'], label='Test Loss')\n",
        "    plt.title(\"Bioclinical BERT Loss Evolution\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(save_dir, \"loss_evolution_biobert.png\"))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # F1 Score\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, history['train_f1'], label='Train F1')\n",
        "    plt.plot(epochs_range, history['test_f1'], label='Test F1')\n",
        "    plt.title(\"Bioclinical BERT F1 Evolution\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"F1 Score\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(save_dir, \"f1_evolution_biobert.png\"))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # Accuracy (doar dacă există în history)\n",
        "    if 'train_acc' in history and 'test_acc' in history:\n",
        "        plt.figure()\n",
        "        plt.plot(epochs_range, history['train_acc'], label='Train Accuracy')\n",
        "        plt.plot(epochs_range, history['test_acc'], label='Test Accuracy')\n",
        "        plt.title(\"Bioclinical BERT Accuracy Evolution\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.legend()\n",
        "        plt.savefig(os.path.join(save_dir, \"accuracy_evolution_biobert.png\"))\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "    else:\n",
        "        print(\"Accuracy metrics not found in history, skipping accuracy plot.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDUlKum57f74"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "\n",
        "\n",
        "warnings.simplefilter(\"ignore\", category=UndefinedMetricWarning)\n",
        "\n",
        "def train_eval_biobert(model, train_loader, test_loader, label_names=None, epochs=5, lr=2e-5, save_path=\"best_model.pt\"):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    warmup_steps = int(0.1 * total_steps)  # 10% pași warmup\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
        "\n",
        "    model.to(device)\n",
        "    best_f1 = 0\n",
        "    history = {\n",
        "        'train_loss': [], 'train_f1': [], 'train_acc': [],\n",
        "        'test_loss': [], 'test_f1': [], 'test_acc': [],\n",
        "        'test_f1_per_class': [], 'test_auc_per_class': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        y_true_train = []\n",
        "        y_pred_train = []\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n",
        "            reports = batch['report']\n",
        "            labels = batch['target_regions'].to(device)\n",
        "\n",
        "            encodings = tokenize_reports(reports, tokenizer)\n",
        "            input_ids = encodings['input_ids'].to(device)\n",
        "            attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).int().cpu()\n",
        "            y_true_train.append(labels.cpu())\n",
        "            y_pred_train.append(preds)\n",
        "\n",
        "        y_true_train = torch.cat(y_true_train).numpy()\n",
        "        y_pred_train = torch.cat(y_pred_train).numpy()\n",
        "\n",
        "        f1_train = f1_score(y_true_train, y_pred_train, average='macro')\n",
        "        acc_train = (y_true_train == y_pred_train).mean()  # calcul acuratețe pe toate clasele și exemplele\n",
        "\n",
        "        history['train_loss'].append(train_loss / len(train_loader))\n",
        "        history['train_f1'].append(f1_train)\n",
        "        history['train_acc'].append(acc_train)\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        y_true_test = []\n",
        "        y_pred_test = []\n",
        "        y_proba_test = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(test_loader, desc=\"Test\"):\n",
        "                reports = batch['report']\n",
        "                labels = batch['target_regions'].to(device)\n",
        "\n",
        "                encodings = tokenize_reports(reports, tokenizer)\n",
        "                input_ids = encodings['input_ids'].to(device)\n",
        "                attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                probs = torch.sigmoid(outputs).cpu()\n",
        "                preds = (probs > 0.5).int()\n",
        "\n",
        "                y_true_test.append(labels.cpu())\n",
        "                y_pred_test.append(preds)\n",
        "                y_proba_test.append(probs)\n",
        "\n",
        "        y_true_test = torch.cat(y_true_test).numpy()\n",
        "        y_pred_test = torch.cat(y_pred_test).numpy()\n",
        "        y_proba_test = torch.cat(y_proba_test).numpy()\n",
        "\n",
        "        f1_test = f1_score(y_true_test, y_pred_test, average='macro')\n",
        "        acc_test = (y_true_test == y_pred_test).mean()\n",
        "\n",
        "        f1_per_class = f1_score(y_true_test, y_pred_test, average=None).tolist()\n",
        "\n",
        "        try:\n",
        "            auc_per_class = roc_auc_score(y_true_test, y_proba_test, average=None).tolist()\n",
        "        except ValueError:\n",
        "            auc_per_class = [float('nan')] * y_true_test.shape[1]\n",
        "\n",
        "        history['test_loss'].append(test_loss / len(test_loader))\n",
        "        history['test_f1'].append(f1_test)\n",
        "        history['test_acc'].append(acc_test)\n",
        "        history['test_f1_per_class'].append(f1_per_class)\n",
        "        history['test_auc_per_class'].append(auc_per_class)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}:\")\n",
        "        print(f\"Train Loss: {history['train_loss'][-1]:.4f}\")\n",
        "        print(f\"Test Loss:  {history['test_loss'][-1]:.4f}\")\n",
        "        print(f\"Train F1 (macro): {f1_train:.4f}\")\n",
        "        print(f\"Train Accuracy:   {acc_train:.4f}\")\n",
        "        print(f\"Test F1 (macro):  {f1_test:.4f}\")\n",
        "        print(f\"Test Accuracy:    {acc_test:.4f}\")\n",
        "        print(\"F1 per class:\")\n",
        "        if label_names:\n",
        "            for i, name in enumerate(label_names):\n",
        "                print(f\"  {name}: {f1_per_class[i]:.4f} | AUC: {auc_per_class[i]:.4f}\")\n",
        "        else:\n",
        "            for i, f1c in enumerate(f1_per_class):\n",
        "                print(f\"  Class {i}: F1={f1c:.4f}, AUC={auc_per_class[i]:.4f}\")\n",
        "\n",
        "        if f1_test > best_f1:\n",
        "            best_f1 = f1_test\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"✅ Saved new best model with F1={f1_test:.4f} to {save_path}\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = BioBERTMultiLabelClassifier(\"emilyalsentzer/Bio_ClinicalBERT\", num_labels=len(dataset.labels))\n",
        "\n",
        "label_names = dataset.labels  # de ex: ['frontal', 'temporal', 'parietal', ...]\n",
        "history = train_eval_biobert(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    label_names=label_names,\n",
        "    epochs=20,\n",
        "    save_path=\"/content/drive/MyDrive/PKG - MU-Glioma-Post/Models/BioClinicalBert/best.pt\"\n",
        ")\n",
        "\n",
        "plot_and_save_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPsYFRhn7g6B"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "import torch.nn as nn\n",
        "\n",
        "class UNetTumorSegmentation(nn.Module):\n",
        "    def __init__(self, encoder_name='resnet34', pretrained=True):\n",
        "        super().__init__()\n",
        "        self.model = smp.Unet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights='imagenet' if pretrained else None,\n",
        "            in_channels=2,  # mri + regions\n",
        "            classes=1,\n",
        "            activation=None  # BCEWithLogitsLoss expects raw logits\n",
        "        )\n",
        "\n",
        "    def forward(self, mri, regions):\n",
        "        x = torch.cat([mri, regions], dim=1)  # concatenate along channel dim\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tqJ6r1X7hoR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import segmentation_models_pytorch as smp\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import jaccard_score\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model U-Net cu 2 input channels (MRI + Regions), 1 output channel\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=2,\n",
        "    classes=1,\n",
        ").to(device)\n",
        "\n",
        "# Loss + optimizer + scheduler\n",
        "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.0, total_iters=50)\n",
        "\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    \"\"\" Calculează Dice, IoU, Accuracy pe tensori numpy binarizați \"\"\"\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    dice = 2 * (y_true * y_pred).sum() / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "    iou = jaccard_score(y_true, y_pred, average='binary')\n",
        "    acc = (y_true == y_pred).mean()\n",
        "    return dice, iou, acc\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss, total_dice, total_iou, total_acc = 0, 0, 0, 0\n",
        "    for batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Input: concatenăm MRI și Regions pe canal\n",
        "        x1 = batch['mri'].float().unsqueeze(1).to(device)  # [B,1,H,W]\n",
        "        x2 = batch['regions'].float().unsqueeze(1).to(device)  # [B,1,H,W]\n",
        "        x = torch.cat([x1, x2], dim=1)  # [B,2,H,W]\n",
        "\n",
        "        y = batch['tumor'].float().unsqueeze(1).to(device)  # [B,1,H,W]\n",
        "\n",
        "        preds = model(x)\n",
        "\n",
        "        loss = criterion(preds, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # preds: logits -> sigmoid -> binarizare prag 0.5\n",
        "        preds_prob = torch.sigmoid(preds).detach().cpu().numpy() > 0.5\n",
        "        y_np = y.detach().cpu().numpy() > 0.5\n",
        "\n",
        "        dice, iou, acc = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += dice\n",
        "        total_iou += iou\n",
        "        total_acc += acc\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n\n",
        "\n",
        "def eval_one_epoch(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_dice, total_iou, total_acc = 0, 0, 0, 0\n",
        "    last_batch_imgs = None  # pentru a salva imagini de afișat\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            x1 = batch['mri'].float().unsqueeze(1).to(device)\n",
        "            x2 = batch['regions'].float().unsqueeze(1).to(device)\n",
        "            x = torch.cat([x1, x2], dim=1)\n",
        "\n",
        "            y = batch['tumor'].float().unsqueeze(1).to(device)\n",
        "\n",
        "            preds = model(x)\n",
        "            loss = criterion(preds, y)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds_prob = torch.sigmoid(preds).cpu().numpy() > 0.5\n",
        "            y_np = y.cpu().numpy() > 0.5\n",
        "\n",
        "            dice, iou, acc = calc_metrics(y_np, preds_prob)\n",
        "            total_dice += dice\n",
        "            total_iou += iou\n",
        "            total_acc += acc\n",
        "\n",
        "            # Salvăm batch-ul curent pentru afișare (ultimul batch)\n",
        "            last_batch_imgs = {\n",
        "                'mri': x1.cpu().numpy(),\n",
        "                'regions': x2.cpu().numpy(),\n",
        "                'y_true': y.cpu().numpy(),\n",
        "                'y_pred': preds_prob\n",
        "            }\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n, last_batch_imgs\n",
        "\n",
        "def plot_prediction(imgs):\n",
        "    # imgs conține: mri, regions, y_true, y_pred; toate în format numpy\n",
        "    mri = imgs['mri'][0,0]        # [B,1,H,W], selectăm prima imagine și canalul 0\n",
        "    regions = imgs['regions'][0,0]\n",
        "    y_true = imgs['y_true'][0,0]\n",
        "    y_pred = imgs['y_pred'][0,0]\n",
        "\n",
        "    fig, axs = plt.subplots(1,4, figsize=(20,5))\n",
        "    axs[0].imshow(mri, cmap='gray')\n",
        "    axs[0].set_title(\"MRI\")\n",
        "    axs[1].imshow(regions, cmap='gray')\n",
        "    axs[1].set_title(\"Regions\")\n",
        "    axs[2].imshow(y_true, cmap='gray')\n",
        "    axs[2].set_title(\"Ground Truth Mask\")\n",
        "    axs[3].imshow(y_pred, cmap='gray')\n",
        "    axs[3].set_title(\"Predicted Mask\")\n",
        "    for ax in axs:\n",
        "        ax.axis('off')\n",
        "    plt.savefig(\"/content/drive/MyDrive/PKG - MU-Glioma-Post/Graphs/sample_prediction_UNet.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics(train_metrics, val_metrics, save_path):\n",
        "    epochs = range(1, len(train_metrics['loss']) + 1)\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    plt.subplot(2,2,1)\n",
        "    plt.plot(epochs, train_metrics['loss'], label='Train Loss')\n",
        "    plt.plot(epochs, val_metrics['loss'], label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss')\n",
        "\n",
        "    plt.subplot(2,2,2)\n",
        "    plt.plot(epochs, train_metrics['dice'], label='Train Dice')\n",
        "    plt.plot(epochs, val_metrics['dice'], label='Val Dice')\n",
        "    plt.legend()\n",
        "    plt.title('Dice Score')\n",
        "\n",
        "    plt.subplot(2,2,3)\n",
        "    plt.plot(epochs, train_metrics['iou'], label='Train IoU')\n",
        "    plt.plot(epochs, val_metrics['iou'], label='Val IoU')\n",
        "    plt.legend()\n",
        "    plt.title('IoU')\n",
        "\n",
        "    plt.subplot(2,2,4)\n",
        "    plt.plot(epochs, train_metrics['acc'], label='Train Accuracy')\n",
        "    plt.plot(epochs, val_metrics['acc'], label='Val Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "\n",
        "num_epochs = 50\n",
        "best_val_iou = 0\n",
        "train_metrics = {'loss': [], 'dice': [], 'iou': [], 'acc': []}\n",
        "val_metrics = {'loss': [], 'dice': [], 'iou': [], 'acc': []}\n",
        "last_val_batch_imgs = None  # aici salvăm imaginile pentru ultima evaluare\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss, train_dice, train_iou, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_dice, val_iou, val_acc, val_imgs = eval_one_epoch(model, test_loader, criterion)\n",
        "    scheduler.step()\n",
        "\n",
        "    train_metrics['loss'].append(train_loss)\n",
        "    train_metrics['dice'].append(train_dice)\n",
        "    train_metrics['iou'].append(train_iou)\n",
        "    train_metrics['acc'].append(train_acc)\n",
        "\n",
        "    val_metrics['loss'].append(val_loss)\n",
        "    val_metrics['dice'].append(val_dice)\n",
        "    val_metrics['iou'].append(val_iou)\n",
        "    val_metrics['acc'].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "    print(f\" Train   - Loss: {train_loss:.4f}, Dice: {train_dice:.4f}, IoU: {train_iou:.4f}, Acc: {train_acc:.4f}\")\n",
        "    print(f\" Valid   - Loss: {val_loss:.4f}, Dice: {val_dice:.4f}, IoU: {val_iou:.4f}, Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_iou > best_val_iou:\n",
        "        best_val_iou = val_iou\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/PKG - MU-Glioma-Post/Models/UNet/best_unet_model.pth\")\n",
        "        print(\"  Saved best model!\")\n",
        "\n",
        "    # Salvăm imaginile din ultimul batch de validare la ultima epocă\n",
        "    if epoch >= num_epochs - 5:\n",
        "        last_val_batch_imgs = val_imgs\n",
        "        plot_prediction(last_val_batch_imgs)\n",
        "\n",
        "# Afișăm predicția vs adevărul pentru ultimul batch\n",
        "if last_val_batch_imgs is not None:\n",
        "    plot_prediction(last_val_batch_imgs)\n",
        "\n",
        "# Salvează graficele metricilor\n",
        "plot_metrics(train_metrics, val_metrics, \"/content/drive/MyDrive/PKG - MU-Glioma-Post/Graphs/training_metrics_UNet.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVma_pO-7i_I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import segmentation_models_pytorch as smp\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import jaccard_score\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "bert_model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "bert_num_labels = len(dataset.labels)\n",
        "bert_model = BioBERTMultiLabelClassifier(bert_model_name, bert_num_labels)\n",
        "bert_state_dict = torch.load(\"/content/drive/MyDrive/PKG - MU-Glioma-Post/Models/BioClinicalBert/best.pt\")\n",
        "bert_model.load_state_dict(bert_state_dict)\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "unet_model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",\n",
        "    encoder_weights=None,\n",
        "    in_channels=2,\n",
        "    classes=1,\n",
        ")\n",
        "unet_state_dict = torch.load(\"/content/drive/MyDrive/PKG - MU-Glioma-Post/Models/UNet/best_unet_model.pth\")\n",
        "unet_model.load_state_dict(unet_state_dict)\n",
        "\n",
        "train_loader_v2 = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=glioma_collate_fn)\n",
        "\n",
        "class ClipModel(nn.Module):\n",
        "    def __init__(self, bert_model, bert_tokenizer, unet_model, embed_dim=512):\n",
        "        super().__init__()\n",
        "        self.bert_model = bert_model\n",
        "        self.unet_model = unet_model\n",
        "        self.bert_tokenizer = bert_tokenizer\n",
        "        self.text_projection = nn.Linear(768, embed_dim)\n",
        "        self.image_projection = nn.Linear(512, embed_dim)\n",
        "\n",
        "        self.log_sigma_clip = nn.Parameter(torch.tensor(0.0))\n",
        "        self.log_sigma_seg = nn.Parameter(torch.tensor(0.0))\n",
        "\n",
        "    def forward(self, text, mri, regions):\n",
        "        encodings = tokenize_reports(text, self.bert_tokenizer)\n",
        "        input_ids = encodings['input_ids'].to(device)\n",
        "        attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "        # Get Text embeddings\n",
        "        outputs = self.bert_model.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        text_embeddings = self.text_projection(pooled_output)\n",
        "        text_embeddings = text_embeddings / text_embeddings.norm(dim=-1, keepdim=True)\n",
        "        # print(f\"Text embeddings size: {text_embeddings.shape}\")\n",
        "\n",
        "        # Get Image embeddings\n",
        "        x1 = mri.float().unsqueeze(1).to(device)\n",
        "        x2 = regions.float().unsqueeze(1).to(device)\n",
        "        x = torch.cat([x1, x2], dim=1)\n",
        "        image_embeddings = self.unet_model.encoder(x)[-1]\n",
        "        image_embeddings = image_embeddings.mean(dim=[2, 3])\n",
        "        image_embeddings = self.image_projection(image_embeddings)\n",
        "        image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True)\n",
        "        # print(f\"Image embeddings size: {image_embeddings.shape}\")\n",
        "\n",
        "        segmentation_result = self.unet_model(x)\n",
        "        # print(f\"Segmentation result size: {segmentation_result.shape}\")\n",
        "\n",
        "        return text_embeddings, image_embeddings, segmentation_result\n",
        "\n",
        "    def clip_contrastive_loss(self, text_embeddings, image_embeddings, temperature=0.07):\n",
        "      logits = torch.matmul(text_embeddings, image_embeddings.T) * torch.exp(torch.tensor(temperature))\n",
        "\n",
        "      labels = torch.arange(text_embeddings.shape[0]).to(device)\n",
        "      loss_i = F.cross_entropy(logits, labels)\n",
        "      loss_t = F.cross_entropy(logits.T, labels)\n",
        "\n",
        "\n",
        "      loss = (loss_i + loss_t) / 2\n",
        "      return loss\n",
        "\n",
        "    def segmentation_loss(self, segmentation_result, target, criterion):\n",
        "      target = target.float().unsqueeze(1).to(device)\n",
        "      loss = criterion(segmentation_result, target)\n",
        "      return loss\n",
        "\n",
        "    def combined_loss(self, text_embeddings, image_embeddings, segmentation_result, target, criterion, temperature=0.07):\n",
        "      clip_loss = self.clip_contrastive_loss(text_embeddings, image_embeddings, temperature)\n",
        "      seg_loss = self.segmentation_loss(segmentation_result, target, criterion)\n",
        "      loss = (\n",
        "            (1.0 / (2.0 * torch.exp(self.log_sigma_clip) ** 2)) * clip_loss +\n",
        "            (1.0 / (2.0 * torch.exp(self.log_sigma_seg) ** 2)) * seg_loss +\n",
        "            self.log_sigma_clip + self.log_sigma_seg\n",
        "        )\n",
        "      return loss\n",
        "\n",
        "\n",
        "clipModel = ClipModel(bert_model, bert_tokenizer, unet_model).to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNr1Mq7W7kDp"
      },
      "outputs": [],
      "source": [
        "def calc_metrics(y_true, y_pred):\n",
        "    \"\"\" Calculează Dice, IoU, Accuracy pe tensori numpy binarizați \"\"\"\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    dice = 2 * (y_true * y_pred).sum() / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "    iou = jaccard_score(y_true, y_pred, average='binary')\n",
        "    acc = (y_true == y_pred).mean()\n",
        "    return dice, iou, acc\n",
        "\n",
        "\n",
        "def plot_prediction(imgs):\n",
        "    # imgs conține: mri, regions, y_true, y_pred; toate în format numpy\n",
        "    mri = imgs['mri'][0,0]        # [B,1,H,W], selectăm prima imagine și canalul 0\n",
        "    regions = imgs['regions'][0,0]\n",
        "    y_true = imgs['y_true'][0,0]\n",
        "    y_pred = imgs['y_pred'][0,0]\n",
        "\n",
        "    fig, axs = plt.subplots(1,4, figsize=(20,5))\n",
        "    axs[0].imshow(mri, cmap='gray')\n",
        "    axs[0].set_title(\"MRI\")\n",
        "    axs[1].imshow(regions, cmap='gray')\n",
        "    axs[1].set_title(\"Regions\")\n",
        "    axs[2].imshow(y_true, cmap='gray')\n",
        "    axs[2].set_title(\"Ground Truth Mask\")\n",
        "    axs[3].imshow(y_pred, cmap='gray')\n",
        "    axs[3].set_title(\"Predicted Mask\")\n",
        "    for ax in axs:\n",
        "        ax.axis('off')\n",
        "    plt.savefig(\"/content/drive/MyDrive/PKG - MU-Glioma-Post/Graphs/sample_prediction_CLIP.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics(train_metrics, val_metrics, save_path):\n",
        "    epochs = range(1, len(train_metrics['loss']) + 1)\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    plt.subplot(2,2,1)\n",
        "    plt.plot(epochs, train_metrics['loss'], label='Train Loss')\n",
        "    plt.plot(epochs, val_metrics['loss'], label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss')\n",
        "\n",
        "    plt.subplot(2,2,2)\n",
        "    plt.plot(epochs, train_metrics['dice'], label='Train Dice')\n",
        "    plt.plot(epochs, val_metrics['dice'], label='Val Dice')\n",
        "    plt.legend()\n",
        "    plt.title('Dice Score')\n",
        "\n",
        "    plt.subplot(2,2,3)\n",
        "    plt.plot(epochs, train_metrics['iou'], label='Train IoU')\n",
        "    plt.plot(epochs, val_metrics['iou'], label='Val IoU')\n",
        "    plt.legend()\n",
        "    plt.title('IoU')\n",
        "\n",
        "    plt.subplot(2,2,4)\n",
        "    plt.plot(epochs, train_metrics['acc'], label='Train Accuracy')\n",
        "    plt.plot(epochs, val_metrics['acc'], label='Val Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "\n",
        "def train_one_epoch_clip(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss, total_dice, total_iou, total_acc = 0, 0, 0, 0\n",
        "    for batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Input: concatenăm MRI și Regions pe canal\n",
        "        mri = batch['mri']\n",
        "        regions = batch['regions']\n",
        "\n",
        "        tumor = batch['tumor']\n",
        "        text = batch['report']\n",
        "\n",
        "        text_embeddings, image_embeddings, segmentation_result = model(text, mri, regions)\n",
        "\n",
        "        loss = model.combined_loss(text_embeddings, image_embeddings, segmentation_result, tumor, criterion)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # preds: logits -> sigmoid -> binarizare prag 0.5\n",
        "        preds_prob = torch.sigmoid(segmentation_result).detach().cpu().numpy() > 0.5\n",
        "        y_np = tumor.float().unsqueeze(1).to(device).detach().cpu().numpy() > 0.5\n",
        "\n",
        "        dice, iou, acc = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += dice\n",
        "        total_iou += iou\n",
        "        total_acc += acc\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n\n",
        "\n",
        "\n",
        "def eval_one_epoch_clip(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_dice, total_iou, total_acc = 0, 0, 0, 0\n",
        "    last_batch_imgs = None  # pentru a salva imagini de afișat\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            mri = batch['mri']\n",
        "            regions = batch['regions']\n",
        "\n",
        "            tumor = batch['tumor']\n",
        "            text = batch['report']\n",
        "\n",
        "            text_embeddings, image_embeddings, segmentation_result = model(text, mri, regions)\n",
        "\n",
        "            loss = model.combined_loss(text_embeddings, image_embeddings, segmentation_result, tumor, criterion)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds_prob = torch.sigmoid(segmentation_result).cpu().numpy() > 0.5\n",
        "            y_np = tumor.float().unsqueeze(1).to(device).detach().cpu().numpy() > 0.5\n",
        "\n",
        "            dice, iou, acc = calc_metrics(y_np, preds_prob)\n",
        "            total_dice += dice\n",
        "            total_iou += iou\n",
        "            total_acc += acc\n",
        "\n",
        "            # Salvăm batch-ul curent pentru afișare (ultimul batch)\n",
        "            last_batch_imgs = {\n",
        "                'mri': mri.float().unsqueeze(1).to(device).cpu().numpy(),\n",
        "                'regions': regions.float().unsqueeze(1).to(device).cpu().numpy(),\n",
        "                'y_true': tumor.float().unsqueeze(1).to(device).cpu().numpy(),\n",
        "                'y_pred': preds_prob\n",
        "            }\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n, last_batch_imgs\n",
        "\n",
        "model = clipModel\n",
        "\n",
        "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.0, total_iters=50)\n",
        "\n",
        "num_epochs = 50\n",
        "best_val_iou = 0\n",
        "train_metrics = {'loss': [], 'dice': [], 'iou': [], 'acc': []}\n",
        "val_metrics = {'loss': [], 'dice': [], 'iou': [], 'acc': []}\n",
        "last_val_batch_imgs = None  # aici salvăm imaginile pentru ultima evaluare\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss, train_dice, train_iou, train_acc = train_one_epoch_clip(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_dice, val_iou, val_acc, val_imgs = eval_one_epoch_clip(model, test_loader, criterion)\n",
        "    scheduler.step()\n",
        "\n",
        "    train_metrics['loss'].append(train_loss)\n",
        "    train_metrics['dice'].append(train_dice)\n",
        "    train_metrics['iou'].append(train_iou)\n",
        "    train_metrics['acc'].append(train_acc)\n",
        "\n",
        "    val_metrics['loss'].append(val_loss)\n",
        "    val_metrics['dice'].append(val_dice)\n",
        "    val_metrics['iou'].append(val_iou)\n",
        "    val_metrics['acc'].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "    print(f\" Train   - Loss: {train_loss:.4f}, Dice: {train_dice:.4f}, IoU: {train_iou:.4f}, Acc: {train_acc:.4f}\")\n",
        "    print(f\" Valid   - Loss: {val_loss:.4f}, Dice: {val_dice:.4f}, IoU: {val_iou:.4f}, Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_iou > best_val_iou:\n",
        "        best_val_iou = val_iou\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/PKG - MU-Glioma-Post/Models/CLIP_Based/best_clip_model.pth\")\n",
        "        print(\"  Saved best model!\")\n",
        "\n",
        "    # Salvăm imaginile din ultimul batch de validare la ultima epocă\n",
        "    if epoch >= num_epochs - 5:\n",
        "      last_val_batch_imgs = val_imgs\n",
        "      plot_prediction(last_val_batch_imgs)\n",
        "\n",
        "# Afișăm predicția vs adevărul pentru ultimul batch\n",
        "if last_val_batch_imgs is not None:\n",
        "    plot_prediction(last_val_batch_imgs)\n",
        "\n",
        "# Salvează graficele metricilor\n",
        "plot_metrics(train_metrics, val_metrics, \"/content/drive/MyDrive/PKG - MU-Glioma-Post/Graphs/training_metrics_CLIP.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JghFp_TJEu2b"
      },
      "source": [
        "**<h2>Libraries<h2>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PnOlsFBMkQYN"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation_models_pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYfjGgr9E0Su"
      },
      "source": [
        "# **M1 - Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJRjNQW9FGwU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load all files\n",
        "mri = np.load(\"/content/PatientID_0036_mri.npy\")\n",
        "tumor = np.load(\"/content/PatientID_0036_tumor.npy\")\n",
        "atlas = np.load(\"/content/PatientID_0036_regions.npy\")\n",
        "\n",
        "# Print shapes\n",
        "print(\"MRI shape:\", mri.shape)\n",
        "print(\"Tumor shape:\", tumor.shape)\n",
        "print(\"Atlas shape:\", atlas.shape)\n",
        "\n",
        "# Plot them together\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# MRI\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(mri, cmap=\"gray\")\n",
        "plt.title(\"MRI\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Tumor mask\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(tumor, cmap=\"hot\")\n",
        "plt.title(\"Tumor mask\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Atlas\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(atlas, cmap=\"nipy_spectral\")\n",
        "plt.title(\"Atlas regions\")\n",
        "plt.axis(\"off\")\n",
        "plt.colorbar()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn2kMfdIK4et"
      },
      "source": [
        "***MRI (left image)***\n",
        "\n",
        "- This is the actual brain scan.\n",
        "\n",
        "- It shows the anatomical structures and tissue appearance.\n",
        "\n",
        "- The model uses this image as the input.\n",
        "\n",
        "--------------------------------------------\n",
        "***Tumor Mask (middle image)***\n",
        "\n",
        "This is the ground-truth annotation.\n",
        "\n",
        "- Yellow = whole tumor region\n",
        "\n",
        "- Red = core or high-confidence tumor area\n",
        "\n",
        "- Black = background\n",
        "\n",
        "The model tries to predict this mask.\n",
        "\n",
        "--------------------------------------------\n",
        "***Atlas Regions (right image)***\n",
        "\n",
        "- This is a brain anatomical atlas aligned to the MRI.\n",
        "\n",
        "- Each color corresponds to a different anatomical region.\n",
        "\n",
        "- It gives the model context about where in the brain each pixel is located.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFOZ6KnBLrIt"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/Preprocessed-Data.zip -d /content/Preprocessed-Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsYhGMN5OMs7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATA_ROOT = \"/content/Preprocessed-Data\"\n",
        "USE_ATLAS = True\n",
        "\n",
        "rows = []\n",
        "\n",
        "# 1. Iterate over all patient folders in Preprocessed-Data\n",
        "for pid in sorted(os.listdir(DATA_ROOT)):\n",
        "    patient_dir = os.path.join(DATA_ROOT, pid)\n",
        "    if not os.path.isdir(patient_dir):\n",
        "        continue\n",
        "\n",
        "    tumor_path = os.path.join(patient_dir, f\"{pid}_tumor.npy\")\n",
        "    atlas_path = os.path.join(patient_dir, f\"{pid}_regions.npy\")\n",
        "\n",
        "    # Skip if tumor mask is missing\n",
        "    if not os.path.isfile(tumor_path):\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Load tumor mask\n",
        "        tumor = np.load(tumor_path).astype(np.float32)\n",
        "        mask = tumor > 0.5\n",
        "\n",
        "        # Tumor area and presence\n",
        "        area = float(mask.sum())\n",
        "        has_tumor = 1 if area >= 1 else 0\n",
        "\n",
        "        # Dominant atlas region (inside tumor) if atlas exists\n",
        "        dom_region = -1\n",
        "        if USE_ATLAS and os.path.isfile(atlas_path) and mask.any():\n",
        "            atlas = np.load(atlas_path).astype(np.int32)\n",
        "            vals, counts = np.unique(atlas[mask], return_counts=True)\n",
        "            if len(vals) > 0:\n",
        "                dom_region = int(vals[np.argmax(counts)])\n",
        "\n",
        "        rows.append({\n",
        "            \"pid\": pid,\n",
        "            \"has_tumor\": has_tumor,\n",
        "            \"area\": area,\n",
        "            \"dom\": dom_region,\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Failed for {pid}: {e}\")\n",
        "\n",
        "# 2. Build DataFrame with metadata\n",
        "meta = pd.DataFrame(rows)\n",
        "print(\"Metadata head:\")\n",
        "print(meta.head())\n",
        "print(\"\\nColumns:\", meta.columns.tolist())\n",
        "print(\"\\nNumber of patients:\", len(meta))\n",
        "\n",
        "# 3. Compute size_bin (tumor size bins) like in your partitioning\n",
        "meta[\"size_bin\"] = 0\n",
        "mask_has_tumor = meta[\"has_tumor\"] == 1\n",
        "\n",
        "if mask_has_tumor.any():\n",
        "    areas = meta.loc[mask_has_tumor, \"area\"].values\n",
        "    qs = np.quantile(areas, np.linspace(0, 1, 4))\n",
        "    qs = np.unique(qs)\n",
        "    if len(qs) > 2:\n",
        "        bins = np.digitize(areas, qs[1:-1], right=True)\n",
        "    else:\n",
        "        bins = np.zeros_like(areas, dtype=int)\n",
        "    meta.loc[mask_has_tumor, \"size_bin\"] = bins.astype(int)\n",
        "\n",
        "print(\"\\nSize bin value counts:\")\n",
        "print(meta[\"size_bin\"].value_counts().sort_index())\n",
        "\n",
        "# 4. Plot the distributions used in data partitioning\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "# Tumor size bins\n",
        "meta[\"size_bin\"].value_counts().sort_index().plot(kind=\"bar\", ax=axs[0, 0])\n",
        "axs[0, 0].set_title(\"Tumor size bins\")\n",
        "axs[0, 0].set_xlabel(\"size_bin\")\n",
        "axs[0, 0].set_ylabel(\"Number of patients\")\n",
        "\n",
        "# Has tumor (0/1)\n",
        "meta[\"has_tumor\"].value_counts().sort_index().plot(kind=\"bar\", ax=axs[0, 1])\n",
        "axs[0, 1].set_title(\"Has tumor\")\n",
        "axs[0, 1].set_xlabel(\"has_tumor (0 = no, 1 = yes)\")\n",
        "axs[0, 1].set_ylabel(\"Number of patients\")\n",
        "\n",
        "# Tumor area histogram\n",
        "meta[\"area\"].hist(bins=30, ax=axs[1, 0])\n",
        "axs[1, 0].set_title(\"Tumor area (voxel count)\")\n",
        "axs[1, 0].set_xlabel(\"area\")\n",
        "axs[1, 0].set_ylabel(\"Number of patients\")\n",
        "\n",
        "# Dominant atlas regions (top 10)\n",
        "meta[\"dom\"].value_counts().head(10).plot(kind=\"bar\", ax=axs[1, 1])\n",
        "axs[1, 1].set_title(\"Top 10 dominant atlas regions\")\n",
        "axs[1, 1].set_xlabel(\"region label\")\n",
        "axs[1, 1].set_ylabel(\"Number of patients\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxd1FA6yPLhc"
      },
      "source": [
        "***Tumor size bins***\n",
        "\n",
        "- These bins represent three tumor-size groups created using quantiles of the tumor voxel count.\n",
        "\n",
        "- They ensure that small, medium, and large tumors are balanced across the dataset and across client splits.\n",
        "\n",
        "------------------------------------\n",
        "***Tumor area (voxel count)***\n",
        "\n",
        "- This histogram shows the raw distribution of tumor sizes in the dataset.\n",
        "\n",
        "- It highlights the variability in tumor burden, from small lesions to very large ones.\n",
        "\n",
        "------------------------------------\n",
        "***Top dominant atlas regions***\n",
        "\n",
        "- Each tumor belongs mostly to one anatomical region in the brain atlas.\n",
        "\n",
        "- This plot shows which regions occur most frequently and helps guide stratification, since some regions are common while others are rare.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWJbDT_JSujU"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the cleaned dataframe from pickle\n",
        "with open(\"cleaned_df.pkl\", \"rb\") as f:\n",
        "    df = pickle.load(f)\n",
        "\n",
        "# Print all column names\n",
        "print(\"Columns in cleaned_df:\")\n",
        "for c in df.columns:\n",
        "    print(\" -\", c)\n",
        "\n",
        "# Column names used for plotting\n",
        "col_sex  = \"Sex at Birth\"\n",
        "col_race = \"Race\"\n",
        "col_age  = \"Age at diagnosis\"\n",
        "col_diag = \"Primary Diagnosis\"\n",
        "\n",
        "# Create a 2x2 grid of subplots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Pie chart: Sex at Birth\n",
        "df[col_sex].value_counts(dropna=False).plot(\n",
        "    kind=\"pie\", autopct='%1.1f%%', ax=axs[0,0], ylabel=\"\"\n",
        ")\n",
        "axs[0,0].set_title(\"Sex at Birth\")\n",
        "\n",
        "# Pie chart: Race\n",
        "df[col_race].value_counts(dropna=False).plot(\n",
        "    kind=\"pie\", autopct='%1.1f%%', ax=axs[0,1], ylabel=\"\"\n",
        ")\n",
        "axs[0,1].set_title(\"Race\")\n",
        "\n",
        "# Pie chart: Primary Diagnosis\n",
        "df[col_diag].value_counts(dropna=False).plot(\n",
        "    kind=\"pie\", autopct='%1.1f%%', ax=axs[1,0], ylabel=\"\"\n",
        ")\n",
        "axs[1,0].set_title(\"Primary Diagnosis\")\n",
        "\n",
        "# Create age bins and pie chart: Age at Diagnosis\n",
        "age_bins = pd.cut(df[col_age], bins=[0, 20, 40, 60, 80, 120])\n",
        "age_bins.value_counts().sort_index().plot(\n",
        "    kind=\"pie\", autopct='%1.1f%%', ax=axs[1,1], ylabel=\"\"\n",
        ")\n",
        "axs[1,1].set_title(\"Age at Diagnosis (binned)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GZTx9vVNTPY"
      },
      "source": [
        "**<h1>Data Partitioning<h1>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9y8S3ShnIyP"
      },
      "source": [
        "<h2>One client, all data<h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JG6B5jVm5yH"
      },
      "outputs": [],
      "source": [
        "%%writefile data_prep_split.py\n",
        "import os, json, pickle, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Tuple\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Paths and global configuration\n",
        "DATA_ROOT = \"Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "OUT_BASE = \"AITDM\"\n",
        "CLIENT_DIR = os.path.join(OUT_BASE, \"client\")\n",
        "os.makedirs(CLIENT_DIR, exist_ok=True)\n",
        "\n",
        "USE_ATLAS = True\n",
        "N_CLIENTS = 1\n",
        "VAL_FRAC_PER_CLIENT = 0.2\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Set all relevant random seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    \"\"\"Dataset that loads MRI, tumor mask and optional atlas for each patient.\"\"\"\n",
        "\n",
        "    def __init__(self, metadata_df_path, data_root, use_atlas=True, exclude_ids=None, transform=None):\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = [\"PatientID_0191\"]\n",
        "\n",
        "        # Filter out excluded patient IDs\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        # Keep only patients for which all required .npy files exist\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            mri_p = os.path.join(self.data_root, pid, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(self.data_root, pid, f\"{pid}_tumor.npy\")\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(self.data_root, pid, f\"{pid}_regions.npy\")\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p) and os.path.isfile(reg_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "            else:\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        \"\"\"Apply simple min-max normalization to a numpy array.\"\"\"\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        return (x - mn) / (mx - mn) if mx > mn else np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Load one patient sample (MRI, tumor mask, and optional atlas).\"\"\"\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        # Load MRI and tumor mask\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "        # Normalize MRI and binarize tumor mask\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        # Optionally load and normalize atlas regions\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "            regions = self._minmax(regions)\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "def image_only_collate_fn(batch, use_atlas=True):\n",
        "    \"\"\"\n",
        "    Custom collate function to build batched tensors:\n",
        "    x: [B, C, H, W], y: [B, 1, H, W], pid: list of patient IDs.\n",
        "    \"\"\"\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    pids = [it[\"patient_id\"] for it in batch]\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": pids}\n",
        "\n",
        "def patient_meta(pid: str) -> Tuple[int, float, int]:\n",
        "    \"\"\"\n",
        "    Compute simple metadata for one patient:\n",
        "    - has_tumor: 0/1 depending on tumor area\n",
        "    - area: tumor voxel count\n",
        "    - dom_region: dominant atlas region inside tumor mask\n",
        "    \"\"\"\n",
        "    base = os.path.join(DATA_ROOT, pid)\n",
        "\n",
        "    tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "    mask = tumor > 0.5\n",
        "    area = float(mask.sum())\n",
        "    has_tumor = 1 if area >= 1 else 0\n",
        "\n",
        "    dom_region = -1\n",
        "    reg_path = os.path.join(base, f\"{pid}_regions.npy\")\n",
        "\n",
        "    # If atlas is present and tumor exists, find region with most tumor voxels\n",
        "    if USE_ATLAS and os.path.isfile(reg_path) and mask.any():\n",
        "        regs = np.load(reg_path).astype(np.int32)\n",
        "        vals, counts = np.unique(regs[mask], return_counts=True)\n",
        "        if len(vals) > 0:\n",
        "            dom_region = int(vals[np.argmax(counts)])\n",
        "\n",
        "    return has_tumor, area, dom_region\n",
        "\n",
        "def build_meta_for(dataset: ImageOnlyGliomaDataset) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build a DataFrame with metadata for each patient:\n",
        "    - pid\n",
        "    - has_tumor\n",
        "    - area\n",
        "    - dom (dominant region)\n",
        "    - size_bin (tumor size bin)\n",
        "    - strat_label (full stratification label)\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for pid in dataset.patient_ids:\n",
        "        try:\n",
        "            ht, area, dom = patient_meta(pid)\n",
        "            rows.append({\"pid\": pid, \"has_tumor\": ht, \"area\": area, \"dom\": dom})\n",
        "        except Exception:\n",
        "            # Skip patients that fail to load or compute\n",
        "            pass\n",
        "\n",
        "    meta = pd.DataFrame(rows)\n",
        "\n",
        "    # Default size bin = 0 (no tumor or very small)\n",
        "    meta[\"size_bin\"] = 0\n",
        "    m = meta[\"has_tumor\"] == 1\n",
        "\n",
        "    # For patients with tumor, compute quantile-based size bins\n",
        "    if m.any():\n",
        "        areas = meta.loc[m, \"area\"].values\n",
        "        qs = np.quantile(areas, np.linspace(0, 1, 4))\n",
        "        qs = np.unique(qs)\n",
        "        if len(qs) > 2:\n",
        "            bins = np.digitize(areas, qs[1:-1], right=True)\n",
        "        else:\n",
        "            bins = np.zeros_like(areas, dtype=int)\n",
        "        meta.loc[m, \"size_bin\"] = bins.astype(int)\n",
        "\n",
        "    # Full stratification label combining several attributes\n",
        "    meta[\"strat_label\"] = [\n",
        "        f\"{int(ht)}_{int(dom)}_{int(sb)}\"\n",
        "        for ht, dom, sb in zip(meta[\"has_tumor\"], meta[\"dom\"], meta[\"size_bin\"])\n",
        "    ]\n",
        "    return meta\n",
        "\n",
        "def build_label(meta_df: pd.DataFrame, level: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build a stratification label at different granularity levels:\n",
        "    - \"full\": has_tumor + dom + size_bin\n",
        "    - \"ht_dom\": has_tumor + dom\n",
        "    - \"ht_size\": has_tumor + size_bin\n",
        "    - \"ht\": has_tumor only\n",
        "    \"\"\"\n",
        "    if level == \"full\":\n",
        "        return np.array([\n",
        "            f\"{int(ht)}_{int(dom)}_{int(sb)}\"\n",
        "            for ht, dom, sb in zip(meta_df[\"has_tumor\"], meta_df[\"dom\"], meta_df[\"size_bin\"])\n",
        "        ])\n",
        "    if level == \"ht_dom\":\n",
        "        return np.array([\n",
        "            f\"{int(ht)}_{int(dom)}\"\n",
        "            for ht, dom in zip(meta_df[\"has_tumor\"], meta_df[\"dom\"])\n",
        "        ])\n",
        "    if level == \"ht_size\":\n",
        "        return np.array([\n",
        "            f\"{int(ht)}_{int(sb)}\"\n",
        "            for ht, sb in zip(meta_df[\"has_tumor\"], meta_df[\"size_bin\"])\n",
        "        ])\n",
        "    if level == \"ht\":\n",
        "        return meta_df[\"has_tumor\"].astype(str).values\n",
        "    raise ValueError(level)\n",
        "\n",
        "def pick_strat_labels_for_client(meta_client_df: pd.DataFrame, min_per_class: int = 2):\n",
        "    \"\"\"\n",
        "    Try different stratification levels and pick the most detailed one\n",
        "    that has at least `min_per_class` samples for each class.\n",
        "    \"\"\"\n",
        "    for level in [\"full\", \"ht_dom\", \"ht_size\", \"ht\"]:\n",
        "        y = build_label(meta_client_df, level)\n",
        "        counts = pd.Series(y).value_counts()\n",
        "        if (counts >= min_per_class).all():\n",
        "            print(f\"[INFO] Using client train/val stratification level: {level}\")\n",
        "            return y, level\n",
        "    print(\"[WARN] Falling back to NON-stratified train/val.\")\n",
        "    return None, \"none\"\n",
        "\n",
        "# Load full dataset and build metadata\n",
        "dataset = ImageOnlyGliomaDataset(METADATA_DF_PATH, DATA_ROOT, use_atlas=USE_ATLAS, exclude_ids=[\"PatientID_0191\"])\n",
        "meta = build_meta_for(dataset)\n",
        "\n",
        "clients: List[Dict[str, List[str]]] = []\n",
        "client_metas = []\n",
        "\n",
        "# In this script we only create a single \"client_0\" with a stratified train/val split\n",
        "meta_c = meta.reset_index(drop=True)\n",
        "Xc = meta_c[\"pid\"].values\n",
        "\n",
        "y_client, tv_level = pick_strat_labels_for_client(meta_c, min_per_class=2)\n",
        "\n",
        "if tv_level != \"none\":\n",
        "    # Stratified train/validation split\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_FRAC_PER_CLIENT, random_state=SEED)\n",
        "    (tr_idx, va_idx), = sss.split(Xc, y_client)\n",
        "    train_pids = Xc[tr_idx].tolist()\n",
        "    val_pids   = Xc[va_idx].tolist()\n",
        "else:\n",
        "    # Fallback: random split without stratification\n",
        "    rng = np.random.RandomState(SEED)\n",
        "    perm = rng.permutation(len(Xc))\n",
        "    split_at = int((1.0 - VAL_FRAC_PER_CLIENT) * len(Xc))\n",
        "    train_pids = Xc[perm[:split_at]].tolist()\n",
        "    val_pids   = Xc[perm[split_at:]].tolist()\n",
        "\n",
        "# Save client_0 train/val patient ID lists\n",
        "cdir = os.path.join(CLIENT_DIR, \"client_0\")\n",
        "os.makedirs(cdir, exist_ok=True)\n",
        "with open(os.path.join(cdir, \"train_pids.json\"), \"w\") as f:\n",
        "    json.dump(train_pids, f, indent=2)\n",
        "with open(os.path.join(cdir, \"val_pids.json\"), \"w\") as f:\n",
        "    json.dump(val_pids, f, indent=2)\n",
        "\n",
        "clients.append({\"train\": train_pids, \"val\": val_pids})\n",
        "client_metas.append(meta_c)\n",
        "\n",
        "# Save basic manifest of the split configuration\n",
        "manifest = {\n",
        "    \"seed\": SEED,\n",
        "    \"use_atlas\": USE_ATLAS,\n",
        "    \"n_clients\": 1,\n",
        "    \"val_frac_per_client\": VAL_FRAC_PER_CLIENT,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"num_workers\": NUM_WORKERS,\n",
        "    \"kfold_level\": \"single_client\"\n",
        "}\n",
        "with open(os.path.join(CLIENT_DIR, \"manifest.json\"), \"w\") as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "\n",
        "class SubsetByPIDs(Dataset):\n",
        "    \"\"\"Simple subset wrapper that restricts the dataset to a given list of patient IDs.\"\"\"\n",
        "\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        # Keep only IDs that exist in the base dataset\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "def make_loader(ds, shuffle):\n",
        "    \"\"\"Create a DataLoader with the custom collate function.\"\"\"\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        generator=torch.Generator().manual_seed(SEED),\n",
        "    )\n",
        "\n",
        "# Build small preview loaders for sanity checks\n",
        "preview_loaders = []\n",
        "for cid, cl in enumerate(clients):\n",
        "    ds_tr = SubsetByPIDs(dataset, cl[\"train\"])\n",
        "    ds_va = SubsetByPIDs(dataset, cl[\"val\"])\n",
        "    ld_tr = make_loader(ds_tr, shuffle=True)\n",
        "    ld_va = make_loader(ds_va, shuffle=False)\n",
        "    preview_loaders.append((ld_tr, ld_va))\n",
        "\n",
        "def summarize(meta_df: pd.DataFrame, name: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Create a compact summary of a metadata subset:\n",
        "    - number of patients\n",
        "    - tumor presence counts\n",
        "    - size bin counts\n",
        "    - top 5 dominant regions\n",
        "    \"\"\"\n",
        "    s = {\"name\": name, \"n\": int(len(meta_df))}\n",
        "    s[\"has_tumor_counts\"] = meta_df[\"has_tumor\"].value_counts().to_dict()\n",
        "    s[\"size_bin_counts\"] = meta_df[\"size_bin\"].value_counts().to_dict()\n",
        "    s[\"dom_region_top5\"] = meta_df[\"dom\"].value_counts().head(5).to_dict()\n",
        "    return s\n",
        "\n",
        "# Global summary\n",
        "summary_all = summarize(meta, \"ALL\")\n",
        "print(\"\\n=== Global summary ===\")\n",
        "print(summary_all)\n",
        "\n",
        "# Per-client train/val summaries (here only one client)\n",
        "per_client_summaries = []\n",
        "for cid, cl in enumerate(clients):\n",
        "    meta_c = client_metas[cid]\n",
        "    tr = meta_c[meta_c[\"pid\"].isin(cl[\"train\"])]\n",
        "    va = meta_c[meta_c[\"pid\"].isin(cl[\"val\"])]\n",
        "    s_client = {\n",
        "        \"client\": \"client\",\n",
        "        \"train\": summarize(tr, \"client_train\"),\n",
        "        \"val\": summarize(va, \"client_val\"),\n",
        "    }\n",
        "    per_client_summaries.append(s_client)\n",
        "    print(\"\\n=== Client ===\")\n",
        "    print(s_client)\n",
        "\n",
        "# Save all summaries to disk\n",
        "with open(os.path.join(CLIENT_DIR, \"summary.json\"), \"w\") as f:\n",
        "    json.dump({\"global\": summary_all, \"per_client\": per_client_summaries}, f, indent=2)\n",
        "\n",
        "print(f\"\\nSaved client split and summaries to: {CLIENT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if1Ip7f-Gn01"
      },
      "source": [
        "**Data Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6DL3ct7luT4"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"global\": {\n",
        "    \"name\": \"ALL\",\n",
        "    \"n\": 202,\n",
        "    \"has_tumor_counts\": {\n",
        "      \"1\": 202\n",
        "    },\n",
        "    \"size_bin_counts\": {\n",
        "      \"0\": 68,\n",
        "      \"1\": 67,\n",
        "      \"2\": 67\n",
        "    },\n",
        "    \"dom_region_top5\": {\n",
        "      \"61\": 85,\n",
        "      \"50\": 81,\n",
        "      \"0\": 10,\n",
        "      \"10\": 4,\n",
        "      \"22\": 3\n",
        "    }\n",
        "  },\n",
        "  \"per_client\": [\n",
        "    {\n",
        "      \"client\": \"client\",\n",
        "      \"train\": {\n",
        "        \"name\": \"client_train\",\n",
        "        \"n\": 161,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 161\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"2\": 54,\n",
        "          \"0\": 54,\n",
        "          \"1\": 53\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"61\": 68,\n",
        "          \"50\": 64,\n",
        "          \"0\": 9,\n",
        "          \"10\": 3,\n",
        "          \"15\": 2\n",
        "        }\n",
        "      },\n",
        "      \"val\": {\n",
        "        \"name\": \"client_val\",\n",
        "        \"n\": 41,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 41\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"1\": 14,\n",
        "          \"0\": 14,\n",
        "          \"2\": 13\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"61\": 17,\n",
        "          \"50\": 17,\n",
        "          \"31\": 1,\n",
        "          \"53\": 1,\n",
        "          \"10\": 1\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqd4YVbAmZe-"
      },
      "source": [
        "<h2>Same distribution between 3 clients<h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FHiqxXmkUeF"
      },
      "outputs": [],
      "source": [
        "%%writefile data_prep_split.py\n",
        "import os, json, pickle, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Tuple\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Global paths and configuration\n",
        "DATA_ROOT = \"Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "OUT_BASE = \"AITDM\"\n",
        "CLIENT_DIR = os.path.join(OUT_BASE, \"client\")\n",
        "os.makedirs(CLIENT_DIR, exist_ok=True)\n",
        "\n",
        "USE_ATLAS = True\n",
        "N_CLIENTS = 3\n",
        "VAL_FRAC_PER_CLIENT = 0.2\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "# Set all random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "# Dataset that loads MRI, tumor mask and optional atlas for each patient\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    def __init__(self, metadata_df_path, data_root, use_atlas=True, exclude_ids=None, transform=None):\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = [\"PatientID_0191\"]\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        # Collect patient IDs that have all required .npy files\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            mri_p = os.path.join(self.data_root, pid, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(self.data_root, pid, f\"{pid}_tumor.npy\")\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(self.data_root, pid, f\"{pid}_regions.npy\")\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p) and os.path.isfile(reg_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "            else:\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    # Simple min–max normalization\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        return (x - mn) / (mx - mn) if mx > mn else np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    # Load a single patient sample\n",
        "    def __getitem__(self, idx):\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "            regions = self._minmax(regions)\n",
        "            sample[\"regions\"] = regions\n",
        "        return sample\n",
        "\n",
        "# Custom collate function building batched tensors and patient IDs\n",
        "def image_only_collate_fn(batch, use_atlas=True):\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "    pids = [it[\"patient_id\"] for it in batch]\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": pids}\n",
        "\n",
        "# Compute basic metadata for a patient (tumor presence, area, dominant atlas region)\n",
        "def patient_meta(pid: str) -> Tuple[int, float, int]:\n",
        "    base = os.path.join(DATA_ROOT, pid)\n",
        "    tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "    mask = tumor > 0.5\n",
        "    area = float(mask.sum())\n",
        "    has_tumor = 1 if area >= 1 else 0\n",
        "\n",
        "    dom_region = -1\n",
        "    reg_path = os.path.join(base, f\"{pid}_regions.npy\")\n",
        "    if USE_ATLAS and os.path.isfile(reg_path) and mask.any():\n",
        "        regs = np.load(reg_path).astype(np.int32)\n",
        "        vals, counts = np.unique(regs[mask], return_counts=True)\n",
        "        if len(vals) > 0:\n",
        "            dom_region = int(vals[np.argmax(counts)])\n",
        "    return has_tumor, area, dom_region\n",
        "\n",
        "# Build a metadata DataFrame for all patients in the dataset\n",
        "def build_meta_for(dataset: ImageOnlyGliomaDataset) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for pid in dataset.patient_ids:\n",
        "        try:\n",
        "            ht, area, dom = patient_meta(pid)\n",
        "            rows.append({\"pid\": pid, \"has_tumor\": ht, \"area\": area, \"dom\": dom})\n",
        "        except Exception:\n",
        "            pass\n",
        "    meta = pd.DataFrame(rows)\n",
        "\n",
        "    # Compute tumor size bins for patients with tumor\n",
        "    meta[\"size_bin\"] = 0\n",
        "    m = meta[\"has_tumor\"] == 1\n",
        "    if m.any():\n",
        "        areas = meta.loc[m, \"area\"].values\n",
        "        qs = np.quantile(areas, np.linspace(0, 1, 4))\n",
        "        qs = np.unique(qs)\n",
        "        bins = np.digitize(areas, qs[1:-1], right=True) if len(qs) > 2 else np.zeros_like(areas, dtype=int)\n",
        "        meta.loc[m, \"size_bin\"] = bins.astype(int)\n",
        "\n",
        "    # Full stratification label combining several attributes\n",
        "    meta[\"strat_label\"] = [\n",
        "        f\"{int(ht)}_{int(dom)}_{int(sb)}\"\n",
        "        for ht, dom, sb in zip(meta[\"has_tumor\"], meta[\"dom\"], meta[\"size_bin\"])\n",
        "    ]\n",
        "    return meta\n",
        "\n",
        "# Build a stratification label with different levels of granularity\n",
        "def build_label(meta_df: pd.DataFrame, level: str) -> np.ndarray:\n",
        "    if level == \"full\":\n",
        "        return np.array([\n",
        "            f\"{int(ht)}_{int(dom)}_{int(sb)}\"\n",
        "            for ht, dom, sb in zip(meta_df[\"has_tumor\"], meta_df[\"dom\"], meta_df[\"size_bin\"])\n",
        "        ])\n",
        "    if level == \"ht_dom\":\n",
        "        return np.array([\n",
        "            f\"{int(ht)}_{int(dom)}\"\n",
        "            for ht, dom in zip(meta_df[\"has_tumor\"], meta_df[\"dom\"])\n",
        "        ])\n",
        "    if level == \"ht_size\":\n",
        "        return np.array([\n",
        "            f\"{int(ht)}_{int(sb)}\"\n",
        "            for ht, sb in zip(meta_df[\"has_tumor\"], meta_df[\"size_bin\"])\n",
        "        ])\n",
        "    if level == \"ht\":\n",
        "        return meta_df[\"has_tumor\"].astype(str).values\n",
        "    raise ValueError(level)\n",
        "\n",
        "# Choose the stratification labels level for K-Fold client split\n",
        "def pick_strat_labels_for_kfold(meta_df: pd.DataFrame, n_splits: int):\n",
        "    for level in [\"full\", \"ht_dom\", \"ht_size\", \"ht\"]:\n",
        "        y = build_label(meta_df, level)\n",
        "        counts = pd.Series(y).value_counts()\n",
        "        if (counts >= n_splits).all():\n",
        "            print(f\"[INFO] Using K-Fold stratification level: {level}\")\n",
        "            return y, level\n",
        "        else:\n",
        "            rare = counts[counts < n_splits]\n",
        "            print(f\"[WARN] Level '{level}' has rare classes (<{n_splits}): {rare.to_dict()} -> trying coarser...\")\n",
        "    print(\"[WARN] Falling back to NON-stratified K-Fold (insufficient counts at all levels).\")\n",
        "    return None, \"none\"\n",
        "\n",
        "# Choose the stratification labels level for the train/val split inside each client\n",
        "def pick_strat_labels_for_client(meta_client_df: pd.DataFrame, min_per_class: int = 2):\n",
        "    for level in [\"full\", \"ht_dom\", \"ht_size\", \"ht\"]:\n",
        "        y = build_label(meta_client_df, level)\n",
        "        counts = pd.Series(y).value_counts()\n",
        "        if (counts >= min_per_class).all():\n",
        "            print(f\"[INFO] Using client train/val stratification level: {level}\")\n",
        "            return y, level\n",
        "        else:\n",
        "            rare = counts[counts < min_per_class]\n",
        "            print(f\"[WARN] Client level '{level}' rare classes (<{min_per_class}): {rare.to_dict()} -> trying coarser...\")\n",
        "    print(\"[WARN] Falling back to NON-stratified train/val (insufficient counts at all levels).\")\n",
        "    return None, \"none\"\n",
        "\n",
        "# Load dataset and metadata for all patients\n",
        "dataset = ImageOnlyGliomaDataset(METADATA_DF_PATH, DATA_ROOT, use_atlas=USE_ATLAS, exclude_ids=[\"PatientID_0191\"])\n",
        "meta = build_meta_for(dataset)\n",
        "\n",
        "# Prepare global patient IDs and K-Fold labels\n",
        "X_all = meta[\"pid\"].values\n",
        "y_all_full, kfold_level = pick_strat_labels_for_kfold(meta, n_splits=N_CLIENTS)\n",
        "\n",
        "clients: List[Dict[str, List[str]]] = []\n",
        "client_metas = []\n",
        "\n",
        "# Create client splits and per-client train/val splits\n",
        "if kfold_level != \"none\":\n",
        "    skf = StratifiedKFold(n_splits=N_CLIENTS, shuffle=True, random_state=SEED)\n",
        "    for split_idx, (_, idx) in enumerate(skf.split(X_all, y_all_full)):\n",
        "        pids_client = X_all[idx]\n",
        "        meta_c = meta[meta[\"pid\"].isin(pids_client)].reset_index(drop=True)\n",
        "\n",
        "        y_client, tv_level = pick_strat_labels_for_client(meta_c, min_per_class=2)\n",
        "        Xc = meta_c[\"pid\"].values\n",
        "\n",
        "        if tv_level != \"none\":\n",
        "            sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_FRAC_PER_CLIENT, random_state=SEED)\n",
        "            (tr_idx, va_idx), = sss.split(Xc, y_client)\n",
        "            train_pids = Xc[tr_idx].tolist()\n",
        "            val_pids   = Xc[va_idx].tolist()\n",
        "        else:\n",
        "            rng = np.random.RandomState(SEED)\n",
        "            perm = rng.permutation(len(Xc))\n",
        "            split_at = int((1.0 - VAL_FRAC_PER_CLIENT) * len(Xc))\n",
        "            train_pids = Xc[perm[:split_at]].tolist()\n",
        "            val_pids   = Xc[perm[split_at:]].tolist()\n",
        "\n",
        "        cdir = os.path.join(CLIENT_DIR, f\"client_{split_idx}\")\n",
        "        os.makedirs(cdir, exist_ok=True)\n",
        "        with open(os.path.join(cdir, \"train_pids.json\"), \"w\") as f:\n",
        "            json.dump(train_pids, f, indent=2)\n",
        "        with open(os.path.join(cdir, \"val_pids.json\"), \"w\") as f:\n",
        "            json.dump(val_pids, f, indent=2)\n",
        "\n",
        "        clients.append({\"train\": train_pids, \"val\": val_pids})\n",
        "        client_metas.append(meta_c)\n",
        "else:\n",
        "    print(\"[INFO] Non-stratified 3-way split (deterministic) for clients.\")\n",
        "    rng = np.random.RandomState(SEED)\n",
        "    perm = rng.permutation(len(X_all))\n",
        "    sizes = [len(X_all) // N_CLIENTS] * N_CLIENTS\n",
        "    sizes[-1] += len(X_all) - sum(sizes)\n",
        "    start = 0\n",
        "    for split_idx, sz in enumerate(sizes):\n",
        "        pids_client = X_all[perm[start:start + sz]]\n",
        "        start += sz\n",
        "\n",
        "        meta_c = meta[meta[\"pid\"].isin(pids_client)].reset_index(drop=True)\n",
        "        Xc = meta_c[\"pid\"].values\n",
        "\n",
        "        perm_c = rng.permutation(len(Xc))\n",
        "        split_at = int((1.0 - VAL_FRAC_PER_CLIENT) * len(Xc))\n",
        "        train_pids = Xc[perm_c[:split_at]].tolist()\n",
        "        val_pids   = Xc[perm_c[split_at:]].tolist()\n",
        "\n",
        "        cdir = os.path.join(CLIENT_DIR, f\"client_{split_idx}\")\n",
        "        os.makedirs(cdir, exist_ok=True)\n",
        "        with open(os.path.join(cdir, \"train_pids.json\"), \"w\") as f:\n",
        "            json.dump(train_pids, f, indent=2)\n",
        "        with open(os.path.join(cdir, \"val_pids.json\"), \"w\") as f:\n",
        "            json.dump(val_pids, f, indent=2)\n",
        "\n",
        "        clients.append({\"train\": train_pids, \"val\": val_pids})\n",
        "        client_metas.append(meta_c)\n",
        "\n",
        "# Save a small manifest describing the split configuration\n",
        "manifest = {\n",
        "    \"seed\": SEED,\n",
        "    \"use_atlas\": USE_ATLAS,\n",
        "    \"n_clients\": N_CLIENTS,\n",
        "    \"val_frac_per_client\": VAL_FRAC_PER_CLIENT,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"num_workers\": NUM_WORKERS,\n",
        "    \"kfold_level\": kfold_level\n",
        "}\n",
        "with open(os.path.join(CLIENT_DIR, \"manifest.json\"), \"w\") as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "\n",
        "# Dataset wrapper that restricts to a given list of patient IDs\n",
        "class SubsetByPIDs(Dataset):\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Helper to create a DataLoader with the custom collate function\n",
        "def make_loader(ds, shuffle):\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        generator=torch.Generator().manual_seed(SEED),\n",
        "    )\n",
        "\n",
        "# Optional preview loaders for quick sanity checks\n",
        "preview_loaders = []\n",
        "for cid, cl in enumerate(clients):\n",
        "    ds_tr = SubsetByPIDs(dataset, cl[\"train\"])\n",
        "    ds_va = SubsetByPIDs(dataset, cl[\"val\"])\n",
        "    ld_tr = make_loader(ds_tr, shuffle=True)\n",
        "    ld_va = make_loader(ds_va, shuffle=False)\n",
        "    preview_loaders.append((ld_tr, ld_va))\n",
        "\n",
        "# Summarize metadata distribution for a subset\n",
        "def summarize(meta_df: pd.DataFrame, name: str) -> Dict:\n",
        "    s = {\"name\": name, \"n\": int(len(meta_df))}\n",
        "    s[\"has_tumor_counts\"] = meta_df[\"has_tumor\"].value_counts().to_dict()\n",
        "    s[\"size_bin_counts\"] = meta_df[\"size_bin\"].value_counts().to_dict()\n",
        "    s[\"dom_region_top5\"] = meta_df[\"dom\"].value_counts().head(5).to_dict()\n",
        "    return s\n",
        "\n",
        "# Global metadata summary\n",
        "summary_all = summarize(meta, \"ALL\")\n",
        "print(\"\\n=== Global summary ===\")\n",
        "print(summary_all)\n",
        "\n",
        "# Per-client train/val metadata summaries\n",
        "per_client_summaries = []\n",
        "for cid, cl in enumerate(clients):\n",
        "    meta_c = client_metas[cid]\n",
        "    tr = meta_c[meta_c[\"pid\"].isin(cl[\"train\"])]\n",
        "    va = meta_c[meta_c[\"pid\"].isin(cl[\"val\"])]\n",
        "    s_client = {\n",
        "        \"client\": cid,\n",
        "        \"train\": summarize(tr, f\"client_{cid}_train\"),\n",
        "        \"val\": summarize(va, f\"client_{cid}_val\"),\n",
        "    }\n",
        "    per_client_summaries.append(s_client)\n",
        "    print(f\"\\n=== Client {cid} ===\")\n",
        "    print(s_client)\n",
        "\n",
        "# Save all summaries to disk\n",
        "with open(os.path.join(CLIENT_DIR, \"summary.json\"), \"w\") as f:\n",
        "    json.dump({\"global\": summary_all, \"per_client\": per_client_summaries}, f, indent=2)\n",
        "\n",
        "print(f\"\\nSaved 3 client splits and summaries to: {CLIENT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfJlyrz0HEQT"
      },
      "source": [
        "**Data Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m02RicJl5mC"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"global\": {\n",
        "    \"name\": \"ALL\",\n",
        "    \"n\": 202,\n",
        "    \"has_tumor_counts\": {\n",
        "      \"1\": 202\n",
        "    },\n",
        "    \"size_bin_counts\": {\n",
        "      \"0\": 68,\n",
        "      \"1\": 67,\n",
        "      \"2\": 67\n",
        "    },\n",
        "    \"dom_region_top5\": {\n",
        "      \"61\": 85,\n",
        "      \"50\": 81,\n",
        "      \"0\": 10,\n",
        "      \"10\": 4,\n",
        "      \"22\": 3\n",
        "    }\n",
        "  },\n",
        "  \"per_client\": [\n",
        "    {\n",
        "      \"client\": 0,\n",
        "      \"train\": {\n",
        "        \"name\": \"client_0_train\",\n",
        "        \"n\": 54,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 54\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"1\": 18,\n",
        "          \"2\": 18,\n",
        "          \"0\": 18\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"61\": 29,\n",
        "          \"50\": 15,\n",
        "          \"0\": 4,\n",
        "          \"7\": 1,\n",
        "          \"17\": 1\n",
        "        }\n",
        "      },\n",
        "      \"val\": {\n",
        "        \"name\": \"client_0_val\",\n",
        "        \"n\": 14,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 14\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"0\": 5,\n",
        "          \"1\": 5,\n",
        "          \"2\": 4\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"50\": 9,\n",
        "          \"53\": 1,\n",
        "          \"10\": 1,\n",
        "          \"61\": 1,\n",
        "          \"15\": 1\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"client\": 1,\n",
        "      \"train\": {\n",
        "        \"name\": \"client_1_train\",\n",
        "        \"n\": 53,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 53\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"1\": 18,\n",
        "          \"2\": 18,\n",
        "          \"0\": 17\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"50\": 22,\n",
        "          \"61\": 19,\n",
        "          \"0\": 3,\n",
        "          \"22\": 2,\n",
        "          \"10\": 1\n",
        "        }\n",
        "      },\n",
        "      \"val\": {\n",
        "        \"name\": \"client_1_val\",\n",
        "        \"n\": 14,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 14\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"2\": 5,\n",
        "          \"0\": 5,\n",
        "          \"1\": 4\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"50\": 6,\n",
        "          \"61\": 6,\n",
        "          \"10\": 1,\n",
        "          \"22\": 1\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"client\": 2,\n",
        "      \"train\": {\n",
        "        \"name\": \"client_2_train\",\n",
        "        \"n\": 53,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 53\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"2\": 18,\n",
        "          \"0\": 18,\n",
        "          \"1\": 17\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"61\": 25,\n",
        "          \"50\": 22,\n",
        "          \"23\": 1,\n",
        "          \"31\": 1,\n",
        "          \"62\": 1\n",
        "        }\n",
        "      },\n",
        "      \"val\": {\n",
        "        \"name\": \"client_2_val\",\n",
        "        \"n\": 14,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 14\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"0\": 5,\n",
        "          \"1\": 5,\n",
        "          \"2\": 4\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"50\": 7,\n",
        "          \"61\": 5,\n",
        "          \"10\": 1,\n",
        "          \"0\": 1\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV6kW5udsrGF"
      },
      "source": [
        "<h2>non-IID between 3 clients<h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1fCwCcXtNQk"
      },
      "outputs": [],
      "source": [
        "%%writefile data_prep_split.py\n",
        "import os, json, pickle, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Global configuration and paths\n",
        "DATA_ROOT = \"Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "OUT_BASE = \"AITDM\"\n",
        "CLIENT_DIR = os.path.join(OUT_BASE, \"client\")\n",
        "os.makedirs(CLIENT_DIR, exist_ok=True)\n",
        "\n",
        "USE_ATLAS = True\n",
        "N_CLIENTS = 3\n",
        "VAL_FRAC_PER_CLIENT = 0.2\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "# Dirichlet alpha controls degree of non-IID distribution\n",
        "DIRICHLET_ALPHA = 0.3\n",
        "\n",
        "# Ensure reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "# Dataset class that loads MRI, tumor masks, and optional atlas data\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    def __init__(self, metadata_df_path, data_root, use_atlas=True, exclude_ids=None, transform=None):\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = [\"PatientID_0191\"]\n",
        "\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        # Collect only patients with required files\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            mri_p = os.path.join(self.data_root, pid, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(self.data_root, pid, f\"{pid}_tumor.npy\")\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(self.data_root, pid, f\"{pid}_regions.npy\")\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p) and os.path.isfile(reg_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "            else:\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    # Min–max normalization\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        return (x - mn) / (mx - mn) if mx > mn else np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    # Load a single patient's MRI + masks\n",
        "    def __getitem__(self, idx):\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "            regions = self._minmax(regions)\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "# Collate function used in DataLoaders\n",
        "def image_only_collate_fn(batch, use_atlas=True):\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    pids = [it[\"patient_id\"] for it in batch]\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": pids}\n",
        "\n",
        "# Compute tumor presence, area and dominant atlas region\n",
        "def patient_meta(pid: str) -> Tuple[int, float, int]:\n",
        "    base = os.path.join(DATA_ROOT, pid)\n",
        "    tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "    mask = tumor > 0.5\n",
        "\n",
        "    area = float(mask.sum())\n",
        "    has_tumor = 1 if area >= 1 else 0\n",
        "\n",
        "    dom_region = -1\n",
        "    reg_path = os.path.join(base, f\"{pid}_regions.npy\")\n",
        "\n",
        "    if USE_ATLAS and os.path.isfile(reg_path) and mask.any():\n",
        "        regs = np.load(reg_path).astype(np.int32)\n",
        "        vals, counts = np.unique(regs[mask], return_counts=True)\n",
        "        if len(vals) > 0:\n",
        "            dom_region = int(vals[np.argmax(counts)])\n",
        "\n",
        "    return has_tumor, area, dom_region\n",
        "\n",
        "# Build metadata for all patients\n",
        "def build_meta_for(dataset: ImageOnlyGliomaDataset) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for pid in dataset.patient_ids:\n",
        "        try:\n",
        "            ht, area, dom = patient_meta(pid)\n",
        "            rows.append({\"pid\": pid, \"has_tumor\": ht, \"area\": area, \"dom\": dom})\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    meta = pd.DataFrame(rows)\n",
        "\n",
        "    # Create tumor size bins\n",
        "    meta[\"size_bin\"] = 0\n",
        "    m = meta[\"has_tumor\"] == 1\n",
        "    if m.any():\n",
        "        areas = meta.loc[m, \"area\"].values\n",
        "        qs = np.quantile(areas, np.linspace(0, 1, 4))\n",
        "        qs = np.unique(qs)\n",
        "        bins = np.digitize(areas, qs[1:-1], right=True) if len(qs) > 2 else np.zeros_like(areas, int)\n",
        "        meta.loc[m, \"size_bin\"] = bins.astype(int)\n",
        "\n",
        "    return meta\n",
        "\n",
        "# Load dataset + metadata\n",
        "dataset = ImageOnlyGliomaDataset(METADATA_DF_PATH, DATA_ROOT, use_atlas=USE_ATLAS, exclude_ids=[\"PatientID_0191\"])\n",
        "meta = build_meta_for(dataset)\n",
        "rng = np.random.RandomState(SEED)\n",
        "\n",
        "# Group patients by class (tumor size bin)\n",
        "class_to_pids = defaultdict(list)\n",
        "for _, row in meta.iterrows():\n",
        "    label = row[\"size_bin\"]\n",
        "    class_to_pids[label].append(row[\"pid\"])\n",
        "\n",
        "# Allocate patients to clients using Dirichlet sampling\n",
        "client_pid_sets = [[] for _ in range(N_CLIENTS)]\n",
        "\n",
        "for label, pids in class_to_pids.items():\n",
        "    pids = rng.permutation(pids)\n",
        "    proportions = rng.dirichlet([DIRICHLET_ALPHA] * N_CLIENTS)\n",
        "    counts = (proportions * len(pids)).astype(int)\n",
        "\n",
        "    # Adjust counts to cover all samples\n",
        "    while counts.sum() < len(pids):\n",
        "        counts[rng.randint(0, N_CLIENTS)] += 1\n",
        "\n",
        "    start = 0\n",
        "    for cid, count in enumerate(counts):\n",
        "        subset = pids[start:start + count]\n",
        "        client_pid_sets[cid].extend(subset)\n",
        "        start += count\n",
        "\n",
        "# Create clients + train/val splits\n",
        "clients = []\n",
        "client_metas = []\n",
        "\n",
        "for cid in range(N_CLIENTS):\n",
        "    Xc = np.array(client_pid_sets[cid])\n",
        "\n",
        "    rng_c = np.random.RandomState(SEED + cid)\n",
        "    perm_c = rng_c.permutation(len(Xc))\n",
        "\n",
        "    split_at = max(1, int((1.0 - VAL_FRAC_PER_CLIENT) * len(Xc)))\n",
        "    split_at = min(split_at, len(Xc) - 1)\n",
        "\n",
        "    train_pids = Xc[perm_c[:split_at]].tolist()\n",
        "    val_pids   = Xc[perm_c[split_at:]].tolist()\n",
        "\n",
        "    meta_c = meta[meta[\"pid\"].isin(Xc)].reset_index(drop=True)\n",
        "\n",
        "    cdir = os.path.join(CLIENT_DIR, f\"client_{cid}\")\n",
        "    os.makedirs(cdir, exist_ok=True)\n",
        "\n",
        "    with open(os.path.join(cdir, \"train_pids.json\"), \"w\") as f:\n",
        "        json.dump(train_pids, f, indent=2)\n",
        "\n",
        "    with open(os.path.join(cdir, \"val_pids.json\"), \"w\") as f:\n",
        "        json.dump(val_pids, f, indent=2)\n",
        "\n",
        "    clients.append({\"train\": train_pids, \"val\": val_pids})\n",
        "    client_metas.append(meta_c)\n",
        "\n",
        "print(f\"[INFO] Created {N_CLIENTS} non-IID clients using Dirichlet split (alpha={DIRICHLET_ALPHA}).\")\n",
        "\n",
        "# Save manifest describing split configuration\n",
        "manifest = {\n",
        "    \"seed\": SEED,\n",
        "    \"use_atlas\": USE_ATLAS,\n",
        "    \"n_clients\": N_CLIENTS,\n",
        "    \"val_frac_per_client\": VAL_FRAC_PER_CLIENT,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"num_workers\": NUM_WORKERS,\n",
        "    \"split_type\": \"non-IID_Dirichlet\",\n",
        "    \"dirichlet_alpha\": DIRICHLET_ALPHA\n",
        "}\n",
        "\n",
        "with open(os.path.join(CLIENT_DIR, \"manifest.json\"), \"w\") as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "\n",
        "# Dataset wrapper for selecting specific patient IDs\n",
        "class SubsetByPIDs(Dataset):\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Helper to build DataLoaders\n",
        "def make_loader(ds, shuffle):\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        generator=torch.Generator().manual_seed(SEED),\n",
        "    )\n",
        "\n",
        "# Build preview loaders for validation\n",
        "preview_loaders = []\n",
        "for cid, cl in enumerate(clients):\n",
        "    ds_tr = SubsetByPIDs(dataset, cl[\"train\"])\n",
        "    ds_va = SubsetByPIDs(dataset, cl[\"val\"])\n",
        "    ld_tr = make_loader(ds_tr, shuffle=True)\n",
        "    ld_va = make_loader(ds_va, shuffle=False)\n",
        "    preview_loaders.append((ld_tr, ld_va))\n",
        "\n",
        "# Produce metadata summaries\n",
        "def summarize(meta_df: pd.DataFrame, name: str) -> Dict:\n",
        "    s = {\"name\": name, \"n\": int(len(meta_df))}\n",
        "    s[\"has_tumor_counts\"] = meta_df[\"has_tumor\"].value_counts().to_dict()\n",
        "    s[\"size_bin_counts\"] = meta_df[\"size_bin\"].value_counts().to_dict()\n",
        "    s[\"dom_region_top5\"] = meta_df[\"dom\"].value_counts().head(5).to_dict()\n",
        "    return s\n",
        "\n",
        "summary_all = summarize(meta, \"ALL\")\n",
        "print(\"\\n=== Global summary ===\")\n",
        "print(summary_all)\n",
        "\n",
        "per_client_summaries = []\n",
        "for cid, cl in enumerate(clients):\n",
        "    meta_c = client_metas[cid]\n",
        "    tr = meta_c[meta_c[\"pid\"].isin(cl[\"train\"])]\n",
        "    va = meta_c[meta_c[\"pid\"].isin(cl[\"val\"])]\n",
        "\n",
        "    s_client = {\n",
        "        \"client\": cid,\n",
        "        \"train\": summarize(tr, f\"client_{cid}_train\"),\n",
        "        \"val\": summarize(va, f\"client_{cid}_val\"),\n",
        "    }\n",
        "\n",
        "    per_client_summaries.append(s_client)\n",
        "    print(f\"\\n=== Client {cid} ===\")\n",
        "    print(s_client)\n",
        "\n",
        "# Save summaries\n",
        "with open(os.path.join(CLIENT_DIR, \"summary.json\"), \"w\") as f:\n",
        "    json.dump({\"global\": summary_all, \"per_client\": per_client_summaries}, f, indent=2)\n",
        "\n",
        "print(f\"\\nSaved {N_CLIENTS} non-IID client splits and summaries to: {CLIENT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hy9_4kXHHgr"
      },
      "source": [
        "**Data Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm0V8RS9l96o"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"global\": {\n",
        "    \"name\": \"ALL\",\n",
        "    \"n\": 202,\n",
        "    \"has_tumor_counts\": {\n",
        "      \"1\": 202\n",
        "    },\n",
        "    \"size_bin_counts\": {\n",
        "      \"0\": 68,\n",
        "      \"1\": 67,\n",
        "      \"2\": 67\n",
        "    },\n",
        "    \"dom_region_top5\": {\n",
        "      \"61\": 85,\n",
        "      \"50\": 81,\n",
        "      \"0\": 10,\n",
        "      \"10\": 4,\n",
        "      \"22\": 3\n",
        "    }\n",
        "  },\n",
        "  \"per_client\": [\n",
        "    {\n",
        "      \"client\": 0,\n",
        "      \"train\": {\n",
        "        \"name\": \"client_0_train\",\n",
        "        \"n\": 35,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 35\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"1\": 32,\n",
        "          \"0\": 2,\n",
        "          \"2\": 1\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"50\": 18,\n",
        "          \"61\": 13,\n",
        "          \"7\": 1,\n",
        "          \"62\": 1,\n",
        "          \"10\": 1\n",
        "        }\n",
        "      },\n",
        "      \"val\": {\n",
        "        \"name\": \"client_0_val\",\n",
        "        \"n\": 9,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 9\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"1\": 8,\n",
        "          \"0\": 1\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"50\": 4,\n",
        "          \"61\": 3,\n",
        "          \"10\": 1,\n",
        "          \"58\": 1\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"client\": 1,\n",
        "      \"train\": {\n",
        "        \"name\": \"client_1_train\",\n",
        "        \"n\": 96,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 96\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"2\": 49,\n",
        "          \"0\": 27,\n",
        "          \"1\": 20\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"61\": 47,\n",
        "          \"50\": 34,\n",
        "          \"0\": 5,\n",
        "          \"1\": 1,\n",
        "          \"23\": 1\n",
        "        }\n",
        "      },\n",
        "      \"val\": {\n",
        "        \"name\": \"client_1_val\",\n",
        "        \"n\": 25,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 25\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"2\": 17,\n",
        "          \"0\": 4,\n",
        "          \"1\": 4\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"61\": 13,\n",
        "          \"50\": 11,\n",
        "          \"0\": 1\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"client\": 2,\n",
        "      \"train\": {\n",
        "        \"name\": \"client_2_train\",\n",
        "        \"n\": 29,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 29\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"0\": 26,\n",
        "          \"1\": 3\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"50\": 12,\n",
        "          \"61\": 8,\n",
        "          \"22\": 2,\n",
        "          \"0\": 2,\n",
        "          \"31\": 1\n",
        "        }\n",
        "      },\n",
        "      \"val\": {\n",
        "        \"name\": \"client_2_val\",\n",
        "        \"n\": 8,\n",
        "        \"has_tumor_counts\": {\n",
        "          \"1\": 8\n",
        "        },\n",
        "        \"size_bin_counts\": {\n",
        "          \"0\": 8\n",
        "        },\n",
        "        \"dom_region_top5\": {\n",
        "          \"50\": 2,\n",
        "          \"61\": 1,\n",
        "          \"10\": 1,\n",
        "          \"45\": 1,\n",
        "          \"22\": 1\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPU64UV3E4v9"
      },
      "source": [
        "# **M1 - Baseline Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkngkfhZtbvV"
      },
      "source": [
        "<h2>Train a model for each client<h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF02IxEM22gg"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/client.zip -d /content/client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6hGU2Q4FuQm"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/Preprocessed-Data.zip -d /content/Preprocessed-Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKHibbXVvLNG"
      },
      "outputs": [],
      "source": [
        "import os, json, pickle, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from sklearn.metrics import jaccard_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Paths and I/O config\n",
        "DATA_ROOT = \"/content/Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "OUT_BASE = \"AITDM\"\n",
        "CLIENT_DIR = os.path.join(OUT_BASE, \"/content/client\")\n",
        "\n",
        "# Experiment config\n",
        "USE_ATLAS = True\n",
        "CLIENT_ID = 0\n",
        "BATCH_SIZE = 8\n",
        "LR = 1e-3\n",
        "EPOCHS = 50\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "# Model / encoder config\n",
        "ENCODER_NAME = \"resnet34\"\n",
        "ENCODER_WEIGHTS = \"imagenet\"\n",
        "\n",
        "# Output directories\n",
        "OUT_MODELS_DIR = os.path.join(OUT_BASE, \"Models\", \"UNet_ImageOnly\")\n",
        "OUT_GRAPHS_DIR = os.path.join(OUT_BASE, \"Graphs\")\n",
        "os.makedirs(OUT_MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_GRAPHS_DIR, exist_ok=True)\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    \"\"\"Dataset that loads MRI, tumor mask, and optional atlas regions per patient.\"\"\"\n",
        "\n",
        "    def __init__(self, metadata_df_path, data_root, use_atlas=True, exclude_ids=None, transform=None):\n",
        "        import pickle, os, numpy as np, pandas as pd\n",
        "\n",
        "        # Load metadata dataframe\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        # Optionally exclude some patient IDs\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = [\"PatientID_0191\"]\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        # Collect patient IDs that have all required files\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            mri_p = os.path.join(self.data_root, pid, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(self.data_root, pid, f\"{pid}_tumor.npy\")\n",
        "\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(self.data_root, pid, f\"{pid}_regions.npy\")\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p) and os.path.isfile(reg_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "            else:\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        \"\"\"Simple min-max normalization to [0, 1].\"\"\"\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        return (x - mn) / (mx - mn) if mx > mn else np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Load and return one sample (dict) for a patient.\"\"\"\n",
        "        import os, numpy as np\n",
        "\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        # Load MRI and tumor mask\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "        # Normalize MRI and binarize tumor mask\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        # Optionally load regions/atlas\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "            regions = self._minmax(regions)\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "def image_only_collate_fn(batch, use_atlas=True):\n",
        "    \"\"\"Custom collate: stack MRI (+ optional regions) and tumor into tensors.\"\"\"\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        # Concatenate MRI and regions as channels\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": [it[\"patient_id\"] for it in batch]}\n",
        "\n",
        "class SubsetByPIDs(Dataset):\n",
        "    \"\"\"Wrap a dataset but keep only a subset of patient IDs.\"\"\"\n",
        "\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        # Map patient IDs to indices\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Load client-specific train/val patient IDs\n",
        "cdir = os.path.join(CLIENT_DIR, f\"client_{CLIENT_ID}\")\n",
        "with open(os.path.join(cdir, \"train_pids.json\"), \"r\") as f:\n",
        "    train_pids = json.load(f)\n",
        "with open(os.path.join(cdir, \"val_pids.json\"), \"r\") as f:\n",
        "    val_pids = json.load(f)\n",
        "\n",
        "# Build full dataset and then client subsets\n",
        "full_ds = ImageOnlyGliomaDataset(\n",
        "    METADATA_DF_PATH,\n",
        "    DATA_ROOT,\n",
        "    use_atlas=USE_ATLAS,\n",
        "    exclude_ids=[\"PatientID_0191\"],\n",
        ")\n",
        "train_dataset = SubsetByPIDs(full_ds, train_pids)\n",
        "val_dataset = SubsetByPIDs(full_ds, val_pids)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        "    worker_init_fn=worker_init_fn,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        "    worker_init_fn=worker_init_fn,\n",
        ")\n",
        "\n",
        "print(f\"Loaded client_{CLIENT_ID}: train patients={len(train_dataset)}, val patients={len(val_dataset)}\")\n",
        "\n",
        "# UNet model (from segmentation_models_pytorch)\n",
        "in_channels = 2 if USE_ATLAS else 1\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER_NAME,\n",
        "    encoder_weights=ENCODER_WEIGHTS,\n",
        "    in_channels=in_channels,\n",
        "    classes=1,\n",
        ").to(device)\n",
        "\n",
        "# Loss, optimizer, scheduler, and AMP scaler\n",
        "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer, start_factor=1.0, end_factor=0.0, total_iters=EPOCHS\n",
        ")\n",
        "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
        "\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    \"\"\"Compute Dice, IoU, and pixel accuracy.\"\"\"\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "\n",
        "    inter = (y_true * y_pred).sum()\n",
        "    dice = (2.0 * inter) / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "\n",
        "    # IoU with sklearn, fallback if it fails\n",
        "    try:\n",
        "        iou = jaccard_score(y_true, y_pred, average=\"binary\")\n",
        "    except Exception:\n",
        "        union = y_true.sum() + y_pred.sum() - inter + 1e-8\n",
        "        iou = inter / union\n",
        "\n",
        "    acc = (y_true == y_pred).mean()\n",
        "    return float(dice), float(iou), float(acc)\n",
        "\n",
        "def plot_prediction(sample_imgs, save_path):\n",
        "    \"\"\"Plot MRI (+ optional regions), GT, and prediction for one batch.\"\"\"\n",
        "    if \"regions\" in sample_imgs:\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
        "    else:\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # MRI\n",
        "    axs[0].imshow(sample_imgs[\"mri\"][0, 0], cmap=\"gray\")\n",
        "    axs[0].set_title(\"MRI\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    col = 1\n",
        "\n",
        "    # Regions (if available)\n",
        "    if \"regions\" in sample_imgs:\n",
        "        axs[col].imshow(sample_imgs[\"regions\"][0, 0], cmap=\"gray\")\n",
        "        axs[col].set_title(\"Regions\")\n",
        "        axs[col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "    # Ground truth\n",
        "    axs[col].imshow(sample_imgs[\"y_true\"][0, 0], cmap=\"gray\")\n",
        "    axs[col].set_title(\"Ground Truth\")\n",
        "    axs[col].axis(\"off\")\n",
        "    col += 1\n",
        "\n",
        "    # Prediction\n",
        "    axs[col].imshow(sample_imgs[\"y_pred\"][0, 0], cmap=\"gray\")\n",
        "    axs[col].set_title(\"Predicted\")\n",
        "    axs[col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics(history, save_path):\n",
        "    \"\"\"Plot training and validation curves for loss and metrics.\"\"\"\n",
        "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss\")\n",
        "\n",
        "    # Dice\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs, history[\"train_dice\"], label=\"Train Dice\")\n",
        "    plt.plot(epochs, history[\"val_dice\"], label=\"Val Dice\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Dice\")\n",
        "\n",
        "    # IoU\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(epochs, history[\"train_iou\"], label=\"Train IoU\")\n",
        "    plt.plot(epochs, history[\"val_iou\"], label=\"Val IoU\")\n",
        "    plt.legend()\n",
        "    plt.title(\"IoU\")\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
        "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Accuracy\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, scaler):\n",
        "    \"\"\"One training epoch over the dataloader.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Mixed precision forward pass\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n",
        "            preds = model(x)\n",
        "            loss = criterion(preds, y)\n",
        "\n",
        "        # Backward with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        # Convert predictions to binary and compute metrics\n",
        "        preds_prob = (torch.sigmoid(preds).detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (y.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, dataloader, criterion, keep_last_batch=True):\n",
        "    \"\"\"Evaluation loop over the validation dataloader.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "    last_batch_imgs = None\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        preds = model(x)\n",
        "        loss = criterion(preds, y)\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        preds_prob = (torch.sigmoid(preds).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "\n",
        "        # Optionally keep last batch for visualization\n",
        "        if keep_last_batch:\n",
        "            ch0 = x[:, 0:1].cpu().numpy()\n",
        "            imgs = {\"mri\": ch0, \"y_true\": y.cpu().numpy(), \"y_pred\": preds_prob}\n",
        "            if x.shape[1] == 2:\n",
        "                ch1 = x[:, 1:2].cpu().numpy()\n",
        "                imgs[\"regions\"] = ch1\n",
        "            last_batch_imgs = imgs\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n, last_batch_imgs\n",
        "\n",
        "def infer_and_visualize_best(\n",
        "    model,\n",
        "    val_dataset,\n",
        "    use_atlas: bool,\n",
        "    out_dir: str,\n",
        "    client_id: int,\n",
        "    best_ckpt_path: str,\n",
        "    k_samples: int = 3,\n",
        "    threshold: float = 0.5,\n",
        "):\n",
        "    \"\"\"Load best checkpoint, run inference on a few validation samples, and save visualizations.\"\"\"\n",
        "    import random\n",
        "\n",
        "    # Make sampling deterministic\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    if os.path.isfile(best_ckpt_path):\n",
        "        model.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "        model.eval()\n",
        "        print(f\"[Best Model] Loaded: {best_ckpt_path}\\n\")\n",
        "    else:\n",
        "        print(f\"[Best Model] Missing checkpoint: {best_ckpt_path}\\n\")\n",
        "        return\n",
        "\n",
        "    k = min(k_samples, len(val_dataset))\n",
        "    if k == 0:\n",
        "        print(\"[Best Model] Empty val dataset.\\n\")\n",
        "        return\n",
        "\n",
        "    # Deterministic random subset of validation indices\n",
        "    idxs = random.sample(range(len(val_dataset)), k)\n",
        "\n",
        "    def _predict_one(sample):\n",
        "        \"\"\"Run model on one sample and return inputs and binarized prediction.\"\"\"\n",
        "        mri = torch.tensor(sample[\"mri\"]).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            regs = torch.tensor(sample[\"regions\"]).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "            x = torch.cat([mri, regs], dim=1)\n",
        "        else:\n",
        "            x = mri\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prob = torch.sigmoid(model(x)).cpu().numpy()\n",
        "            pred_bin = (prob > threshold).astype(np.uint8)\n",
        "\n",
        "        return x.cpu().numpy(), pred_bin\n",
        "\n",
        "    saved_paths = []\n",
        "\n",
        "    # Save individual sample figures\n",
        "    for i, idx in enumerate(idxs, 1):\n",
        "        sample = val_dataset[idx]\n",
        "        pid = sample.get(\"patient_id\", f\"val_{idx}\")\n",
        "        x_np, pred_bin = _predict_one(sample)\n",
        "\n",
        "        imgs = {\n",
        "            \"mri\": x_np[:, 0:1],\n",
        "            \"y_true\": np.expand_dims(\n",
        "                np.expand_dims(sample[\"tumor\"], 0), 0\n",
        "            ).astype(np.float32),\n",
        "            \"y_pred\": pred_bin.astype(np.float32),\n",
        "        }\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            imgs[\"regions\"] = x_np[:, 1:2]\n",
        "\n",
        "        out_path = os.path.join(\n",
        "            out_dir, f\"best_val_sample_{i}_client{client_id}_{pid}.png\"\n",
        "        )\n",
        "        plot_prediction(imgs, out_path)\n",
        "        saved_paths.append(out_path)\n",
        "\n",
        "    print(\"[Best Model] Saved individual figures:\")\n",
        "    for p in saved_paths:\n",
        "        print(\" -\", p)\n",
        "    print()\n",
        "\n",
        "    # Save grid figure\n",
        "    cols = 4 if use_atlas else 3\n",
        "    fig, axs = plt.subplots(k, cols, figsize=(5 * cols, 4 * k))\n",
        "\n",
        "    if k == 1:\n",
        "        axs = np.expand_dims(axs, 0)\n",
        "\n",
        "    for row, idx in enumerate(idxs):\n",
        "        sample = val_dataset[idx]\n",
        "        x_np, pred_bin = _predict_one(sample)\n",
        "\n",
        "        mri = x_np[0, 0]\n",
        "        gt = sample[\"tumor\"]\n",
        "        col = 0\n",
        "\n",
        "        axs[row, col].imshow(mri, cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"MRI\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            regs = x_np[0, 1]\n",
        "            axs[row, col].imshow(regs, cmap=\"gray\")\n",
        "            axs[row, col].set_title(\"Regions\")\n",
        "            axs[row, col].axis(\"off\")\n",
        "            col += 1\n",
        "\n",
        "        axs[row, col].imshow(gt, cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"Ground Truth\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "        axs[row, col].imshow(pred_bin[0, 0], cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"Predicted (τ=0.5)\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    grid_path = os.path.join(out_dir, f\"best_model_val_grid_client{client_id}.png\")\n",
        "    plt.savefig(grid_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(f\"[Best Model] Saved grid -> {grid_path}\\n\")\n",
        "\n",
        "# History containers for training curves\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_dice\": [],\n",
        "    \"train_iou\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_dice\": [],\n",
        "    \"val_iou\": [],\n",
        "    \"val_acc\": [],\n",
        "}\n",
        "\n",
        "# Tracking best validation metrics\n",
        "best_val_iou = 0.0\n",
        "best_val_dice = -float(\"inf\")\n",
        "best_val_loss = float(\"inf\")\n",
        "best_path = os.path.join(OUT_MODELS_DIR, f\"best_unet_client{CLIENT_ID}.pth\")\n",
        "\n",
        "log_rows = []\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # Train one epoch\n",
        "    trL, trD, trI, trA = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion, scaler\n",
        "    )\n",
        "    # Validate\n",
        "    vaL, vaD, vaI, vaA, _ = eval_one_epoch(\n",
        "        model, val_loader, criterion, keep_last_batch=True\n",
        "    )\n",
        "\n",
        "    # Update scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save metrics for plots\n",
        "    history[\"train_loss\"].append(trL)\n",
        "    history[\"train_dice\"].append(trD)\n",
        "    history[\"train_iou\"].append(trI)\n",
        "    history[\"train_acc\"].append(trA)\n",
        "\n",
        "    history[\"val_loss\"].append(vaL)\n",
        "    history[\"val_dice\"].append(vaD)\n",
        "    history[\"val_iou\"].append(vaI)\n",
        "    history[\"val_acc\"].append(vaA)\n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch:03d}/{EPOCHS}] \"\n",
        "        f\"Train — Loss {trL:.4f} | Dice {trD:.4f} | IoU {trI:.4f} | Accuracy {trA:.4f} || \"\n",
        "        f\"Val — Loss {vaL:.4f} | Dice {vaD:.4f} | IoU {vaI:.4f} | Accuracy {vaA:.4f}\\n\"\n",
        "    )\n",
        "\n",
        "    # Save checkpoint if Dice improves and loss decreases\n",
        "    saved_ckpt = False\n",
        "    if (vaD > best_val_dice) and (vaL < best_val_loss):\n",
        "        best_val_dice = vaD\n",
        "        best_val_loss = vaL\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        saved_ckpt = True\n",
        "        print(\n",
        "            f\"Saved best model (Val Dice↑ {best_val_dice:.4f} & Val Loss↓ {best_val_loss:.4f}) -> {best_path}\\n\"\n",
        "        )\n",
        "\n",
        "    # Log row for CSV\n",
        "    log_rows.append(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": trL,\n",
        "            \"train_dice\": trD,\n",
        "            \"train_iou\": trI,\n",
        "            \"train_acc\": trA,\n",
        "            \"val_loss\": vaL,\n",
        "            \"val_dice\": vaD,\n",
        "            \"val_iou\": vaI,\n",
        "            \"val_acc\": vaA,\n",
        "            \"saved_ckpt\": saved_ckpt,\n",
        "            \"marker\": \"X\" if saved_ckpt else \"\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Save metrics as CSV\n",
        "metrics_csv = os.path.join(OUT_GRAPHS_DIR, f\"metrics_client{CLIENT_ID}.csv\")\n",
        "pd.DataFrame(log_rows).to_csv(metrics_csv, index=False)\n",
        "print(f\"[Log] Wrote per-epoch metrics CSV -> {metrics_csv}\\n\")\n",
        "\n",
        "# Plot training curves\n",
        "plot_metrics(history, os.path.join(OUT_GRAPHS_DIR, f\"training_curves_client{CLIENT_ID}.png\"))\n",
        "\n",
        "# Run inference with best model and visualize a few validation samples\n",
        "infer_and_visualize_best(\n",
        "    model=model,\n",
        "    val_dataset=val_dataset,\n",
        "    use_atlas=USE_ATLAS,\n",
        "    out_dir=OUT_GRAPHS_DIR,\n",
        "    client_id=CLIENT_ID,\n",
        "    best_ckpt_path=best_path,\n",
        "    k_samples=3,\n",
        "    threshold=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeATNHiwE86m"
      },
      "source": [
        "# **M1 - Federated Learning Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0BCxaFfYUhz"
      },
      "source": [
        "<h2>Federated Experiment<h2>\n",
        "\n",
        "**with Flower**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU6gtvgwWuNm"
      },
      "outputs": [],
      "source": [
        "%%writefile seg_data.py\n",
        "import os, pickle, numpy as np, torch\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Global paths and configuration\n",
        "DATA_ROOT = \"/content/Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "USE_ATLAS = True\n",
        "EXCLUDE_IDS = [\"PatientID_0191\"]\n",
        "\n",
        "# Dataset that loads MRI, tumor mask and optional atlas for each patient\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        metadata_df_path=METADATA_DF_PATH,\n",
        "        data_root=DATA_ROOT,\n",
        "        use_atlas=USE_ATLAS,\n",
        "        exclude_ids=None,\n",
        "        transform=None,\n",
        "    ):\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        # Optionally exclude specific patients\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = EXCLUDE_IDS\n",
        "\n",
        "        # Keep only non-excluded patient rows\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        # Collect patient IDs that have all required .npy files\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            base = os.path.join(self.data_root, pid)\n",
        "            mri_p = os.path.join(base, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(base, f\"{pid}_tumor.npy\")\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(base, f\"{pid}_regions.npy\")\n",
        "                ok = os.path.isfile(mri_p) and os.path.isfile(tumor_p) and os.path.isfile(reg_p)\n",
        "            else:\n",
        "                ok = os.path.isfile(mri_p) and os.path.isfile(tumor_p)\n",
        "            if ok:\n",
        "                self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    # Simple min–max normalization\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        return (x - mn) / (mx - mn) if mx > mn else np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    # Load a single sample: MRI, tumor mask, and optional atlas\n",
        "    def __getitem__(self, idx):\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "            regions = self._minmax(regions)\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "# Collate function to build batched tensors and patient ID list\n",
        "def image_only_collate_fn(batch, use_atlas=USE_ATLAS):\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": [it[\"patient_id\"] for it in batch]}\n",
        "\n",
        "# Dataset wrapper that restricts to a subset of patient IDs\n",
        "class SubsetByPIDs(Dataset):\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Compute Dice, IoU and accuracy for binary masks\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "\n",
        "    inter = (y_true & y_pred).sum()\n",
        "    dice = (2.0 * inter) / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "    union = y_true.sum() + y_pred.sum() - inter + 1e-8\n",
        "    iou = inter / union\n",
        "    acc = (y_true == y_pred).mean()\n",
        "\n",
        "    return float(dice), float(iou), float(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFmBJsv8Fr23"
      },
      "outputs": [],
      "source": [
        "%%writefile fl_client.py\n",
        "import argparse, os, json, numpy as np, torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import flwr as fl\n",
        "import copy\n",
        "import segmentation_models_pytorch as smp\n",
        "from seg_data import (\n",
        "    ImageOnlyGliomaDataset,\n",
        "    SubsetByPIDs,\n",
        "    image_only_collate_fn,\n",
        "    calc_metrics,\n",
        "    DATA_ROOT,\n",
        "    METADATA_DF_PATH,\n",
        "    USE_ATLAS,\n",
        ")\n",
        "\n",
        "# Base directory for client data splits\n",
        "CLIENT_DIR = \"/content/client\"\n",
        "\n",
        "# Data/loading config\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "# Device and model config\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "ENCODER_NAME = \"resnet34\"\n",
        "ENCODER_WEIGHTS = \"imagenet\"\n",
        "\n",
        "# Local checkpoint directory (per client best models)\n",
        "CKPT_DIR = os.path.join(\"AITDM\", \"checkpoints\")\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"Create and return a UNet segmentation model.\"\"\"\n",
        "    in_ch = 2 if USE_ATLAS else 1\n",
        "    model = smp.Unet(\n",
        "        encoder_name=ENCODER_NAME,\n",
        "        encoder_weights=ENCODER_WEIGHTS,\n",
        "        in_channels=in_ch,\n",
        "        classes=1,\n",
        "    )\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "\n",
        "def get_loaders(cid: int):\n",
        "    \"\"\"Build train/val dataloaders for a given client ID.\"\"\"\n",
        "    full = ImageOnlyGliomaDataset(\n",
        "        METADATA_DF_PATH, DATA_ROOT, use_atlas=USE_ATLAS, exclude_ids=[\"PatientID_0191\"]\n",
        "    )\n",
        "\n",
        "    # Load client-specific patient IDs\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"train_pids.json\")) as f:\n",
        "        tr_p = json.load(f)\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"val_pids.json\")) as f:\n",
        "        va_p = json.load(f)\n",
        "\n",
        "    g = torch.Generator().manual_seed(SEED)\n",
        "\n",
        "    # Subset datasets\n",
        "    ds_tr = SubsetByPIDs(full, tr_p)\n",
        "    ds_va = SubsetByPIDs(full, va_p)\n",
        "\n",
        "    # Train loader\n",
        "    ld_tr = DataLoader(\n",
        "        ds_tr,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        generator=g,\n",
        "    )\n",
        "\n",
        "    # Validation loader\n",
        "    ld_va = DataLoader(\n",
        "        ds_va,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        generator=g,\n",
        "    )\n",
        "\n",
        "    return ld_tr, ld_va, len(ds_tr), len(ds_va)\n",
        "\n",
        "\n",
        "def get_parameters(model):\n",
        "    \"\"\"Convert model parameters to a list of NumPy arrays (for Flower).\"\"\"\n",
        "    return [p.detach().cpu().numpy() for _, p in model.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(model, params):\n",
        "    \"\"\"Load model parameters from a list of NumPy arrays (from Flower).\"\"\"\n",
        "    sd = model.state_dict()\n",
        "    for k, v in zip(sd.keys(), params):\n",
        "        sd[k] = torch.tensor(v)\n",
        "    model.load_state_dict(sd, strict=True)\n",
        "\n",
        "\n",
        "# Loss functions used for combined criterion\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "dice_loss = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "\n",
        "\n",
        "def criterion(pred, y):\n",
        "    \"\"\"Hybrid loss: BCE + Dice.\"\"\"\n",
        "    return 0.5 * bce(pred, y) + 0.5 * dice_loss(pred, y)\n",
        "\n",
        "\n",
        "def maybe_save_best(cid, val_loss, val_dice, best_epoch, rnd, model):\n",
        "    \"\"\"Save best local model (per client) based on validation loss and Dice.\"\"\"\n",
        "    best_json = os.path.join(CKPT_DIR, f\"client_{cid}_best.json\")\n",
        "    best_pt = os.path.join(CKPT_DIR, f\"client_{cid}_best.pt\")\n",
        "\n",
        "    # Default previous best values\n",
        "    prev = {\"val_loss\": float(\"inf\"), \"val_dice\": -1.0}\n",
        "    if os.path.isfile(best_json):\n",
        "        try:\n",
        "            with open(best_json, \"r\") as f:\n",
        "                prev = json.load(f)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Check if current model improved both loss and Dice\n",
        "    improved = (val_loss < prev.get(\"val_loss\", float(\"inf\"))) and (\n",
        "        val_dice > prev.get(\"val_dice\", -1.0)\n",
        "    )\n",
        "\n",
        "    if improved:\n",
        "        # Save state dict and metadata\n",
        "        torch.save(model.state_dict(), best_pt)\n",
        "        with open(best_json, \"w\") as f:\n",
        "            json.dump(\n",
        "                {\n",
        "                    \"round\": int(rnd),\n",
        "                    \"epoch\": int(best_epoch),\n",
        "                    \"val_loss\": float(val_loss),\n",
        "                    \"val_dice\": float(val_dice),\n",
        "                },\n",
        "                f,\n",
        "            )\n",
        "\n",
        "\n",
        "class SegClient(fl.client.NumPyClient):\n",
        "    \"\"\"Flower NumPyClient for federated glioma segmentation.\"\"\"\n",
        "\n",
        "    def __init__(self, cid: int):\n",
        "        self.cid = cid\n",
        "        self.model = get_model()\n",
        "        self.train_loader, self.val_loader, self.ntr, self.nva = get_loaders(cid)\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        \"\"\"Return current local model parameters.\"\"\"\n",
        "        return get_parameters(self.model)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"Local training for a number of epochs, then return updated parameters and metrics.\"\"\"\n",
        "        # Load global parameters\n",
        "        set_parameters(self.model, parameters)\n",
        "\n",
        "        # Read fit configuration from server\n",
        "        epochs = int(config.get(\"local_epochs\", 1))\n",
        "        lr = float(config.get(\"lr\", 1e-3))\n",
        "        rnd = int(config.get(\"round\", 0))\n",
        "\n",
        "        # Optimizer and AMP scaler\n",
        "        opt = optim.AdamW(self.model.parameters(), lr=lr)\n",
        "        scaler = torch.amp.GradScaler(\"cuda\", enabled=(DEVICE.type == \"cuda\"))\n",
        "\n",
        "        # Track best validation performance\n",
        "        best_state = None\n",
        "        best_val_loss = float(\"inf\")\n",
        "        best_val_dice = -1.0\n",
        "        best_epoch_idx = -1\n",
        "\n",
        "        # Track best train metrics for that epoch (optional, for debugging)\n",
        "        best_train_loss = float(\"inf\")\n",
        "        best_train_dice = -1.0\n",
        "        best_train_iou = 0.0\n",
        "        best_train_acc = 0.0\n",
        "\n",
        "        # Per-epoch logs (will be sent to server)\n",
        "        epoch_logs = []\n",
        "\n",
        "        for epoch_idx in range(1, epochs + 1):\n",
        "            # ----- Training phase -----\n",
        "            self.model.train()\n",
        "            tot_tr_loss = tot_tr_d = tot_tr_i = tot_tr_a = 0.0\n",
        "            nb_tr = 0\n",
        "\n",
        "            for batch in self.train_loader:\n",
        "                x = batch[\"x\"].to(DEVICE)\n",
        "                y = batch[\"y\"].to(DEVICE)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "\n",
        "                # Forward pass with mixed precision\n",
        "                with torch.amp.autocast(\"cuda\", enabled=(DEVICE.type == \"cuda\")):\n",
        "                    pred = self.model(x)\n",
        "                    loss = criterion(pred, y)\n",
        "\n",
        "                # Backward pass and optimizer step\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "\n",
        "                # Compute train metrics on this batch\n",
        "                with torch.no_grad():\n",
        "                    y_hat = (torch.sigmoid(pred).detach().cpu().numpy() > 0.5).astype(\n",
        "                        np.uint8\n",
        "                    )\n",
        "                    y_np = (y.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                tot_tr_loss += float(loss.item())\n",
        "                tot_tr_d += d\n",
        "                tot_tr_i += i\n",
        "                tot_tr_a += a\n",
        "                nb_tr += 1\n",
        "\n",
        "            nb_tr = max(nb_tr, 1)\n",
        "            epoch_tr_loss = tot_tr_loss / nb_tr\n",
        "            epoch_tr_dice = tot_tr_d / nb_tr\n",
        "            epoch_tr_iou = tot_tr_i / nb_tr\n",
        "            epoch_tr_acc = tot_tr_a / nb_tr\n",
        "\n",
        "            # ----- Validation phase -----\n",
        "            self.model.eval()\n",
        "            tot_val_loss = tot_val_d = tot_val_i = tot_val_a = 0.0\n",
        "            nb_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in self.val_loader:\n",
        "                    x = batch[\"x\"].to(DEVICE)\n",
        "                    y = batch[\"y\"].to(DEVICE)\n",
        "                    pred = self.model(x)\n",
        "\n",
        "                    v_loss = float(criterion(pred, y).item())\n",
        "                    y_hat = (torch.sigmoid(pred).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                    tot_val_loss += v_loss\n",
        "                    tot_val_d += d\n",
        "                    tot_val_i += i\n",
        "                    tot_val_a += a\n",
        "                    nb_val += 1\n",
        "\n",
        "            nb_val = max(nb_val, 1)\n",
        "            epoch_val_loss = tot_val_loss / nb_val\n",
        "            epoch_val_dice = tot_val_d / nb_val\n",
        "            epoch_val_iou = tot_val_i / nb_val\n",
        "            epoch_val_acc = tot_val_a / nb_val\n",
        "\n",
        "            # Log per-epoch metrics\n",
        "            epoch_logs.append(\n",
        "                {\n",
        "                    \"epoch\": int(epoch_idx),\n",
        "                    \"train_loss\": float(epoch_tr_loss),\n",
        "                    \"train_dice\": float(epoch_tr_dice),\n",
        "                    \"train_iou\": float(epoch_tr_iou),\n",
        "                    \"train_acc\": float(epoch_tr_acc),\n",
        "                    \"val_loss\": float(epoch_val_loss),\n",
        "                    \"val_dice\": float(epoch_val_dice),\n",
        "                    \"val_iou\": float(epoch_val_iou),\n",
        "                    \"val_acc\": float(epoch_val_acc),\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Update best model based on validation metrics\n",
        "            if (epoch_val_loss < best_val_loss) and (epoch_val_dice > best_val_dice):\n",
        "                best_val_loss = epoch_val_loss\n",
        "                best_val_dice = epoch_val_dice\n",
        "                best_state = copy.deepcopy(self.model.state_dict())\n",
        "                best_epoch_idx = epoch_idx\n",
        "\n",
        "                best_train_loss = epoch_tr_loss\n",
        "                best_train_dice = epoch_tr_dice\n",
        "                best_train_iou = epoch_tr_iou\n",
        "                best_train_acc = epoch_tr_acc\n",
        "\n",
        "        # Load best local model state if available\n",
        "        if best_state is not None:\n",
        "            self.model.load_state_dict(best_state)\n",
        "\n",
        "        # Mark best epoch inside logs\n",
        "        for ep in epoch_logs:\n",
        "            ep[\"best_epoch\"] = (ep[\"epoch\"] == best_epoch_idx)\n",
        "\n",
        "        # Metrics sent back to server\n",
        "        train_metrics = {\n",
        "            \"cid\": int(self.cid),\n",
        "            \"best_epoch\": int(best_epoch_idx),\n",
        "            \"best_val_loss\": float(best_val_loss),\n",
        "            \"best_val_dice\": float(best_val_dice),\n",
        "            \"per_epoch\": json.dumps(epoch_logs),\n",
        "        }\n",
        "\n",
        "        # Save best local checkpoint\n",
        "        maybe_save_best(self.cid, best_val_loss, best_val_dice, best_epoch_idx, rnd, self.model)\n",
        "\n",
        "        # Return updated parameters, number of train examples, and metrics\n",
        "        return get_parameters(self.model), self.ntr, train_metrics\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        \"\"\"Evaluate global parameters on local validation set.\"\"\"\n",
        "        # Load global parameters\n",
        "        set_parameters(self.model, parameters)\n",
        "        self.model.eval()\n",
        "\n",
        "        tot_loss = tot_d = tot_i = tot_a = 0.0\n",
        "        nb = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_loader:\n",
        "                x = batch[\"x\"].to(DEVICE)\n",
        "                y = batch[\"y\"].to(DEVICE)\n",
        "                pred = self.model(x)\n",
        "\n",
        "                loss = float(criterion(pred, y).item())\n",
        "                y_hat = (torch.sigmoid(pred).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                tot_loss += loss\n",
        "                tot_d += d\n",
        "                tot_i += i\n",
        "                tot_a += a\n",
        "                nb += 1\n",
        "\n",
        "        nb = max(nb, 1)\n",
        "        metrics = {\n",
        "            \"loss\": tot_loss / nb,\n",
        "            \"dice\": tot_d / nb,\n",
        "            \"iou\": tot_i / nb,\n",
        "            \"acc\": tot_a / nb,\n",
        "            \"cid\": int(self.cid),\n",
        "        }\n",
        "\n",
        "        # Flower expects (loss, num_examples, metrics)\n",
        "        return metrics[\"loss\"], self.nva, metrics\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Standalone client entry point (for non-simulation setups)\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--cid\", type=int, required=True)\n",
        "    parser.add_argument(\"--server\", default=\"0.0.0.0:8080\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(f\"[SegClient {args.cid}] device={DEVICE}, cuda={torch.cuda.is_available()}\")\n",
        "\n",
        "    fl.client.start_numpy_client(\n",
        "        server_address=args.server,\n",
        "        client=SegClient(args.cid),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZxs3HOEF4Wj"
      },
      "outputs": [],
      "source": [
        "%%writefile fl_sim_colab.py\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import torch\n",
        "import flwr as fl\n",
        "from flwr.common import FitIns\n",
        "from fl_client import SegClient\n",
        "\n",
        "# Base directory for outputs\n",
        "BASE_DIR = \"AITDM\"\n",
        "# Directory where per-client metrics will be saved\n",
        "METRICS_DIR = os.path.join(BASE_DIR, \"metrics\")\n",
        "os.makedirs(METRICS_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def client_fn(cid: str):\n",
        "    \"\"\"Create a Flower client for a given client ID.\"\"\"\n",
        "    return SegClient(int(cid)).to_client()\n",
        "\n",
        "\n",
        "def ensure_csv(path: str, header: list[str]):\n",
        "    \"\"\"Create a CSV file with header if it does not exist.\"\"\"\n",
        "    if not os.path.isfile(path):\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, \"w\", newline=\"\") as f:\n",
        "            csv.writer(f).writerow(header)\n",
        "\n",
        "\n",
        "def append_row(path: str, row: list):\n",
        "    \"\"\"Append a single row to a CSV file.\"\"\"\n",
        "    with open(path, \"a\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow(row)\n",
        "\n",
        "\n",
        "class PerClientLoggingFedAvg(fl.server.strategy.FedAvg):\n",
        "    \"\"\"Custom FedAvg strategy that logs per-client metrics to CSV.\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        # CSV header for logged metrics\n",
        "        self.header = [\n",
        "            \"round\",\n",
        "            \"epoch\",\n",
        "            \"train_loss\",\n",
        "            \"train_dice\",\n",
        "            \"train_iou\",\n",
        "            \"train_acc\",\n",
        "            \"val_loss\",\n",
        "            \"val_dice\",\n",
        "            \"val_iou\",\n",
        "            \"val_acc\",\n",
        "            \"best_epoch\",\n",
        "        ]\n",
        "\n",
        "    def configure_fit(self, server_round, parameters, client_manager):\n",
        "        \"\"\"Inject current round number into fit configuration for each client.\"\"\"\n",
        "        items = super().configure_fit(server_round, parameters, client_manager)\n",
        "        out = []\n",
        "        for it in items:\n",
        "            if isinstance(it, tuple):\n",
        "                client, fitins = it\n",
        "            else:\n",
        "                client, fitins = None, it\n",
        "\n",
        "            cfg = dict(fitins.config)\n",
        "            cfg[\"round\"] = server_round\n",
        "            new_fitins = FitIns(fitins.parameters, cfg)\n",
        "\n",
        "            out.append((client, new_fitins) if client is not None else new_fitins)\n",
        "        return out\n",
        "\n",
        "    def aggregate_fit(self, rnd, results, failures):\n",
        "        \"\"\"Aggregate fit results and log per-epoch metrics for each client.\"\"\"\n",
        "        agg = super().aggregate_fit(rnd, results, failures)\n",
        "\n",
        "        for client_proxy, fit_res in results:\n",
        "            m = fit_res.metrics or {}\n",
        "            cid = str(m.get(\"cid\", client_proxy.cid))\n",
        "\n",
        "            client_csv = os.path.join(METRICS_DIR, f\"metrics_client_{cid}.csv\")\n",
        "            ensure_csv(client_csv, self.header)\n",
        "\n",
        "            best_epoch = int(m.get(\"best_epoch\", -1))\n",
        "            per_epoch_raw = m.get(\"per_epoch\", \"[]\")\n",
        "\n",
        "            # Parse per-epoch metrics sent from the client\n",
        "            try:\n",
        "                per_epoch = json.loads(per_epoch_raw)\n",
        "            except Exception:\n",
        "                per_epoch = []\n",
        "\n",
        "            # Write one row per local epoch\n",
        "            for ep in per_epoch:\n",
        "                epoch = ep.get(\"epoch\", \"\")\n",
        "                row = [\n",
        "                    rnd,\n",
        "                    epoch,\n",
        "                    ep.get(\"train_loss\", \"\"),\n",
        "                    ep.get(\"train_dice\", \"\"),\n",
        "                    ep.get(\"train_iou\", \"\"),\n",
        "                    ep.get(\"train_acc\", \"\"),\n",
        "                    ep.get(\"val_loss\", \"\"),\n",
        "                    ep.get(\"val_dice\", \"\"),\n",
        "                    ep.get(\"val_iou\", \"\"),\n",
        "                    ep.get(\"val_acc\", \"\"),\n",
        "                    \"x\" if int(epoch) == best_epoch else \"\",\n",
        "                ]\n",
        "                append_row(client_csv, row)\n",
        "\n",
        "        return agg\n",
        "\n",
        "\n",
        "# Federated learning strategy configuration\n",
        "strategy = PerClientLoggingFedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=1.0,\n",
        "    min_fit_clients=3,\n",
        "    min_evaluate_clients=3,\n",
        "    min_available_clients=3,\n",
        "    on_fit_config_fn=lambda rnd: {\"local_epochs\": 5, \"lr\": 1e-3},\n",
        ")\n",
        "\n",
        "# Resource configuration (GPU if available)\n",
        "use_gpu = torch.cuda.is_available()\n",
        "client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0 if use_gpu else 0.0}\n",
        "\n",
        "# Start Flower simulation with 3 clients and 5 communication rounds\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=3,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        "    ray_init_args={\"include_dashboard\": False},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3dlt740MYbP"
      },
      "outputs": [],
      "source": [
        "!python fl_sim_colab.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzRm-EHu8iCx"
      },
      "source": [
        "# **M2 - Clip Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA8ci1ByLTbg"
      },
      "source": [
        "**We train UNet for tumor segmentation, train BioClinicalBERT for region prediction in reports, then train a multimodal CLIP-like model that aligns text–image embeddings and, simultaneously, preserves segmentation through a combined loss.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9EatFoMKv7p"
      },
      "source": [
        "**<h2>UNet on images<h2>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwxW3U1PKUbv"
      },
      "outputs": [],
      "source": [
        "import os, json, pickle, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from sklearn.metrics import jaccard_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Paths and I/O config\n",
        "DATA_ROOT = \"/content/Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "OUT_BASE = \"AITDM\"\n",
        "CLIENT_DIR = os.path.join(OUT_BASE, \"/content/client\")\n",
        "\n",
        "# Experiment config\n",
        "USE_ATLAS = True\n",
        "CLIENT_ID = 0\n",
        "BATCH_SIZE = 8\n",
        "LR = 1e-3\n",
        "EPOCHS = 50\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "# Model / encoder config\n",
        "ENCODER_NAME = \"resnet34\"\n",
        "ENCODER_WEIGHTS = \"imagenet\"\n",
        "\n",
        "# Output directories\n",
        "OUT_MODELS_DIR = os.path.join(OUT_BASE, \"Models\", \"UNet_ImageOnly\")\n",
        "OUT_GRAPHS_DIR = os.path.join(OUT_BASE, \"Graphs\")\n",
        "os.makedirs(OUT_MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_GRAPHS_DIR, exist_ok=True)\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    \"\"\"Dataset that loads MRI, tumor mask, and optional atlas regions per patient.\"\"\"\n",
        "\n",
        "    def __init__(self, metadata_df_path, data_root, use_atlas=True, exclude_ids=None, transform=None):\n",
        "        import pickle, os, numpy as np, pandas as pd\n",
        "\n",
        "        # Load metadata dataframe\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        # Optionally exclude some patient IDs\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = [\"PatientID_0191\"]\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        # Collect patient IDs that have all required files\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            mri_p = os.path.join(self.data_root, pid, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(self.data_root, pid, f\"{pid}_tumor.npy\")\n",
        "\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(self.data_root, pid, f\"{pid}_regions.npy\")\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p) and os.path.isfile(reg_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "            else:\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        \"\"\"Simple min-max normalization to [0, 1].\"\"\"\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        return (x - mn) / (mx - mn) if mx > mn else np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Load and return one sample (dict) for a patient.\"\"\"\n",
        "        import os, numpy as np\n",
        "\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        # Load MRI and tumor mask\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "        # Normalize MRI and binarize tumor mask\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        # Optionally load regions/atlas\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "            regions = self._minmax(regions)\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "def image_only_collate_fn(batch, use_atlas=True):\n",
        "    \"\"\"Custom collate: stack MRI (+ optional regions) and tumor into tensors.\"\"\"\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        # Concatenate MRI and regions as channels\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": [it[\"patient_id\"] for it in batch]}\n",
        "\n",
        "class SubsetByPIDs(Dataset):\n",
        "    \"\"\"Wrap a dataset but keep only a subset of patient IDs.\"\"\"\n",
        "\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        # Map patient IDs to indices\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Load client-specific train/val patient IDs\n",
        "cdir = os.path.join(CLIENT_DIR, f\"client_{CLIENT_ID}\")\n",
        "with open(os.path.join(cdir, \"train_pids.json\"), \"r\") as f:\n",
        "    train_pids = json.load(f)\n",
        "with open(os.path.join(cdir, \"val_pids.json\"), \"r\") as f:\n",
        "    val_pids = json.load(f)\n",
        "\n",
        "# Build full dataset and then client subsets\n",
        "full_ds = ImageOnlyGliomaDataset(\n",
        "    METADATA_DF_PATH,\n",
        "    DATA_ROOT,\n",
        "    use_atlas=USE_ATLAS,\n",
        "    exclude_ids=[\"PatientID_0191\"],\n",
        ")\n",
        "train_dataset = SubsetByPIDs(full_ds, train_pids)\n",
        "val_dataset = SubsetByPIDs(full_ds, val_pids)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        "    worker_init_fn=worker_init_fn,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        "    worker_init_fn=worker_init_fn,\n",
        ")\n",
        "\n",
        "print(f\"Loaded client_{CLIENT_ID}: train patients={len(train_dataset)}, val patients={len(val_dataset)}\")\n",
        "\n",
        "# UNet model (from segmentation_models_pytorch)\n",
        "in_channels = 2 if USE_ATLAS else 1\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER_NAME,\n",
        "    encoder_weights=ENCODER_WEIGHTS,\n",
        "    in_channels=in_channels,\n",
        "    classes=1,\n",
        ").to(device)\n",
        "\n",
        "# Loss, optimizer, scheduler, and AMP scaler\n",
        "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer, start_factor=1.0, end_factor=0.0, total_iters=EPOCHS\n",
        ")\n",
        "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
        "\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    \"\"\"Compute Dice, IoU, and pixel accuracy.\"\"\"\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "\n",
        "    inter = (y_true * y_pred).sum()\n",
        "    dice = (2.0 * inter) / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "\n",
        "    # IoU with sklearn, fallback if it fails\n",
        "    try:\n",
        "        iou = jaccard_score(y_true, y_pred, average=\"binary\")\n",
        "    except Exception:\n",
        "        union = y_true.sum() + y_pred.sum() - inter + 1e-8\n",
        "        iou = inter / union\n",
        "\n",
        "    acc = (y_true == y_pred).mean()\n",
        "    return float(dice), float(iou), float(acc)\n",
        "\n",
        "def plot_prediction(sample_imgs, save_path):\n",
        "    \"\"\"Plot MRI (+ optional regions), GT, and prediction for one batch.\"\"\"\n",
        "    if \"regions\" in sample_imgs:\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
        "    else:\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # MRI\n",
        "    axs[0].imshow(sample_imgs[\"mri\"][0, 0], cmap=\"gray\")\n",
        "    axs[0].set_title(\"MRI\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    col = 1\n",
        "\n",
        "    # Regions (if available)\n",
        "    if \"regions\" in sample_imgs:\n",
        "        axs[col].imshow(sample_imgs[\"regions\"][0, 0], cmap=\"gray\")\n",
        "        axs[col].set_title(\"Regions\")\n",
        "        axs[col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "    # Ground truth\n",
        "    axs[col].imshow(sample_imgs[\"y_true\"][0, 0], cmap=\"gray\")\n",
        "    axs[col].set_title(\"Ground Truth\")\n",
        "    axs[col].axis(\"off\")\n",
        "    col += 1\n",
        "\n",
        "    # Prediction\n",
        "    axs[col].imshow(sample_imgs[\"y_pred\"][0, 0], cmap=\"gray\")\n",
        "    axs[col].set_title(\"Predicted\")\n",
        "    axs[col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics(history, save_path):\n",
        "    \"\"\"Plot training and validation curves for loss and metrics.\"\"\"\n",
        "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss\")\n",
        "\n",
        "    # Dice\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs, history[\"train_dice\"], label=\"Train Dice\")\n",
        "    plt.plot(epochs, history[\"val_dice\"], label=\"Val Dice\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Dice\")\n",
        "\n",
        "    # IoU\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(epochs, history[\"train_iou\"], label=\"Train IoU\")\n",
        "    plt.plot(epochs, history[\"val_iou\"], label=\"Val IoU\")\n",
        "    plt.legend()\n",
        "    plt.title(\"IoU\")\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
        "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Accuracy\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, scaler):\n",
        "    \"\"\"One training epoch over the dataloader.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Mixed precision forward pass\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n",
        "            preds = model(x)\n",
        "            loss = criterion(preds, y)\n",
        "\n",
        "        # Backward with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        # Convert predictions to binary and compute metrics\n",
        "        preds_prob = (torch.sigmoid(preds).detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (y.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, dataloader, criterion, keep_last_batch=True):\n",
        "    \"\"\"Evaluation loop over the validation dataloader.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "    last_batch_imgs = None\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        preds = model(x)\n",
        "        loss = criterion(preds, y)\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        preds_prob = (torch.sigmoid(preds).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "\n",
        "        # Optionally keep last batch for visualization\n",
        "        if keep_last_batch:\n",
        "            ch0 = x[:, 0:1].cpu().numpy()\n",
        "            imgs = {\"mri\": ch0, \"y_true\": y.cpu().numpy(), \"y_pred\": preds_prob}\n",
        "            if x.shape[1] == 2:\n",
        "                ch1 = x[:, 1:2].cpu().numpy()\n",
        "                imgs[\"regions\"] = ch1\n",
        "            last_batch_imgs = imgs\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n, last_batch_imgs\n",
        "\n",
        "def infer_and_visualize_best(\n",
        "    model,\n",
        "    val_dataset,\n",
        "    use_atlas: bool,\n",
        "    out_dir: str,\n",
        "    client_id: int,\n",
        "    best_ckpt_path: str,\n",
        "    k_samples: int = 3,\n",
        "    threshold: float = 0.5,\n",
        "):\n",
        "    \"\"\"Load best checkpoint, run inference on a few validation samples, and save visualizations.\"\"\"\n",
        "    import random\n",
        "\n",
        "    # Make sampling deterministic\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    if os.path.isfile(best_ckpt_path):\n",
        "        model.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "        model.eval()\n",
        "        print(f\"[Best Model] Loaded: {best_ckpt_path}\\n\")\n",
        "    else:\n",
        "        print(f\"[Best Model] Missing checkpoint: {best_ckpt_path}\\n\")\n",
        "        return\n",
        "\n",
        "    k = min(k_samples, len(val_dataset))\n",
        "    if k == 0:\n",
        "        print(\"[Best Model] Empty val dataset.\\n\")\n",
        "        return\n",
        "\n",
        "    # Deterministic random subset of validation indices\n",
        "    idxs = random.sample(range(len(val_dataset)), k)\n",
        "\n",
        "    def _predict_one(sample):\n",
        "        \"\"\"Run model on one sample and return inputs and binarized prediction.\"\"\"\n",
        "        mri = torch.tensor(sample[\"mri\"]).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            regs = torch.tensor(sample[\"regions\"]).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "            x = torch.cat([mri, regs], dim=1)\n",
        "        else:\n",
        "            x = mri\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prob = torch.sigmoid(model(x)).cpu().numpy()\n",
        "            pred_bin = (prob > threshold).astype(np.uint8)\n",
        "\n",
        "        return x.cpu().numpy(), pred_bin\n",
        "\n",
        "    saved_paths = []\n",
        "\n",
        "    # Save individual sample figures\n",
        "    for i, idx in enumerate(idxs, 1):\n",
        "        sample = val_dataset[idx]\n",
        "        pid = sample.get(\"patient_id\", f\"val_{idx}\")\n",
        "        x_np, pred_bin = _predict_one(sample)\n",
        "\n",
        "        imgs = {\n",
        "            \"mri\": x_np[:, 0:1],\n",
        "            \"y_true\": np.expand_dims(\n",
        "                np.expand_dims(sample[\"tumor\"], 0), 0\n",
        "            ).astype(np.float32),\n",
        "            \"y_pred\": pred_bin.astype(np.float32),\n",
        "        }\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            imgs[\"regions\"] = x_np[:, 1:2]\n",
        "\n",
        "        out_path = os.path.join(\n",
        "            out_dir, f\"best_val_sample_{i}_client{client_id}_{pid}.png\"\n",
        "        )\n",
        "        plot_prediction(imgs, out_path)\n",
        "        saved_paths.append(out_path)\n",
        "\n",
        "    print(\"[Best Model] Saved individual figures:\")\n",
        "    for p in saved_paths:\n",
        "        print(\" -\", p)\n",
        "    print()\n",
        "\n",
        "    # Save grid figure\n",
        "    cols = 4 if use_atlas else 3\n",
        "    fig, axs = plt.subplots(k, cols, figsize=(5 * cols, 4 * k))\n",
        "\n",
        "    if k == 1:\n",
        "        axs = np.expand_dims(axs, 0)\n",
        "\n",
        "    for row, idx in enumerate(idxs):\n",
        "        sample = val_dataset[idx]\n",
        "        x_np, pred_bin = _predict_one(sample)\n",
        "\n",
        "        mri = x_np[0, 0]\n",
        "        gt = sample[\"tumor\"]\n",
        "        col = 0\n",
        "\n",
        "        axs[row, col].imshow(mri, cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"MRI\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            regs = x_np[0, 1]\n",
        "            axs[row, col].imshow(regs, cmap=\"gray\")\n",
        "            axs[row, col].set_title(\"Regions\")\n",
        "            axs[row, col].axis(\"off\")\n",
        "            col += 1\n",
        "\n",
        "        axs[row, col].imshow(gt, cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"Ground Truth\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "        axs[row, col].imshow(pred_bin[0, 0], cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"Predicted (τ=0.5)\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    grid_path = os.path.join(out_dir, f\"best_model_val_grid_client{client_id}.png\")\n",
        "    plt.savefig(grid_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(f\"[Best Model] Saved grid -> {grid_path}\\n\")\n",
        "\n",
        "# History containers for training curves\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_dice\": [],\n",
        "    \"train_iou\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_dice\": [],\n",
        "    \"val_iou\": [],\n",
        "    \"val_acc\": [],\n",
        "}\n",
        "\n",
        "# Tracking best validation metrics\n",
        "best_val_iou = 0.0\n",
        "best_val_dice = -float(\"inf\")\n",
        "best_val_loss = float(\"inf\")\n",
        "best_path = os.path.join(OUT_MODELS_DIR, f\"best_unet_client{CLIENT_ID}.pth\")\n",
        "\n",
        "log_rows = []\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # Train one epoch\n",
        "    trL, trD, trI, trA = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion, scaler\n",
        "    )\n",
        "    # Validate\n",
        "    vaL, vaD, vaI, vaA, _ = eval_one_epoch(\n",
        "        model, val_loader, criterion, keep_last_batch=True\n",
        "    )\n",
        "\n",
        "    # Update scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save metrics for plots\n",
        "    history[\"train_loss\"].append(trL)\n",
        "    history[\"train_dice\"].append(trD)\n",
        "    history[\"train_iou\"].append(trI)\n",
        "    history[\"train_acc\"].append(trA)\n",
        "\n",
        "    history[\"val_loss\"].append(vaL)\n",
        "    history[\"val_dice\"].append(vaD)\n",
        "    history[\"val_iou\"].append(vaI)\n",
        "    history[\"val_acc\"].append(vaA)\n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch:03d}/{EPOCHS}] \"\n",
        "        f\"Train — Loss {trL:.4f} | Dice {trD:.4f} | IoU {trI:.4f} | Accuracy {trA:.4f} || \"\n",
        "        f\"Val — Loss {vaL:.4f} | Dice {vaD:.4f} | IoU {vaI:.4f} | Accuracy {vaA:.4f}\\n\"\n",
        "    )\n",
        "\n",
        "    # Save checkpoint if Dice improves and loss decreases\n",
        "    saved_ckpt = False\n",
        "    if (vaD > best_val_dice) and (vaL < best_val_loss):\n",
        "        best_val_dice = vaD\n",
        "        best_val_loss = vaL\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        saved_ckpt = True\n",
        "        print(\n",
        "            f\"Saved best model (Val Dice↑ {best_val_dice:.4f} & Val Loss↓ {best_val_loss:.4f}) -> {best_path}\\n\"\n",
        "        )\n",
        "\n",
        "    # Log row for CSV\n",
        "    log_rows.append(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": trL,\n",
        "            \"train_dice\": trD,\n",
        "            \"train_iou\": trI,\n",
        "            \"train_acc\": trA,\n",
        "            \"val_loss\": vaL,\n",
        "            \"val_dice\": vaD,\n",
        "            \"val_iou\": vaI,\n",
        "            \"val_acc\": vaA,\n",
        "            \"saved_ckpt\": saved_ckpt,\n",
        "            \"marker\": \"X\" if saved_ckpt else \"\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Save metrics as CSV\n",
        "metrics_csv = os.path.join(OUT_GRAPHS_DIR, f\"metrics_client{CLIENT_ID}.csv\")\n",
        "pd.DataFrame(log_rows).to_csv(metrics_csv, index=False)\n",
        "print(f\"[Log] Wrote per-epoch metrics CSV -> {metrics_csv}\\n\")\n",
        "\n",
        "# Plot training curves\n",
        "plot_metrics(history, os.path.join(OUT_GRAPHS_DIR, f\"training_curves_client{CLIENT_ID}.png\"))\n",
        "\n",
        "# Run inference with best model and visualize a few validation samples\n",
        "infer_and_visualize_best(\n",
        "    model=model,\n",
        "    val_dataset=val_dataset,\n",
        "    use_atlas=USE_ATLAS,\n",
        "    out_dir=OUT_GRAPHS_DIR,\n",
        "    client_id=CLIENT_ID,\n",
        "    best_ckpt_path=best_path,\n",
        "    k_samples=3,\n",
        "    threshold=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKYalDg9K4tg"
      },
      "source": [
        "**<h2>BioClinicalBERT on reports<h2>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtOH3OE4UST0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import random\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "\n",
        "warnings.simplefilter(\"ignore\", category=UndefinedMetricWarning)\n",
        "\n",
        "# ---- Reproducibility ----\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "# ---- Paths / Config ----\n",
        "METADATA_DF_PATH = \"/content/cleaned_df.pkl\"\n",
        "LABELS_PATH = \"/content/labels_list.pkl\"\n",
        "OUT_BASE = \"/content/AITDM\"\n",
        "CLIENT_BASE_DIR = \"/content/client\"\n",
        "\n",
        "CLIENT_ID = 0\n",
        "BATCH_SIZE = 8\n",
        "LR = 2e-5\n",
        "EPOCHS = 20\n",
        "NUM_WORKERS = 2\n",
        "MAX_LEN = 512\n",
        "WARMUP_RATIO = 0.1\n",
        "\n",
        "BERT_MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "DROPOUT = 0.3\n",
        "\n",
        "TOPK_PRED = 5\n",
        "USE_POS_WEIGHT = True\n",
        "REMOVE_BACKGROUND_LABEL = True\n",
        "\n",
        "OUT_MODELS_DIR = os.path.join(OUT_BASE, \"Models\", \"BioClinicalBert\")\n",
        "OUT_GRAPHS_DIR = os.path.join(OUT_BASE, \"Graphs\")\n",
        "os.makedirs(OUT_MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_GRAPHS_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "\n",
        "def worker_init_fn(worker_id: int) -> None:\n",
        "    s = SEED + worker_id\n",
        "    random.seed(s)\n",
        "    np.random.seed(s)\n",
        "\n",
        "\n",
        "set_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class ReportsGliomaDataset(Dataset):\n",
        "    \"\"\"Multi-label dataset: report text -> set of region labels.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        metadata_df_path: str,\n",
        "        labels_path: str,\n",
        "        exclude_ids: Optional[List[str]] = None,\n",
        "        remove_background: bool = False,\n",
        "    ):\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        with open(labels_path, \"rb\") as f:\n",
        "            labels = list(pickle.load(f))\n",
        "\n",
        "        if remove_background:\n",
        "            labels = [l for l in labels if str(l).strip().lower() != \"background\"]\n",
        "\n",
        "        self.labels: List[str] = labels\n",
        "        self.label_to_idx: Dict[str, int] = {lab: i for i, lab in enumerate(self.labels)}\n",
        "\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = [\"PatientID_0191\"]\n",
        "\n",
        "        df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "        df = df[df[\"Report\"].notna() & df[\"Top 5 Regions\"].notna()].reset_index(drop=True)\n",
        "\n",
        "        self.df = df\n",
        "        self.patient_ids = df[\"Patient_ID\"].tolist()\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    def _make_multilabel_target(self, regions_list) -> np.ndarray:\n",
        "        y = np.zeros(len(self.labels), dtype=np.float32)\n",
        "        if not isinstance(regions_list, (list, tuple)):\n",
        "            return y\n",
        "        for reg in regions_list:\n",
        "            idx = self.label_to_idx.get(reg, None)\n",
        "            if idx is not None:\n",
        "                y[idx] = 1.0\n",
        "        return y\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, object]:\n",
        "        row = self.df.iloc[idx]\n",
        "        pid = row[\"Patient_ID\"]\n",
        "        report = str(row[\"Report\"])\n",
        "        top5 = row[\"Top 5 Regions\"]\n",
        "        target = self._make_multilabel_target(top5)\n",
        "        return {\"patient_id\": pid, \"report\": report, \"target\": target}\n",
        "\n",
        "\n",
        "class SubsetByPIDs(Dataset):\n",
        "    \"\"\"Filter a dataset by a provided list of patient IDs.\"\"\"\n",
        "\n",
        "    def __init__(self, full_dataset: ReportsGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i: int) -> Dict[str, object]:\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "\n",
        "def reports_collate_fn(batch: List[Dict[str, object]]) -> Dict[str, object]:\n",
        "    reports = [b[\"report\"] for b in batch]\n",
        "    targets = torch.from_numpy(np.stack([b[\"target\"] for b in batch])).float()\n",
        "    pids = [b[\"patient_id\"] for b in batch]\n",
        "    return {\"report\": reports, \"target\": targets, \"pid\": pids}\n",
        "\n",
        "\n",
        "class BioBERTMultiLabelClassifier(nn.Module):\n",
        "    \"\"\"BioClinicalBERT + linear head for multi-label prediction.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str, num_labels: int, dropout: float = 0.3):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled = outputs.pooler_output\n",
        "        if pooled is None:\n",
        "            pooled = outputs.last_hidden_state[:, 0]  # CLS\n",
        "        x = self.dropout(pooled)\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
        "\n",
        "\n",
        "def tokenize_reports(reports: List[str], max_len: int = 512) -> Dict[str, torch.Tensor]:\n",
        "    return tokenizer(\n",
        "        reports,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "\n",
        "def compute_pos_weight(train_dataset: Dataset, num_labels: int) -> torch.Tensor:\n",
        "    ys = np.stack([train_dataset[i][\"target\"] for i in range(len(train_dataset))]).astype(np.float32)\n",
        "    pos = ys.sum(axis=0)\n",
        "    neg = ys.shape[0] - pos\n",
        "    pw = (neg + 1e-6) / (pos + 1e-6)\n",
        "    pw = np.clip(pw, 1.0, 100.0)\n",
        "    return torch.tensor(pw, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def preds_topk(probs: np.ndarray, k: int) -> np.ndarray:\n",
        "    k = max(1, min(k, probs.shape[1]))\n",
        "    pred = np.zeros_like(probs, dtype=np.int32)\n",
        "    topk_idx = np.argsort(-probs, axis=1)[:, :k]\n",
        "    rows = np.arange(probs.shape[0])[:, None]\n",
        "    pred[rows, topk_idx] = 1\n",
        "    return pred\n",
        "\n",
        "\n",
        "def precision_recall_at_k(y_true: np.ndarray, probs: np.ndarray, k: int) -> Tuple[float, float]:\n",
        "    pred = preds_topk(probs, k)\n",
        "    tp = (pred * y_true).sum(axis=1)\n",
        "    prec = (tp / (k + 1e-8)).mean()\n",
        "    true_pos = y_true.sum(axis=1)\n",
        "    rec = (tp / (true_pos + 1e-8)).mean()\n",
        "    return float(prec), float(rec)\n",
        "\n",
        "\n",
        "def safe_auc_per_class(y_true: np.ndarray, y_score: np.ndarray) -> np.ndarray:\n",
        "    num_labels = y_true.shape[1]\n",
        "    out = np.full(num_labels, np.nan, dtype=np.float32)\n",
        "    for j in range(num_labels):\n",
        "        col = y_true[:, j]\n",
        "        if col.min() == col.max():\n",
        "            continue\n",
        "        try:\n",
        "            out[j] = float(roc_auc_score(col, y_score[:, j]))\n",
        "        except Exception:\n",
        "            out[j] = np.nan\n",
        "    return out\n",
        "\n",
        "\n",
        "def plot_history(history: Dict[str, List[float]], save_dir: str, client_id: int, topk: int) -> None:\n",
        "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "    def _plot(tr_key: str, va_key: str, title: str, fname: str, ylabel: str):\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, history[tr_key], label=\"Train\")\n",
        "        plt.plot(epochs, history[va_key], label=\"Val\")\n",
        "        plt.title(title)\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(ylabel)\n",
        "        plt.legend()\n",
        "        plt.savefig(os.path.join(save_dir, fname), bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    _plot(\"train_loss\", \"val_loss\", \"BioClinicalBERT Loss\", f\"biobert_loss_client{client_id}.png\", \"Loss\")\n",
        "    _plot(\"train_f1_macro_topk\", \"val_f1_macro_topk\", f\"F1 Macro (Top-{topk})\", f\"biobert_f1macro_topk_client{client_id}.png\", \"F1\")\n",
        "    _plot(\"train_f1_micro_topk\", \"val_f1_micro_topk\", f\"F1 Micro (Top-{topk})\", f\"biobert_f1micro_topk_client{client_id}.png\", \"F1\")\n",
        "    _plot(\"train_exact_match_topk\", \"val_exact_match_topk\", f\"Exact Match (Top-{topk})\", f\"biobert_exactmatch_topk_client{client_id}.png\", \"Exact Match\")\n",
        "\n",
        "\n",
        "def train_eval_biobert(\n",
        "    model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    label_names: List[str],\n",
        "    train_dataset: Dataset,\n",
        "    epochs: int = 20,\n",
        "    lr: float = 2e-5,\n",
        "    warmup_ratio: float = 0.1,\n",
        "    max_len: int = 512,\n",
        "    client_id: int = 0,\n",
        "    topk: int = 5,\n",
        "    use_pos_weight: bool = True,\n",
        ") -> Tuple[Dict[str, List[float]], str]:\n",
        "    num_labels = len(label_names)\n",
        "\n",
        "    pos_weight = compute_pos_weight(train_dataset, num_labels).to(device) if use_pos_weight else None\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    warmup_steps = int(warmup_ratio * total_steps)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=total_steps,\n",
        "    )\n",
        "\n",
        "    scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
        "    model.to(device)\n",
        "\n",
        "    best_val_f1 = -1.0\n",
        "    best_path = os.path.join(OUT_MODELS_DIR, f\"best_biobert_client{client_id}.pt\")\n",
        "\n",
        "    history: Dict[str, List[float]] = {\n",
        "        \"train_loss\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"train_f1_macro_topk\": [],\n",
        "        \"val_f1_macro_topk\": [],\n",
        "        \"train_f1_micro_topk\": [],\n",
        "        \"val_f1_micro_topk\": [],\n",
        "        \"train_f1_samples_topk\": [],\n",
        "        \"val_f1_samples_topk\": [],\n",
        "        \"train_exact_match_topk\": [],\n",
        "        \"val_exact_match_topk\": [],\n",
        "        \"train_p_at_k\": [],\n",
        "        \"val_p_at_k\": [],\n",
        "        \"train_r_at_k\": [],\n",
        "        \"val_r_at_k\": [],\n",
        "        \"train_f1_macro_thr\": [],\n",
        "        \"val_f1_macro_thr\": [],\n",
        "    }\n",
        "\n",
        "    log_rows: List[Dict[str, object]] = []\n",
        "\n",
        "    def _metrics(y_true: np.ndarray, probs: np.ndarray) -> Dict[str, float]:\n",
        "        pred_topk = preds_topk(probs, topk)\n",
        "        f1_macro = f1_score(y_true, pred_topk, average=\"macro\", zero_division=0)\n",
        "        f1_micro = f1_score(y_true, pred_topk, average=\"micro\", zero_division=0)\n",
        "        f1_samples = f1_score(y_true, pred_topk, average=\"samples\", zero_division=0)\n",
        "        exact_match = float((y_true == pred_topk).all(axis=1).mean())\n",
        "        p_at_k, r_at_k = precision_recall_at_k(y_true, probs, topk)\n",
        "        pred_thr = (probs > 0.5).astype(np.int32)\n",
        "        f1_macro_thr = f1_score(y_true, pred_thr, average=\"macro\", zero_division=0)\n",
        "        return {\n",
        "            \"f1_macro_topk\": float(f1_macro),\n",
        "            \"f1_micro_topk\": float(f1_micro),\n",
        "            \"f1_samples_topk\": float(f1_samples),\n",
        "            \"exact_match_topk\": float(exact_match),\n",
        "            \"p_at_k\": float(p_at_k),\n",
        "            \"r_at_k\": float(r_at_k),\n",
        "            \"f1_macro_thr\": float(f1_macro_thr),\n",
        "        }\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # ---- Train ----\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        y_true_train, y_prob_train = [], []\n",
        "\n",
        "        for batch in train_loader:\n",
        "            reports = batch[\"report\"]\n",
        "            labels = batch[\"target\"].to(device, non_blocking=True)\n",
        "\n",
        "            enc = tokenize_reports(reports, max_len=max_len)\n",
        "            input_ids = enc[\"input_ids\"].to(device, non_blocking=True)\n",
        "            attention_mask = enc[\"attention_mask\"].to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.amp.autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n",
        "                logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += float(loss.item())\n",
        "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "            y_prob_train.append(probs)\n",
        "            y_true_train.append(labels.detach().cpu().numpy())\n",
        "\n",
        "        y_true_train = np.concatenate(y_true_train, axis=0).astype(np.int32)\n",
        "        y_prob_train = np.concatenate(y_prob_train, axis=0)\n",
        "        trm = _metrics(y_true_train, y_prob_train)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss / max(1, len(train_loader)))\n",
        "        history[\"train_f1_macro_topk\"].append(trm[\"f1_macro_topk\"])\n",
        "        history[\"train_f1_micro_topk\"].append(trm[\"f1_micro_topk\"])\n",
        "        history[\"train_f1_samples_topk\"].append(trm[\"f1_samples_topk\"])\n",
        "        history[\"train_exact_match_topk\"].append(trm[\"exact_match_topk\"])\n",
        "        history[\"train_p_at_k\"].append(trm[\"p_at_k\"])\n",
        "        history[\"train_r_at_k\"].append(trm[\"r_at_k\"])\n",
        "        history[\"train_f1_macro_thr\"].append(trm[\"f1_macro_thr\"])\n",
        "\n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        y_true_val, y_prob_val = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                reports = batch[\"report\"]\n",
        "                labels = batch[\"target\"].to(device, non_blocking=True)\n",
        "\n",
        "                enc = tokenize_reports(reports, max_len=max_len)\n",
        "                input_ids = enc[\"input_ids\"].to(device, non_blocking=True)\n",
        "                attention_mask = enc[\"attention_mask\"].to(device, non_blocking=True)\n",
        "\n",
        "                logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                loss = criterion(logits, labels)\n",
        "                val_loss += float(loss.item())\n",
        "\n",
        "                probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "                y_prob_val.append(probs)\n",
        "                y_true_val.append(labels.detach().cpu().numpy())\n",
        "\n",
        "        y_true_val = np.concatenate(y_true_val, axis=0).astype(np.int32)\n",
        "        y_prob_val = np.concatenate(y_prob_val, axis=0)\n",
        "        vam = _metrics(y_true_val, y_prob_val)\n",
        "\n",
        "        history[\"val_loss\"].append(val_loss / max(1, len(val_loader)))\n",
        "        history[\"val_f1_macro_topk\"].append(vam[\"f1_macro_topk\"])\n",
        "        history[\"val_f1_micro_topk\"].append(vam[\"f1_micro_topk\"])\n",
        "        history[\"val_f1_samples_topk\"].append(vam[\"f1_samples_topk\"])\n",
        "        history[\"val_exact_match_topk\"].append(vam[\"exact_match_topk\"])\n",
        "        history[\"val_p_at_k\"].append(vam[\"p_at_k\"])\n",
        "        history[\"val_r_at_k\"].append(vam[\"r_at_k\"])\n",
        "        history[\"val_f1_macro_thr\"].append(vam[\"f1_macro_thr\"])\n",
        "\n",
        "        pred_topk_val = preds_topk(y_prob_val, topk)\n",
        "        f1_per_class = f1_score(y_true_val, pred_topk_val, average=None, zero_division=0)\n",
        "        auc_per_class = safe_auc_per_class(y_true_val, y_prob_val)\n",
        "\n",
        "        print(f\"[Epoch {epoch:03d}/{epochs}]\")\n",
        "        print(\n",
        "            f\"Train — Loss {history['train_loss'][-1]:.4f} | \"\n",
        "            f\"F1macro@{topk} {trm['f1_macro_topk']:.4f} | F1micro@{topk} {trm['f1_micro_topk']:.4f} | \"\n",
        "            f\"P@{topk} {trm['p_at_k']:.4f} | R@{topk} {trm['r_at_k']:.4f} | \"\n",
        "            f\"Exact {trm['exact_match_topk']:.4f} | F1macro(thr0.5) {trm['f1_macro_thr']:.4f}\"\n",
        "        )\n",
        "        print(\n",
        "            f\"Val   — Loss {history['val_loss'][-1]:.4f} | \"\n",
        "            f\"F1macro@{topk} {vam['f1_macro_topk']:.4f} | F1micro@{topk} {vam['f1_micro_topk']:.4f} | \"\n",
        "            f\"P@{topk} {vam['p_at_k']:.4f} | R@{topk} {vam['r_at_k']:.4f} | \"\n",
        "            f\"Exact {vam['exact_match_topk']:.4f} | F1macro(thr0.5) {vam['f1_macro_thr']:.4f}\"\n",
        "        )\n",
        "\n",
        "        valid_auc_mask = ~np.isnan(auc_per_class)\n",
        "        valid_idx = np.where(valid_auc_mask)[0]\n",
        "        print(f\"AUC valid for {int(valid_auc_mask.sum())}/{len(auc_per_class)} classes in validation.\")\n",
        "        print(\"Val per-class F1/AUC (first 5 VALID):\")\n",
        "        for j in valid_idx[:5]:\n",
        "            print(f\"  {label_names[j]}: F1={float(f1_per_class[j]):.4f}, AUC={float(auc_per_class[j]):.4f}\")\n",
        "        if len(valid_idx) == 0:\n",
        "            print(\"  (No valid AUC classes in this validation split.)\")\n",
        "        print()\n",
        "\n",
        "        saved_ckpt = False\n",
        "        if vam[\"f1_macro_topk\"] > best_val_f1:\n",
        "            best_val_f1 = float(vam[\"f1_macro_topk\"])\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "            saved_ckpt = True\n",
        "            print(f\"[Checkpoint] Saved best BioBERT (Val F1macro@{topk}={best_val_f1:.4f}) -> {best_path}\\n\")\n",
        "\n",
        "        log_rows.append(\n",
        "            {\n",
        "                \"epoch\": epoch,\n",
        "                \"train_loss\": history[\"train_loss\"][-1],\n",
        "                \"val_loss\": history[\"val_loss\"][-1],\n",
        "                \"train_f1_macro_topk\": history[\"train_f1_macro_topk\"][-1],\n",
        "                \"val_f1_macro_topk\": history[\"val_f1_macro_topk\"][-1],\n",
        "                \"train_f1_micro_topk\": history[\"train_f1_micro_topk\"][-1],\n",
        "                \"val_f1_micro_topk\": history[\"val_f1_micro_topk\"][-1],\n",
        "                \"train_f1_samples_topk\": history[\"train_f1_samples_topk\"][-1],\n",
        "                \"val_f1_samples_topk\": history[\"val_f1_samples_topk\"][-1],\n",
        "                \"train_exact_match_topk\": history[\"train_exact_match_topk\"][-1],\n",
        "                \"val_exact_match_topk\": history[\"val_exact_match_topk\"][-1],\n",
        "                \"train_p_at_k\": history[\"train_p_at_k\"][-1],\n",
        "                \"val_p_at_k\": history[\"val_p_at_k\"][-1],\n",
        "                \"train_r_at_k\": history[\"train_r_at_k\"][-1],\n",
        "                \"val_r_at_k\": history[\"val_r_at_k\"][-1],\n",
        "                \"train_f1_macro_thr\": history[\"train_f1_macro_thr\"][-1],\n",
        "                \"val_f1_macro_thr\": history[\"val_f1_macro_thr\"][-1],\n",
        "                \"saved_ckpt\": saved_ckpt,\n",
        "                \"marker\": \"X\" if saved_ckpt else \"\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "    metrics_csv = os.path.join(OUT_GRAPHS_DIR, f\"biobert_metrics_client{client_id}.csv\")\n",
        "    pd.DataFrame(log_rows).to_csv(metrics_csv, index=False)\n",
        "    print(f\"[Log] Wrote BioBERT per-epoch metrics CSV -> {metrics_csv}\\n\")\n",
        "\n",
        "    plot_history(history, OUT_GRAPHS_DIR, client_id, topk)\n",
        "    return history, best_path\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load client split\n",
        "    cdir = os.path.join(CLIENT_BASE_DIR, f\"client_{CLIENT_ID}\")\n",
        "    with open(os.path.join(cdir, \"train_pids.json\"), \"r\") as f:\n",
        "        train_pids = json.load(f)\n",
        "    with open(os.path.join(cdir, \"val_pids.json\"), \"r\") as f:\n",
        "        val_pids = json.load(f)\n",
        "\n",
        "    # Build datasets\n",
        "    full_ds = ReportsGliomaDataset(\n",
        "        METADATA_DF_PATH,\n",
        "        LABELS_PATH,\n",
        "        exclude_ids=[\"PatientID_0191\"],\n",
        "        remove_background=REMOVE_BACKGROUND_LABEL,\n",
        "    )\n",
        "    label_names = full_ds.labels\n",
        "\n",
        "    train_dataset = SubsetByPIDs(full_ds, train_pids)\n",
        "    val_dataset = SubsetByPIDs(full_ds, val_pids)\n",
        "\n",
        "    # DataLoaders\n",
        "    g = torch.Generator().manual_seed(SEED)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=reports_collate_fn,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        generator=g,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=reports_collate_fn,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        generator=g,\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"Loaded client_{CLIENT_ID}: \"\n",
        "        f\"train patients={len(train_dataset)}, val patients={len(val_dataset)}, num_labels={len(label_names)}\"\n",
        "    )\n",
        "\n",
        "    # Model + training\n",
        "    model = BioBERTMultiLabelClassifier(\n",
        "        BERT_MODEL_NAME,\n",
        "        num_labels=len(label_names),\n",
        "        dropout=DROPOUT,\n",
        "    )\n",
        "\n",
        "    history, best_model_path = train_eval_biobert(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        label_names=label_names,\n",
        "        train_dataset=train_dataset,\n",
        "        epochs=EPOCHS,\n",
        "        lr=LR,\n",
        "        warmup_ratio=WARMUP_RATIO,\n",
        "        max_len=MAX_LEN,\n",
        "        client_id=CLIENT_ID,\n",
        "        topk=TOPK_PRED,\n",
        "        use_pos_weight=USE_POS_WEIGHT,\n",
        "    )\n",
        "\n",
        "    print(f\"[Done] Best BioBERT model saved at: {best_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGF1_XihLEBQ"
      },
      "source": [
        "**<h2>Clip-like model<h2>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4SPJvVHVzde"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Global config\n",
        "# ------------------------\n",
        "SEED = 42\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Reproducibility helpers\n",
        "# ------------------------\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "\n",
        "def worker_init_fn(worker_id: int) -> None:\n",
        "    # Make each dataloader worker deterministic\n",
        "    s = SEED + worker_id\n",
        "    np.random.seed(s)\n",
        "    random.seed(s)\n",
        "\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Small utilities\n",
        "# ------------------------\n",
        "def minmax01(x: np.ndarray) -> np.ndarray:\n",
        "    # Min-max normalize to [0, 1]\n",
        "    x = x.astype(np.float32)\n",
        "    mn = float(np.min(x))\n",
        "    mx = float(np.max(x))\n",
        "    if mx <= mn:\n",
        "        return np.zeros_like(x, dtype=np.float32)\n",
        "    return (x - mn) / (mx - mn)\n",
        "\n",
        "\n",
        "def find_first_existing(paths: List[str]) -> str:\n",
        "    # Pick the first path that exists\n",
        "    for p in paths:\n",
        "        if p and os.path.exists(p):\n",
        "            return p\n",
        "    raise FileNotFoundError(\"None of these paths exist:\\n\" + \"\\n\".join(paths))\n",
        "\n",
        "\n",
        "def ensure_dir(p: str) -> None:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Dataset: loads MRI + atlas regions + tumor mask + report text\n",
        "# Also builds a multi-label target from \"Top 5 Regions\"\n",
        "# ------------------------\n",
        "class GliomaDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        metadata_df_path: str,\n",
        "        labels_path: str,\n",
        "        data_root: str,\n",
        "        exclude_ids: Optional[List[str]] = None,\n",
        "        remove_background: bool = False,\n",
        "    ):\n",
        "        # Load metadata dataframe (contains report + labels per patient)\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = [\"PatientID_0191\"]\n",
        "\n",
        "        # Filter invalid rows and excluded patients\n",
        "        df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "        df = df[df[\"Report\"].notna() & df[\"Top 5 Regions\"].notna()].reset_index(drop=True)\n",
        "\n",
        "        # Load label list\n",
        "        with open(labels_path, \"rb\") as f:\n",
        "            labels = list(pickle.load(f))\n",
        "\n",
        "        if remove_background:\n",
        "            labels = [l for l in labels if str(l).strip().lower() != \"background\"]\n",
        "\n",
        "        self.labels = labels\n",
        "        self.label_to_idx = {lab: i for i, lab in enumerate(self.labels)}\n",
        "\n",
        "        self.data_root = data_root\n",
        "        self.df = df\n",
        "\n",
        "        # Encode some categorical columns\n",
        "        self.categorical_cols = [\n",
        "            \"Sex at Birth\",\n",
        "            \"Race\",\n",
        "            \"Primary Diagnosis\",\n",
        "            \"Previous Brain Tumor\",\n",
        "            \"Type of previous brain tumor\",\n",
        "            \"Age Range\",\n",
        "        ]\n",
        "        self.code_maps: Dict[str, Dict[int, Any]] = {}\n",
        "        for col in self.categorical_cols:\n",
        "            cat = pd.Categorical(self.df[col])\n",
        "            self.df[col + \"_code\"] = cat.codes.astype(np.int64)\n",
        "            self.code_maps[col] = dict(enumerate(cat.categories))\n",
        "\n",
        "        # Keep only patients that have all required .npy files\n",
        "        self.patient_ids: List[str] = []\n",
        "        for pid in self.df[\"Patient_ID\"].tolist():\n",
        "            base = os.path.join(self.data_root, pid)\n",
        "            mri_p = os.path.join(base, f\"{pid}_mri.npy\")\n",
        "            reg_p = os.path.join(base, f\"{pid}_regions.npy\")\n",
        "            tumor_p = os.path.join(base, f\"{pid}_tumor.npy\")\n",
        "            if os.path.isfile(mri_p) and os.path.isfile(reg_p) and os.path.isfile(tumor_p):\n",
        "                self.patient_ids.append(pid)\n",
        "\n",
        "        self.df = self.df[self.df[\"Patient_ID\"].isin(self.patient_ids)].reset_index(drop=True)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def _make_target_regions(self, regions_list: Any) -> np.ndarray:\n",
        "        # Multi-label vector over all region labels\n",
        "        y = np.zeros(len(self.labels), dtype=np.float32)\n",
        "        if not isinstance(regions_list, (list, tuple)):\n",
        "            return y\n",
        "        for reg in regions_list:\n",
        "            idx = self.label_to_idx.get(reg, None)\n",
        "            if idx is not None:\n",
        "                y[idx] = 1.0\n",
        "        return y\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
        "        row = self.df.iloc[idx]\n",
        "        pid = row[\"Patient_ID\"]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        # Load arrays\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "        # Normalize inputs, binarize mask\n",
        "        mri = minmax01(mri)\n",
        "        regions = minmax01(regions)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        target_regions = self._make_target_regions(row[\"Top 5 Regions\"])\n",
        "\n",
        "        return {\n",
        "            \"patient_id\": pid,\n",
        "            \"mri\": mri,\n",
        "            \"regions\": regions,\n",
        "            \"tumor\": tumor,\n",
        "            \"report\": str(row[\"Report\"]),\n",
        "            \"target_regions\": target_regions,\n",
        "            # Extra metadata\n",
        "            \"sex\": int(row[\"Sex at Birth_code\"]),\n",
        "            \"race\": int(row[\"Race_code\"]),\n",
        "            \"age\": float(row[\"Age at diagnosis\"]),\n",
        "            \"primary_diagnosis\": int(row[\"Primary Diagnosis_code\"]),\n",
        "            \"h3_3a_mutation\": float(row[\"H3-3A mutation\"]),\n",
        "            \"pten_mutation\": float(row[\"PTEN mutation\"]),\n",
        "            \"CDKN2A_B_deletion\": float(row[\"CDKN2A/B deletion\"]),\n",
        "            \"TP53_alteration\": float(row[\"TP53 alteration\"]),\n",
        "            \"other_mutations_alterations\": row[\"Other mutations/alterations\"],\n",
        "            \"previous_brain_tumor\": int(row[\"Previous Brain Tumor_code\"]),\n",
        "            \"type_of_previous_brain_tumor\": int(row[\"Type of previous brain tumor_code\"]),\n",
        "            \"age_range\": int(row[\"Age Range_code\"]),\n",
        "        }\n",
        "\n",
        "\n",
        "def glioma_collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    # Build tensors for MRI/regions/mask and keep report text as list\n",
        "    mri = torch.from_numpy(np.stack([b[\"mri\"] for b in batch])).float().unsqueeze(1)\n",
        "    regions = torch.from_numpy(np.stack([b[\"regions\"] for b in batch])).float().unsqueeze(1)\n",
        "    tumor = torch.from_numpy(np.stack([b[\"tumor\"] for b in batch])).float().unsqueeze(1)\n",
        "    target_regions = torch.from_numpy(np.stack([b[\"target_regions\"] for b in batch])).float()\n",
        "\n",
        "    return {\n",
        "        \"patient_id\": [b[\"patient_id\"] for b in batch],\n",
        "        \"report\": [b[\"report\"] for b in batch],\n",
        "        \"mri\": mri,\n",
        "        \"regions\": regions,\n",
        "        \"tumor\": tumor,\n",
        "        \"target_regions\": target_regions,\n",
        "    }\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Text encoder: BioClinicalBERT + linear head (head not used later)\n",
        "# ------------------------\n",
        "class BioBERTMultiLabelClassifier(nn.Module):\n",
        "    def __init__(self, model_name: str, num_labels: int, dropout: float = 0.3):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled = out.pooler_output\n",
        "        if pooled is None:\n",
        "            pooled = out.last_hidden_state[:, 0]  # CLS\n",
        "        x = self.dropout(pooled)\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "def tokenize_reports(tokenizer: AutoTokenizer, reports: List[str], max_len: int = 512) -> Dict[str, torch.Tensor]:\n",
        "    # Tokenize a list of report texts for BERT\n",
        "    return tokenizer(\n",
        "        reports,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "\n",
        "def dice_iou_acc(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[float, float, float]:\n",
        "    # Compute Dice, IoU and pixel accuracy for segmentation masks\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "    inter = int((y_true * y_pred).sum())\n",
        "    dice = (2.0 * inter) / (float(y_true.sum() + y_pred.sum()) + 1e-8)\n",
        "    try:\n",
        "        iou = float(jaccard_score(y_true, y_pred, average=\"binary\"))\n",
        "    except Exception:\n",
        "        union = float(y_true.sum() + y_pred.sum() - inter) + 1e-8\n",
        "        iou = float(inter / union)\n",
        "    acc = float((y_true == y_pred).mean())\n",
        "    return float(dice), float(iou), float(acc)\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# CLIP-like model: aligns text embedding with image embedding\n",
        "# and also predicts segmentation mask with UNet\n",
        "# ------------------------\n",
        "class ClipModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        bert_backbone: AutoModel,\n",
        "        tokenizer: AutoTokenizer,\n",
        "        unet_model: nn.Module,\n",
        "        embed_dim: int = 512,\n",
        "        max_len: int = 512,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.bert_backbone = bert_backbone\n",
        "        self.tokenizer = tokenizer\n",
        "        self.unet_model = unet_model\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Projection layers to a shared embedding space\n",
        "        self.text_projection = nn.Linear(self.bert_backbone.config.hidden_size, embed_dim)\n",
        "        self.image_projection = nn.Linear(512, embed_dim)\n",
        "\n",
        "        # CLIP temperature parameter and uncertainty weights for multitask loss\n",
        "        self.logit_scale = nn.Parameter(torch.tensor(np.log(1 / 0.07), dtype=torch.float32))\n",
        "        self.log_sigma_clip = nn.Parameter(torch.tensor(0.0))\n",
        "        self.log_sigma_seg = nn.Parameter(torch.tensor(0.0))\n",
        "\n",
        "    def encode_text(self, texts: List[str]) -> torch.Tensor:\n",
        "        # Encode reports -> normalized text embeddings\n",
        "        enc = tokenize_reports(self.tokenizer, texts, max_len=self.max_len)\n",
        "        input_ids = enc[\"input_ids\"].to(DEVICE, non_blocking=True)\n",
        "        attention_mask = enc[\"attention_mask\"].to(DEVICE, non_blocking=True)\n",
        "\n",
        "        out = self.bert_backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled = out.pooler_output\n",
        "        if pooled is None:\n",
        "            pooled = out.last_hidden_state[:, 0]\n",
        "\n",
        "        t = self.text_projection(pooled)\n",
        "        return F.normalize(t, dim=-1)\n",
        "\n",
        "    def encode_image(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Encode image -> normalized image embeddings\n",
        "        feats = self.unet_model.encoder(x)[-1]\n",
        "        v = feats.mean(dim=(2, 3))\n",
        "        v = self.image_projection(v)\n",
        "        return F.normalize(v, dim=-1)\n",
        "\n",
        "    def forward(\n",
        "        self, texts: List[str], mri: torch.Tensor, regions: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        # Build 2-channel input (MRI + atlas regions)\n",
        "        x = torch.cat([mri, regions], dim=1).to(DEVICE, non_blocking=True)\n",
        "\n",
        "        # CLIP embeddings + segmentation logits\n",
        "        t = self.encode_text(texts)\n",
        "        v = self.encode_image(x)\n",
        "        seg_logits = self.unet_model(x)\n",
        "        return t, v, seg_logits\n",
        "\n",
        "    def clip_contrastive_loss(self, t: torch.Tensor, v: torch.Tensor) -> torch.Tensor:\n",
        "        # Standard CLIP-style symmetric cross-entropy loss over batch similarities\n",
        "        logit_scale = self.logit_scale.exp().clamp(1e-3, 100.0)\n",
        "        logits = (t @ v.t()) * logit_scale\n",
        "        labels = torch.arange(t.size(0), device=logits.device)\n",
        "        return 0.5 * (F.cross_entropy(logits, labels) + F.cross_entropy(logits.t(), labels))\n",
        "\n",
        "    def combined_loss(\n",
        "        self,\n",
        "        t: torch.Tensor,\n",
        "        v: torch.Tensor,\n",
        "        seg_logits: torch.Tensor,\n",
        "        seg_target: torch.Tensor,\n",
        "        seg_criterion: nn.Module,\n",
        "    ) -> torch.Tensor:\n",
        "        # Multi-task loss with learned uncertainty weighting\n",
        "        clip_loss = self.clip_contrastive_loss(t, v)\n",
        "        seg_loss = seg_criterion(seg_logits, seg_target.to(seg_logits.device, non_blocking=True).float())\n",
        "        return (\n",
        "            (1.0 / (2.0 * torch.exp(self.log_sigma_clip) ** 2)) * clip_loss\n",
        "            + (1.0 / (2.0 * torch.exp(self.log_sigma_seg) ** 2)) * seg_loss\n",
        "            + self.log_sigma_clip\n",
        "            + self.log_sigma_seg\n",
        "        )\n",
        "\n",
        "\n",
        "def load_biobert_backbone_only(bert_wrapper: BioBERTMultiLabelClassifier, ckpt_path: str) -> None:\n",
        "    # Load only BERT weights (skip classifier head)\n",
        "    sd = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    sd = {k: v for k, v in sd.items() if not k.startswith(\"classifier.\")}\n",
        "    bert_wrapper.load_state_dict(sd, strict=False)\n",
        "\n",
        "\n",
        "def build_unet(in_channels: int = 2, encoder_name: str = \"resnet34\", encoder_weights: Optional[str] = None) -> nn.Module:\n",
        "    # UNet used both for segmentation and as image feature encoder\n",
        "    return smp.Unet(\n",
        "        encoder_name=encoder_name,\n",
        "        encoder_weights=encoder_weights,\n",
        "        in_channels=in_channels,\n",
        "        classes=1,\n",
        "        activation=None,\n",
        "    )\n",
        "\n",
        "\n",
        "def train_one_epoch_clip(\n",
        "    model: ClipModel,\n",
        "    loader: DataLoader,\n",
        "    optimizer: optim.Optimizer,\n",
        "    seg_criterion: nn.Module,\n",
        "    scaler: torch.amp.GradScaler,\n",
        ") -> Dict[str, float]:\n",
        "    # One epoch of training (contrastive + segmentation)\n",
        "    model.train()\n",
        "    tot_loss = tot_dice = tot_iou = tot_acc = 0.0\n",
        "    n = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        texts = batch[\"report\"]\n",
        "        mri = batch[\"mri\"].to(DEVICE, non_blocking=True)\n",
        "        regions = batch[\"regions\"].to(DEVICE, non_blocking=True)\n",
        "        tumor = batch[\"tumor\"].to(DEVICE, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(DEVICE.type == \"cuda\")):\n",
        "            t, v, seg_logits = model(texts, mri, regions)\n",
        "            loss = model.combined_loss(t, v, seg_logits, tumor, seg_criterion)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = (torch.sigmoid(seg_logits).detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "            y_np = (tumor.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "            d, i, a = dice_iou_acc(y_np, preds)\n",
        "\n",
        "        tot_loss += float(loss.item())\n",
        "        tot_dice += d\n",
        "        tot_iou += i\n",
        "        tot_acc += a\n",
        "        n += 1\n",
        "\n",
        "    return {\n",
        "        \"loss\": tot_loss / max(1, n),\n",
        "        \"dice\": tot_dice / max(1, n),\n",
        "        \"iou\": tot_iou / max(1, n),\n",
        "        \"acc\": tot_acc / max(1, n),\n",
        "    }\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch_clip(model: ClipModel, loader: DataLoader, seg_criterion: nn.Module) -> Dict[str, float]:\n",
        "    # Validation epoch\n",
        "    model.eval()\n",
        "    tot_loss = tot_dice = tot_iou = tot_acc = 0.0\n",
        "    n = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        texts = batch[\"report\"]\n",
        "        mri = batch[\"mri\"].to(DEVICE, non_blocking=True)\n",
        "        regions = batch[\"regions\"].to(DEVICE, non_blocking=True)\n",
        "        tumor = batch[\"tumor\"].to(DEVICE, non_blocking=True)\n",
        "\n",
        "        t, v, seg_logits = model(texts, mri, regions)\n",
        "        loss = model.combined_loss(t, v, seg_logits, tumor, seg_criterion)\n",
        "\n",
        "        preds = (torch.sigmoid(seg_logits).detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (tumor.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = dice_iou_acc(y_np, preds)\n",
        "\n",
        "        tot_loss += float(loss.item())\n",
        "        tot_dice += d\n",
        "        tot_iou += i\n",
        "        tot_acc += a\n",
        "        n += 1\n",
        "\n",
        "    return {\n",
        "        \"loss\": tot_loss / max(1, n),\n",
        "        \"dice\": tot_dice / max(1, n),\n",
        "        \"iou\": tot_iou / max(1, n),\n",
        "        \"acc\": tot_acc / max(1, n),\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    candidates_metadata = [\n",
        "        \"/content/cleaned_df.pkl\",\n",
        "        \"/content/drive/MyDrive/PKG - MU-Glioma-Post/cleaned_df.pkl\",\n",
        "        \"/content/cleaned_df.pkl\",\n",
        "    ]\n",
        "    candidates_labels = [\n",
        "        \"/content/labels_list.pkl\",\n",
        "        \"/content/drive/MyDrive/PKG - MU-Glioma-Post/labels_list.pkl\",\n",
        "        \"/content/labels_list.pkl\",\n",
        "    ]\n",
        "    candidates_data_root = [\n",
        "        \"/content/Preprocessed-Data\",\n",
        "        \"/content/drive/MyDrive/PKG - MU-Glioma-Post/Preprocessed-Data\",\n",
        "        \"/content/Preprocessed-Data\",\n",
        "    ]\n",
        "\n",
        "    METADATA_DF_PATH = find_first_existing(candidates_metadata)\n",
        "    LABELS_PATH = find_first_existing(candidates_labels)\n",
        "    DATA_ROOT = find_first_existing(candidates_data_root)\n",
        "\n",
        "    BERT_MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "\n",
        "    # Optional pretrained checkpoints\n",
        "    BIOBERT_BEST_CAND = [\n",
        "        \"/content/AITDM/Models/BioClinicalBert/best_biobert_client0.pt\",\n",
        "        \"/content/drive/MyDrive/PKG - MU-Glioma-Post/Models/BioClinicalBert/best.pt\",\n",
        "        \"/content/AITDM/Models/BioClinicalBert/best_biobert_client0.pt\",\n",
        "    ]\n",
        "    UNET_BEST_CAND = [\n",
        "        \"/content/AITDM/Models/UNet_ImageOnly/best_unet_client0.pth\",\n",
        "        \"/content/AITDM/Models/UNet_ImageOnly/best_unet_client0.pth\",\n",
        "        \"/content/drive/MyDrive/PKG - MU-Glioma-Post/Models/UNet/best_unet_model.pth\",\n",
        "        \"/content/AITDM/Models/UNet_ImageOnly/best_unet_client0.pth\",\n",
        "        \"/content/AITDM/Models/UNet_ImageOnly/best_unet_client0.pth\",\n",
        "    ]\n",
        "\n",
        "    BIOBERT_BEST = next((p for p in BIOBERT_BEST_CAND if os.path.isfile(p)), \"\")\n",
        "    UNET_BEST = next((p for p in UNET_BEST_CAND if os.path.isfile(p)), \"\")\n",
        "\n",
        "    # Output checkpoint for the CLIP-like model\n",
        "    CLIP_SAVE = \"/content/drive/MyDrive/PKG - MU-Glioma-Post/Models/CLIP_Based/best_clip_model.pth\"\n",
        "    ensure_dir(os.path.dirname(CLIP_SAVE))\n",
        "\n",
        "    # Training hyperparams\n",
        "    BATCH_SIZE = 4\n",
        "    EPOCHS = 50\n",
        "    LR = 1e-4\n",
        "    MAX_LEN = 512\n",
        "\n",
        "    print(\"Resolved paths:\")\n",
        "    print(\"  metadata:\", METADATA_DF_PATH)\n",
        "    print(\"  labels  :\", LABELS_PATH)\n",
        "    print(\"  data_root:\", DATA_ROOT)\n",
        "    print(\"  biobert ckpt:\", BIOBERT_BEST if BIOBERT_BEST else \"(not found, will use base)\")\n",
        "    print(\"  unet ckpt  :\", UNET_BEST if UNET_BEST else \"(not found, will use random init)\")\n",
        "\n",
        "    # Build dataset and split train/test\n",
        "    dataset = GliomaDataset(\n",
        "        metadata_df_path=METADATA_DF_PATH,\n",
        "        labels_path=LABELS_PATH,\n",
        "        data_root=DATA_ROOT,\n",
        "        exclude_ids=[\"PatientID_0191\"],\n",
        "        remove_background=False,\n",
        "    )\n",
        "\n",
        "    test_size = int(0.2 * len(dataset))\n",
        "    train_size = len(dataset) - test_size\n",
        "    train_dataset, test_dataset = random_split(\n",
        "        dataset, [train_size, test_size], generator=torch.Generator().manual_seed(SEED)\n",
        "    )\n",
        "\n",
        "    # Dataloaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        collate_fn=glioma_collate_fn,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        collate_fn=glioma_collate_fn,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    # Tokenizer + BERT backbone\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
        "    bert_wrapper = BioBERTMultiLabelClassifier(BERT_MODEL_NAME, num_labels=len(dataset.labels), dropout=0.3)\n",
        "    if BIOBERT_BEST:\n",
        "        try:\n",
        "            bert_wrapper.load_state_dict(torch.load(BIOBERT_BEST, map_location=\"cpu\"))\n",
        "        except RuntimeError:\n",
        "            load_biobert_backbone_only(bert_wrapper, BIOBERT_BEST)\n",
        "    bert_backbone = bert_wrapper.bert.to(DEVICE)\n",
        "\n",
        "    # UNet\n",
        "    unet_model = build_unet(in_channels=2, encoder_name=\"resnet34\", encoder_weights=None)\n",
        "    if UNET_BEST:\n",
        "        unet_model.load_state_dict(torch.load(UNET_BEST, map_location=\"cpu\"))\n",
        "    unet_model = unet_model.to(DEVICE)\n",
        "\n",
        "    # Build CLIP-like multimodal model\n",
        "    clip_model = ClipModel(\n",
        "        bert_backbone=bert_backbone,\n",
        "        tokenizer=tokenizer,\n",
        "        unet_model=unet_model,\n",
        "        embed_dim=512,\n",
        "        max_len=MAX_LEN,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # Loss/optimizer/scheduler\n",
        "    seg_criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "    optimizer = optim.AdamW(clip_model.parameters(), lr=LR)\n",
        "\n",
        "    total_steps = len(train_loader) * EPOCHS\n",
        "    warmup_steps = int(0.1 * total_steps)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    scaler = torch.amp.GradScaler(\"cuda\", enabled=(DEVICE.type == \"cuda\"))\n",
        "\n",
        "    # Track best checkpoint by (Dice up) and (loss down)\n",
        "    best_val_dice = -1.0\n",
        "    best_val_loss = float(\"inf\")\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        tr = train_one_epoch_clip(clip_model, train_loader, optimizer, seg_criterion, scaler)\n",
        "        va = eval_one_epoch_clip(clip_model, test_loader, seg_criterion)\n",
        "\n",
        "        # Step LR scheduler once per training step (done here in a loop)\n",
        "        for _ in range(len(train_loader)):\n",
        "            scheduler.step()\n",
        "\n",
        "        print(\n",
        "            f\"[Epoch {epoch:03d}/{EPOCHS}] \"\n",
        "            f\"Train loss {tr['loss']:.4f} dice {tr['dice']:.4f} iou {tr['iou']:.4f} acc {tr['acc']:.4f} || \"\n",
        "            f\"Val loss {va['loss']:.4f} dice {va['dice']:.4f} iou {va['iou']:.4f} acc {va['acc']:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Save best model\n",
        "        if (va[\"dice\"] > best_val_dice) and (va[\"loss\"] < best_val_loss):\n",
        "            best_val_dice = va[\"dice\"]\n",
        "            best_val_loss = va[\"loss\"]\n",
        "            torch.save(clip_model.state_dict(), CLIP_SAVE)\n",
        "            print(f\"Saved best model -> {CLIP_SAVE} (val dice {best_val_dice:.4f}, val loss {best_val_loss:.4f})\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXoXxVZ4Lig_"
      },
      "source": [
        "# **M2 - Ensemble on Images only**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgL9BfPx8seu"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "print(list(smp.encoders.get_encoder_names()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtwsveySU7ft"
      },
      "source": [
        "**<h2>UNet - \"resnet50\"<h2>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSXYT79OULsR"
      },
      "outputs": [],
      "source": [
        "import os, json, pickle, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from sklearn.metrics import jaccard_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Paths and I/O config\n",
        "DATA_ROOT = \"/content/Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "OUT_BASE = \"AITDM\"\n",
        "CLIENT_DIR = os.path.join(OUT_BASE, \"/content/client\")\n",
        "\n",
        "# Experiment config\n",
        "USE_ATLAS = True\n",
        "CLIENT_ID = 0\n",
        "BATCH_SIZE = 8\n",
        "LR = 1e-3\n",
        "EPOCHS = 50\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "# Model / encoder config\n",
        "ENCODER_NAME = \"resnet50\"\n",
        "ENCODER_WEIGHTS = \"imagenet\"\n",
        "\n",
        "# Output directories\n",
        "OUT_MODELS_DIR = os.path.join(OUT_BASE, \"Models\", \"UNet_ImageOnly\")\n",
        "OUT_GRAPHS_DIR = os.path.join(OUT_BASE, \"Graphs\")\n",
        "os.makedirs(OUT_MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_GRAPHS_DIR, exist_ok=True)\n",
        "\n",
        "def sanitize(s: str) -> str:\n",
        "    return str(s).replace(\"/\", \"-\").replace(\" \", \"_\")\n",
        "\n",
        "encoder_tag = sanitize(ENCODER_NAME)\n",
        "weights_tag = sanitize(ENCODER_WEIGHTS) if ENCODER_WEIGHTS is not None else \"none\"\n",
        "atlas_tag = \"atlas\" if USE_ATLAS else \"img\"\n",
        "\n",
        "run_tag = f\"unet_{encoder_tag}_{weights_tag}_{atlas_tag}\"\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    \"\"\"Dataset that loads MRI, tumor mask, and optional atlas regions per patient.\"\"\"\n",
        "\n",
        "    def __init__(self, metadata_df_path, data_root, use_atlas=True, exclude_ids=None, transform=None):\n",
        "        import pickle, os, numpy as np, pandas as pd\n",
        "\n",
        "        # Load metadata dataframe\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        # Optionally exclude some patient IDs\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = [\"PatientID_0191\"]\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        # Collect patient IDs that have all required files\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            mri_p = os.path.join(self.data_root, pid, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(self.data_root, pid, f\"{pid}_tumor.npy\")\n",
        "\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(self.data_root, pid, f\"{pid}_regions.npy\")\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p) and os.path.isfile(reg_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "            else:\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        \"\"\"Simple min-max normalization to [0, 1].\"\"\"\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        return (x - mn) / (mx - mn) if mx > mn else np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Load and return one sample (dict) for a patient.\"\"\"\n",
        "        import os, numpy as np\n",
        "\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        # Load MRI and tumor mask\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "        # Normalize MRI and binarize tumor mask\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        # Optionally load regions/atlas\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "            regions = self._minmax(regions)\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "def image_only_collate_fn(batch, use_atlas=True):\n",
        "    \"\"\"Custom collate: stack MRI (+ optional regions) and tumor into tensors.\"\"\"\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        # Concatenate MRI and regions as channels\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": [it[\"patient_id\"] for it in batch]}\n",
        "\n",
        "class SubsetByPIDs(Dataset):\n",
        "    \"\"\"Wrap a dataset but keep only a subset of patient IDs.\"\"\"\n",
        "\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        # Map patient IDs to indices\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Load client-specific train/val patient IDs\n",
        "cdir = os.path.join(CLIENT_DIR, f\"client_{CLIENT_ID}\")\n",
        "with open(os.path.join(cdir, \"train_pids.json\"), \"r\") as f:\n",
        "    train_pids = json.load(f)\n",
        "with open(os.path.join(cdir, \"val_pids.json\"), \"r\") as f:\n",
        "    val_pids = json.load(f)\n",
        "\n",
        "# Build full dataset and then client subsets\n",
        "full_ds = ImageOnlyGliomaDataset(\n",
        "    METADATA_DF_PATH,\n",
        "    DATA_ROOT,\n",
        "    use_atlas=USE_ATLAS,\n",
        "    exclude_ids=[\"PatientID_0191\"],\n",
        ")\n",
        "train_dataset = SubsetByPIDs(full_ds, train_pids)\n",
        "val_dataset = SubsetByPIDs(full_ds, val_pids)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        "    worker_init_fn=worker_init_fn,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        "    worker_init_fn=worker_init_fn,\n",
        ")\n",
        "\n",
        "print(f\"Loaded client_{CLIENT_ID}: train patients={len(train_dataset)}, val patients={len(val_dataset)}\")\n",
        "\n",
        "# UNet model (from segmentation_models_pytorch)\n",
        "in_channels = 2 if USE_ATLAS else 1\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER_NAME,\n",
        "    encoder_weights=ENCODER_WEIGHTS,\n",
        "    in_channels=in_channels,\n",
        "    classes=1,\n",
        ").to(device)\n",
        "\n",
        "# Loss, optimizer, scheduler, and AMP scaler\n",
        "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer, start_factor=1.0, end_factor=0.0, total_iters=EPOCHS\n",
        ")\n",
        "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
        "\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    \"\"\"Compute Dice, IoU, and pixel accuracy.\"\"\"\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "\n",
        "    inter = (y_true * y_pred).sum()\n",
        "    dice = (2.0 * inter) / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "\n",
        "    # IoU with sklearn, fallback if it fails\n",
        "    try:\n",
        "        iou = jaccard_score(y_true, y_pred, average=\"binary\")\n",
        "    except Exception:\n",
        "        union = y_true.sum() + y_pred.sum() - inter + 1e-8\n",
        "        iou = inter / union\n",
        "\n",
        "    acc = (y_true == y_pred).mean()\n",
        "    return float(dice), float(iou), float(acc)\n",
        "\n",
        "def plot_prediction(sample_imgs, save_path):\n",
        "    \"\"\"Plot MRI (+ optional regions), GT, and prediction for one batch.\"\"\"\n",
        "    if \"regions\" in sample_imgs:\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
        "    else:\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # MRI\n",
        "    axs[0].imshow(sample_imgs[\"mri\"][0, 0], cmap=\"gray\")\n",
        "    axs[0].set_title(\"MRI\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    col = 1\n",
        "\n",
        "    # Regions (if available)\n",
        "    if \"regions\" in sample_imgs:\n",
        "        axs[col].imshow(sample_imgs[\"regions\"][0, 0], cmap=\"gray\")\n",
        "        axs[col].set_title(\"Regions\")\n",
        "        axs[col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "    # Ground truth\n",
        "    axs[col].imshow(sample_imgs[\"y_true\"][0, 0], cmap=\"gray\")\n",
        "    axs[col].set_title(\"Ground Truth\")\n",
        "    axs[col].axis(\"off\")\n",
        "    col += 1\n",
        "\n",
        "    # Prediction\n",
        "    axs[col].imshow(sample_imgs[\"y_pred\"][0, 0], cmap=\"gray\")\n",
        "    axs[col].set_title(\"Predicted\")\n",
        "    axs[col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics(history, save_path):\n",
        "    \"\"\"Plot training and validation curves for loss and metrics.\"\"\"\n",
        "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss\")\n",
        "\n",
        "    # Dice\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs, history[\"train_dice\"], label=\"Train Dice\")\n",
        "    plt.plot(epochs, history[\"val_dice\"], label=\"Val Dice\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Dice\")\n",
        "\n",
        "    # IoU\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(epochs, history[\"train_iou\"], label=\"Train IoU\")\n",
        "    plt.plot(epochs, history[\"val_iou\"], label=\"Val IoU\")\n",
        "    plt.legend()\n",
        "    plt.title(\"IoU\")\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
        "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Accuracy\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, scaler):\n",
        "    \"\"\"One training epoch over the dataloader.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Mixed precision forward pass\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n",
        "            preds = model(x)\n",
        "            loss = criterion(preds, y)\n",
        "\n",
        "        # Backward with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        # Convert predictions to binary and compute metrics\n",
        "        preds_prob = (torch.sigmoid(preds).detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (y.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, dataloader, criterion, keep_last_batch=True):\n",
        "    \"\"\"Evaluation loop over the validation dataloader.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "    last_batch_imgs = None\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        preds = model(x)\n",
        "        loss = criterion(preds, y)\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        preds_prob = (torch.sigmoid(preds).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "\n",
        "        # Optionally keep last batch for visualization\n",
        "        if keep_last_batch:\n",
        "            ch0 = x[:, 0:1].cpu().numpy()\n",
        "            imgs = {\"mri\": ch0, \"y_true\": y.cpu().numpy(), \"y_pred\": preds_prob}\n",
        "            if x.shape[1] == 2:\n",
        "                ch1 = x[:, 1:2].cpu().numpy()\n",
        "                imgs[\"regions\"] = ch1\n",
        "            last_batch_imgs = imgs\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n, last_batch_imgs\n",
        "\n",
        "def infer_and_visualize_best(\n",
        "    model,\n",
        "    val_dataset,\n",
        "    use_atlas: bool,\n",
        "    out_dir: str,\n",
        "    client_id: int,\n",
        "    best_ckpt_path: str,\n",
        "    k_samples: int = 3,\n",
        "    threshold: float = 0.5,\n",
        "):\n",
        "    \"\"\"Load best checkpoint, run inference on a few validation samples, and save visualizations.\"\"\"\n",
        "    import random\n",
        "\n",
        "    # Make sampling deterministic\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    if os.path.isfile(best_ckpt_path):\n",
        "        model.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "        model.eval()\n",
        "        print(f\"[Best Model] Loaded: {best_ckpt_path}\\n\")\n",
        "    else:\n",
        "        print(f\"[Best Model] Missing checkpoint: {best_ckpt_path}\\n\")\n",
        "        return\n",
        "\n",
        "    k = min(k_samples, len(val_dataset))\n",
        "    if k == 0:\n",
        "        print(\"[Best Model] Empty val dataset.\\n\")\n",
        "        return\n",
        "\n",
        "    # Deterministic random subset of validation indices\n",
        "    idxs = random.sample(range(len(val_dataset)), k)\n",
        "\n",
        "    def _predict_one(sample):\n",
        "        \"\"\"Run model on one sample and return inputs and binarized prediction.\"\"\"\n",
        "        mri = torch.tensor(sample[\"mri\"]).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            regs = torch.tensor(sample[\"regions\"]).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "            x = torch.cat([mri, regs], dim=1)\n",
        "        else:\n",
        "            x = mri\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prob = torch.sigmoid(model(x)).cpu().numpy()\n",
        "            pred_bin = (prob > threshold).astype(np.uint8)\n",
        "\n",
        "        return x.cpu().numpy(), pred_bin\n",
        "\n",
        "    saved_paths = []\n",
        "\n",
        "    # Save individual sample figures\n",
        "    for i, idx in enumerate(idxs, 1):\n",
        "        sample = val_dataset[idx]\n",
        "        pid = sample.get(\"patient_id\", f\"val_{idx}\")\n",
        "        x_np, pred_bin = _predict_one(sample)\n",
        "\n",
        "        imgs = {\n",
        "            \"mri\": x_np[:, 0:1],\n",
        "            \"y_true\": np.expand_dims(\n",
        "                np.expand_dims(sample[\"tumor\"], 0), 0\n",
        "            ).astype(np.float32),\n",
        "            \"y_pred\": pred_bin.astype(np.float32),\n",
        "        }\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            imgs[\"regions\"] = x_np[:, 1:2]\n",
        "\n",
        "        out_path = os.path.join(\n",
        "            out_dir, f\"best_val_sample_{i}_client{client_id}_{pid}.png\"\n",
        "        )\n",
        "        plot_prediction(imgs, out_path)\n",
        "        saved_paths.append(out_path)\n",
        "\n",
        "    print(\"[Best Model] Saved individual figures:\")\n",
        "    for p in saved_paths:\n",
        "        print(\" -\", p)\n",
        "    print()\n",
        "\n",
        "    # Save grid figure\n",
        "    cols = 4 if use_atlas else 3\n",
        "    fig, axs = plt.subplots(k, cols, figsize=(5 * cols, 4 * k))\n",
        "\n",
        "    if k == 1:\n",
        "        axs = np.expand_dims(axs, 0)\n",
        "\n",
        "    for row, idx in enumerate(idxs):\n",
        "        sample = val_dataset[idx]\n",
        "        x_np, pred_bin = _predict_one(sample)\n",
        "\n",
        "        mri = x_np[0, 0]\n",
        "        gt = sample[\"tumor\"]\n",
        "        col = 0\n",
        "\n",
        "        axs[row, col].imshow(mri, cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"MRI\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            regs = x_np[0, 1]\n",
        "            axs[row, col].imshow(regs, cmap=\"gray\")\n",
        "            axs[row, col].set_title(\"Regions\")\n",
        "            axs[row, col].axis(\"off\")\n",
        "            col += 1\n",
        "\n",
        "        axs[row, col].imshow(gt, cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"Ground Truth\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "        axs[row, col].imshow(pred_bin[0, 0], cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"Predicted (τ=0.5)\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    grid_path = os.path.join(out_dir, f\"best_model_val_grid_{run_tag}_client{client_id}.png\")\n",
        "    plt.savefig(grid_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(f\"[Best Model] Saved grid -> {grid_path}\\n\")\n",
        "\n",
        "# History containers for training curves\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_dice\": [],\n",
        "    \"train_iou\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_dice\": [],\n",
        "    \"val_iou\": [],\n",
        "    \"val_acc\": [],\n",
        "}\n",
        "\n",
        "# Tracking best validation metrics\n",
        "best_val_iou = 0.0\n",
        "best_val_dice = -float(\"inf\")\n",
        "best_val_loss = float(\"inf\")\n",
        "best_path = os.path.join(OUT_MODELS_DIR, f\"best_{run_tag}_client{CLIENT_ID}.pth\")\n",
        "\n",
        "log_rows = []\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # Train one epoch\n",
        "    trL, trD, trI, trA = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion, scaler\n",
        "    )\n",
        "    # Validate\n",
        "    vaL, vaD, vaI, vaA, _ = eval_one_epoch(\n",
        "        model, val_loader, criterion, keep_last_batch=True\n",
        "    )\n",
        "\n",
        "    # Update scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save metrics for plots\n",
        "    history[\"train_loss\"].append(trL)\n",
        "    history[\"train_dice\"].append(trD)\n",
        "    history[\"train_iou\"].append(trI)\n",
        "    history[\"train_acc\"].append(trA)\n",
        "\n",
        "    history[\"val_loss\"].append(vaL)\n",
        "    history[\"val_dice\"].append(vaD)\n",
        "    history[\"val_iou\"].append(vaI)\n",
        "    history[\"val_acc\"].append(vaA)\n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch:03d}/{EPOCHS}] \"\n",
        "        f\"Train — Loss {trL:.4f} | Dice {trD:.4f} | IoU {trI:.4f} | Accuracy {trA:.4f} || \"\n",
        "        f\"Val — Loss {vaL:.4f} | Dice {vaD:.4f} | IoU {vaI:.4f} | Accuracy {vaA:.4f}\\n\"\n",
        "    )\n",
        "\n",
        "    # Save checkpoint if Dice improves and loss decreases\n",
        "    saved_ckpt = False\n",
        "    if (vaD > best_val_dice) and (vaL < best_val_loss):\n",
        "        best_val_dice = vaD\n",
        "        best_val_loss = vaL\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        saved_ckpt = True\n",
        "        print(\n",
        "            f\"Saved best model (Val Dice↑ {best_val_dice:.4f} & Val Loss↓ {best_val_loss:.4f}) -> {best_path}\\n\"\n",
        "        )\n",
        "\n",
        "    # Log row for CSV\n",
        "    log_rows.append(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": trL,\n",
        "            \"train_dice\": trD,\n",
        "            \"train_iou\": trI,\n",
        "            \"train_acc\": trA,\n",
        "            \"val_loss\": vaL,\n",
        "            \"val_dice\": vaD,\n",
        "            \"val_iou\": vaI,\n",
        "            \"val_acc\": vaA,\n",
        "            \"saved_ckpt\": saved_ckpt,\n",
        "            \"marker\": \"X\" if saved_ckpt else \"\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Save metrics as CSV\n",
        "metrics_csv = os.path.join(OUT_GRAPHS_DIR, f\"metrics_{run_tag}_client{CLIENT_ID}.csv\")\n",
        "pd.DataFrame(log_rows).to_csv(metrics_csv, index=False)\n",
        "print(f\"[Log] Wrote per-epoch metrics CSV -> {metrics_csv}\\n\")\n",
        "\n",
        "# Plot training curves (tagged)\n",
        "curves_path = os.path.join(OUT_GRAPHS_DIR, f\"training_curves_{run_tag}_client{CLIENT_ID}.png\")\n",
        "plot_metrics(history, curves_path)\n",
        "\n",
        "# Run inference with best model and visualize a few validation samples\n",
        "infer_and_visualize_best(\n",
        "    model=model,\n",
        "    val_dataset=val_dataset,\n",
        "    use_atlas=USE_ATLAS,\n",
        "    out_dir=OUT_GRAPHS_DIR,\n",
        "    client_id=CLIENT_ID,\n",
        "    best_ckpt_path=best_path,\n",
        "    k_samples=3,\n",
        "    threshold=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMKUalT3VBME"
      },
      "source": [
        "**<h2>UNet - \"mit_b3\"<h2>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQFigtpPHpoI"
      },
      "outputs": [],
      "source": [
        "import os, json, pickle, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from sklearn.metrics import jaccard_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Paths and I/O config\n",
        "DATA_ROOT = \"/content/Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "OUT_BASE = \"AITDM\"\n",
        "CLIENT_DIR = os.path.join(OUT_BASE, \"/content/client\")\n",
        "\n",
        "# Experiment config\n",
        "USE_ATLAS = True\n",
        "CLIENT_ID = 0\n",
        "BATCH_SIZE = 8\n",
        "LR = 1e-3\n",
        "EPOCHS = 50\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "# Model / encoder config\n",
        "ENCODER_NAME = \"mit_b3\"\n",
        "ENCODER_WEIGHTS = \"imagenet\"\n",
        "\n",
        "# Output directories\n",
        "OUT_MODELS_DIR = os.path.join(OUT_BASE, \"Models\", \"UNet_ImageOnly\")\n",
        "OUT_GRAPHS_DIR = os.path.join(OUT_BASE, \"Graphs\")\n",
        "os.makedirs(OUT_MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_GRAPHS_DIR, exist_ok=True)\n",
        "\n",
        "def sanitize(s: str) -> str:\n",
        "    return str(s).replace(\"/\", \"-\").replace(\" \", \"_\")\n",
        "\n",
        "encoder_tag = sanitize(ENCODER_NAME)\n",
        "weights_tag = sanitize(ENCODER_WEIGHTS) if ENCODER_WEIGHTS is not None else \"none\"\n",
        "atlas_tag = \"atlas\" if USE_ATLAS else \"img\"\n",
        "\n",
        "run_tag = f\"unet_{encoder_tag}_{weights_tag}_{atlas_tag}\"\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(False)\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    \"\"\"Dataset that loads MRI, tumor mask, and optional atlas regions per patient.\"\"\"\n",
        "\n",
        "    def __init__(self, metadata_df_path, data_root, use_atlas=True, exclude_ids=None, transform=None):\n",
        "        import pickle, os, numpy as np, pandas as pd\n",
        "\n",
        "        # Load metadata dataframe\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        # Optionally exclude some patient IDs\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = [\"PatientID_0191\"]\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        # Collect patient IDs that have all required files\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            mri_p = os.path.join(self.data_root, pid, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(self.data_root, pid, f\"{pid}_tumor.npy\")\n",
        "\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(self.data_root, pid, f\"{pid}_regions.npy\")\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p) and os.path.isfile(reg_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "            else:\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        \"\"\"Simple min-max normalization to [0, 1].\"\"\"\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        return (x - mn) / (mx - mn) if mx > mn else np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Load and return one sample (dict) for a patient.\"\"\"\n",
        "        import os, numpy as np\n",
        "\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        # Load MRI and tumor mask\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "        # Normalize MRI and binarize tumor mask\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        # Optionally load regions/atlas\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "            regions = self._minmax(regions)\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "def image_only_collate_fn(batch, use_atlas=True):\n",
        "    \"\"\"Custom collate: stack MRI (+ optional regions) and tumor into tensors.\"\"\"\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        # Concatenate MRI and regions as channels\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": [it[\"patient_id\"] for it in batch]}\n",
        "\n",
        "class SubsetByPIDs(Dataset):\n",
        "    \"\"\"Wrap a dataset but keep only a subset of patient IDs.\"\"\"\n",
        "\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        # Map patient IDs to indices\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Load client-specific train/val patient IDs\n",
        "cdir = os.path.join(CLIENT_DIR, f\"client_{CLIENT_ID}\")\n",
        "with open(os.path.join(cdir, \"train_pids.json\"), \"r\") as f:\n",
        "    train_pids = json.load(f)\n",
        "with open(os.path.join(cdir, \"val_pids.json\"), \"r\") as f:\n",
        "    val_pids = json.load(f)\n",
        "\n",
        "# Build full dataset and then client subsets\n",
        "full_ds = ImageOnlyGliomaDataset(\n",
        "    METADATA_DF_PATH,\n",
        "    DATA_ROOT,\n",
        "    use_atlas=USE_ATLAS,\n",
        "    exclude_ids=[\"PatientID_0191\"],\n",
        ")\n",
        "train_dataset = SubsetByPIDs(full_ds, train_pids)\n",
        "val_dataset = SubsetByPIDs(full_ds, val_pids)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        "    worker_init_fn=worker_init_fn,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        "    worker_init_fn=worker_init_fn,\n",
        ")\n",
        "\n",
        "print(f\"Loaded client_{CLIENT_ID}: train patients={len(train_dataset)}, val patients={len(val_dataset)}\")\n",
        "\n",
        "# UNet model (from segmentation_models_pytorch)\n",
        "in_channels = 2 if USE_ATLAS else 1\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER_NAME,\n",
        "    encoder_weights=ENCODER_WEIGHTS,\n",
        "    in_channels=in_channels,\n",
        "    classes=1,\n",
        ").to(device)\n",
        "\n",
        "# Loss, optimizer, scheduler, and AMP scaler\n",
        "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer, start_factor=1.0, end_factor=0.0, total_iters=EPOCHS\n",
        ")\n",
        "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
        "\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    \"\"\"Compute Dice, IoU, and pixel accuracy.\"\"\"\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "\n",
        "    inter = (y_true * y_pred).sum()\n",
        "    dice = (2.0 * inter) / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "\n",
        "    # IoU with sklearn, fallback if it fails\n",
        "    try:\n",
        "        iou = jaccard_score(y_true, y_pred, average=\"binary\")\n",
        "    except Exception:\n",
        "        union = y_true.sum() + y_pred.sum() - inter + 1e-8\n",
        "        iou = inter / union\n",
        "\n",
        "    acc = (y_true == y_pred).mean()\n",
        "    return float(dice), float(iou), float(acc)\n",
        "\n",
        "def plot_prediction(sample_imgs, save_path):\n",
        "    \"\"\"Plot MRI (+ optional regions), GT, and prediction for one batch.\"\"\"\n",
        "    if \"regions\" in sample_imgs:\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
        "    else:\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # MRI\n",
        "    axs[0].imshow(sample_imgs[\"mri\"][0, 0], cmap=\"gray\")\n",
        "    axs[0].set_title(\"MRI\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    col = 1\n",
        "\n",
        "    # Regions (if available)\n",
        "    if \"regions\" in sample_imgs:\n",
        "        axs[col].imshow(sample_imgs[\"regions\"][0, 0], cmap=\"gray\")\n",
        "        axs[col].set_title(\"Regions\")\n",
        "        axs[col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "    # Ground truth\n",
        "    axs[col].imshow(sample_imgs[\"y_true\"][0, 0], cmap=\"gray\")\n",
        "    axs[col].set_title(\"Ground Truth\")\n",
        "    axs[col].axis(\"off\")\n",
        "    col += 1\n",
        "\n",
        "    # Prediction\n",
        "    axs[col].imshow(sample_imgs[\"y_pred\"][0, 0], cmap=\"gray\")\n",
        "    axs[col].set_title(\"Predicted\")\n",
        "    axs[col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics(history, save_path):\n",
        "    \"\"\"Plot training and validation curves for loss and metrics.\"\"\"\n",
        "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss\")\n",
        "\n",
        "    # Dice\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs, history[\"train_dice\"], label=\"Train Dice\")\n",
        "    plt.plot(epochs, history[\"val_dice\"], label=\"Val Dice\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Dice\")\n",
        "\n",
        "    # IoU\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(epochs, history[\"train_iou\"], label=\"Train IoU\")\n",
        "    plt.plot(epochs, history[\"val_iou\"], label=\"Val IoU\")\n",
        "    plt.legend()\n",
        "    plt.title(\"IoU\")\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
        "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Accuracy\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, scaler):\n",
        "    \"\"\"One training epoch over the dataloader.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Mixed precision forward pass\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n",
        "            preds = model(x)\n",
        "            loss = criterion(preds, y)\n",
        "\n",
        "        # Backward with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        # Convert predictions to binary and compute metrics\n",
        "        preds_prob = (torch.sigmoid(preds).detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (y.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, dataloader, criterion, keep_last_batch=True):\n",
        "    \"\"\"Evaluation loop over the validation dataloader.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "    last_batch_imgs = None\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        preds = model(x)\n",
        "        loss = criterion(preds, y)\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        preds_prob = (torch.sigmoid(preds).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "\n",
        "        # Optionally keep last batch for visualization\n",
        "        if keep_last_batch:\n",
        "            ch0 = x[:, 0:1].cpu().numpy()\n",
        "            imgs = {\"mri\": ch0, \"y_true\": y.cpu().numpy(), \"y_pred\": preds_prob}\n",
        "            if x.shape[1] == 2:\n",
        "                ch1 = x[:, 1:2].cpu().numpy()\n",
        "                imgs[\"regions\"] = ch1\n",
        "            last_batch_imgs = imgs\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n, last_batch_imgs\n",
        "\n",
        "def infer_and_visualize_best(\n",
        "    model,\n",
        "    val_dataset,\n",
        "    use_atlas: bool,\n",
        "    out_dir: str,\n",
        "    client_id: int,\n",
        "    best_ckpt_path: str,\n",
        "    k_samples: int = 3,\n",
        "    threshold: float = 0.5,\n",
        "):\n",
        "    \"\"\"Load best checkpoint, run inference on a few validation samples, and save visualizations.\"\"\"\n",
        "    import random\n",
        "\n",
        "    # Make sampling deterministic\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    if os.path.isfile(best_ckpt_path):\n",
        "        model.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "        model.eval()\n",
        "        print(f\"[Best Model] Loaded: {best_ckpt_path}\\n\")\n",
        "    else:\n",
        "        print(f\"[Best Model] Missing checkpoint: {best_ckpt_path}\\n\")\n",
        "        return\n",
        "\n",
        "    k = min(k_samples, len(val_dataset))\n",
        "    if k == 0:\n",
        "        print(\"[Best Model] Empty val dataset.\\n\")\n",
        "        return\n",
        "\n",
        "    # Deterministic random subset of validation indices\n",
        "    idxs = random.sample(range(len(val_dataset)), k)\n",
        "\n",
        "    def _predict_one(sample):\n",
        "        \"\"\"Run model on one sample and return inputs and binarized prediction.\"\"\"\n",
        "        mri = torch.tensor(sample[\"mri\"]).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            regs = torch.tensor(sample[\"regions\"]).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "            x = torch.cat([mri, regs], dim=1)\n",
        "        else:\n",
        "            x = mri\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prob = torch.sigmoid(model(x)).cpu().numpy()\n",
        "            pred_bin = (prob > threshold).astype(np.uint8)\n",
        "\n",
        "        return x.cpu().numpy(), pred_bin\n",
        "\n",
        "    saved_paths = []\n",
        "\n",
        "    # Save individual sample figures\n",
        "    for i, idx in enumerate(idxs, 1):\n",
        "        sample = val_dataset[idx]\n",
        "        pid = sample.get(\"patient_id\", f\"val_{idx}\")\n",
        "        x_np, pred_bin = _predict_one(sample)\n",
        "\n",
        "        imgs = {\n",
        "            \"mri\": x_np[:, 0:1],\n",
        "            \"y_true\": np.expand_dims(\n",
        "                np.expand_dims(sample[\"tumor\"], 0), 0\n",
        "            ).astype(np.float32),\n",
        "            \"y_pred\": pred_bin.astype(np.float32),\n",
        "        }\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            imgs[\"regions\"] = x_np[:, 1:2]\n",
        "\n",
        "        out_path = os.path.join(\n",
        "            out_dir, f\"best_val_sample_{i}_client{client_id}_{pid}.png\"\n",
        "        )\n",
        "        plot_prediction(imgs, out_path)\n",
        "        saved_paths.append(out_path)\n",
        "\n",
        "    print(\"[Best Model] Saved individual figures:\")\n",
        "    for p in saved_paths:\n",
        "        print(\" -\", p)\n",
        "    print()\n",
        "\n",
        "    # Save grid figure\n",
        "    cols = 4 if use_atlas else 3\n",
        "    fig, axs = plt.subplots(k, cols, figsize=(5 * cols, 4 * k))\n",
        "\n",
        "    if k == 1:\n",
        "        axs = np.expand_dims(axs, 0)\n",
        "\n",
        "    for row, idx in enumerate(idxs):\n",
        "        sample = val_dataset[idx]\n",
        "        x_np, pred_bin = _predict_one(sample)\n",
        "\n",
        "        mri = x_np[0, 0]\n",
        "        gt = sample[\"tumor\"]\n",
        "        col = 0\n",
        "\n",
        "        axs[row, col].imshow(mri, cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"MRI\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            regs = x_np[0, 1]\n",
        "            axs[row, col].imshow(regs, cmap=\"gray\")\n",
        "            axs[row, col].set_title(\"Regions\")\n",
        "            axs[row, col].axis(\"off\")\n",
        "            col += 1\n",
        "\n",
        "        axs[row, col].imshow(gt, cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"Ground Truth\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "        axs[row, col].imshow(pred_bin[0, 0], cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"Predicted (τ=0.5)\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    grid_path = os.path.join(out_dir, f\"best_model_val_grid_{run_tag}_client{client_id}.png\")\n",
        "    plt.savefig(grid_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(f\"[Best Model] Saved grid -> {grid_path}\\n\")\n",
        "\n",
        "# History containers for training curves\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_dice\": [],\n",
        "    \"train_iou\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_dice\": [],\n",
        "    \"val_iou\": [],\n",
        "    \"val_acc\": [],\n",
        "}\n",
        "\n",
        "# Tracking best validation metrics\n",
        "best_val_iou = 0.0\n",
        "best_val_dice = -float(\"inf\")\n",
        "best_val_loss = float(\"inf\")\n",
        "best_path = os.path.join(OUT_MODELS_DIR, f\"best_{run_tag}_client{CLIENT_ID}.pth\")\n",
        "\n",
        "log_rows = []\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # Train one epoch\n",
        "    trL, trD, trI, trA = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion, scaler\n",
        "    )\n",
        "    # Validate\n",
        "    vaL, vaD, vaI, vaA, _ = eval_one_epoch(\n",
        "        model, val_loader, criterion, keep_last_batch=True\n",
        "    )\n",
        "\n",
        "    # Update scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save metrics for plots\n",
        "    history[\"train_loss\"].append(trL)\n",
        "    history[\"train_dice\"].append(trD)\n",
        "    history[\"train_iou\"].append(trI)\n",
        "    history[\"train_acc\"].append(trA)\n",
        "\n",
        "    history[\"val_loss\"].append(vaL)\n",
        "    history[\"val_dice\"].append(vaD)\n",
        "    history[\"val_iou\"].append(vaI)\n",
        "    history[\"val_acc\"].append(vaA)\n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch:03d}/{EPOCHS}] \"\n",
        "        f\"Train — Loss {trL:.4f} | Dice {trD:.4f} | IoU {trI:.4f} | Accuracy {trA:.4f} || \"\n",
        "        f\"Val — Loss {vaL:.4f} | Dice {vaD:.4f} | IoU {vaI:.4f} | Accuracy {vaA:.4f}\\n\"\n",
        "    )\n",
        "\n",
        "    # Save checkpoint if Dice improves and loss decreases\n",
        "    saved_ckpt = False\n",
        "    if (vaD > best_val_dice) and (vaL < best_val_loss):\n",
        "        best_val_dice = vaD\n",
        "        best_val_loss = vaL\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        saved_ckpt = True\n",
        "        print(\n",
        "            f\"Saved best model (Val Dice↑ {best_val_dice:.4f} & Val Loss↓ {best_val_loss:.4f}) -> {best_path}\\n\"\n",
        "        )\n",
        "\n",
        "    # Log row for CSV\n",
        "    log_rows.append(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": trL,\n",
        "            \"train_dice\": trD,\n",
        "            \"train_iou\": trI,\n",
        "            \"train_acc\": trA,\n",
        "            \"val_loss\": vaL,\n",
        "            \"val_dice\": vaD,\n",
        "            \"val_iou\": vaI,\n",
        "            \"val_acc\": vaA,\n",
        "            \"saved_ckpt\": saved_ckpt,\n",
        "            \"marker\": \"X\" if saved_ckpt else \"\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Save metrics as CSV\n",
        "metrics_csv = os.path.join(OUT_GRAPHS_DIR, f\"metrics_{run_tag}_client{CLIENT_ID}.csv\")\n",
        "pd.DataFrame(log_rows).to_csv(metrics_csv, index=False)\n",
        "print(f\"[Log] Wrote per-epoch metrics CSV -> {metrics_csv}\\n\")\n",
        "\n",
        "# Plot training curves (tagged)\n",
        "curves_path = os.path.join(OUT_GRAPHS_DIR, f\"training_curves_{run_tag}_client{CLIENT_ID}.png\")\n",
        "plot_metrics(history, curves_path)\n",
        "\n",
        "# Run inference with best model and visualize a few validation samples\n",
        "infer_and_visualize_best(\n",
        "    model=model,\n",
        "    val_dataset=val_dataset,\n",
        "    use_atlas=USE_ATLAS,\n",
        "    out_dir=OUT_GRAPHS_DIR,\n",
        "    client_id=CLIENT_ID,\n",
        "    best_ckpt_path=best_path,\n",
        "    k_samples=3,\n",
        "    threshold=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZjGJX8yVG0C"
      },
      "source": [
        "**<h2>DeepLabV3Plus - \"timm-mobilenetv3_small_100\"<h2>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvaGPwgQPnIQ"
      },
      "outputs": [],
      "source": [
        "import os, json, pickle, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from sklearn.metrics import jaccard_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Paths and I/O config\n",
        "DATA_ROOT = \"/content/Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "OUT_BASE = \"AITDM\"\n",
        "CLIENT_DIR = os.path.join(OUT_BASE, \"/content/client\")\n",
        "\n",
        "# Experiment config\n",
        "USE_ATLAS = True\n",
        "CLIENT_ID = 0\n",
        "BATCH_SIZE = 8\n",
        "LR = 1e-3\n",
        "EPOCHS = 50\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "# Model / encoder config\n",
        "ENCODER_NAME = \"timm-mobilenetv3_small_100\"\n",
        "ENCODER_WEIGHTS = \"imagenet\"\n",
        "\n",
        "# Output directories\n",
        "OUT_MODELS_DIR = os.path.join(OUT_BASE, \"Models\", \"DeepLabV3Plus_ImageOnly\")\n",
        "OUT_GRAPHS_DIR = os.path.join(OUT_BASE, \"Graphs\")\n",
        "os.makedirs(OUT_MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_GRAPHS_DIR, exist_ok=True)\n",
        "\n",
        "def sanitize(s: str) -> str:\n",
        "    return str(s).replace(\"/\", \"-\").replace(\" \", \"_\")\n",
        "\n",
        "encoder_tag = sanitize(ENCODER_NAME)\n",
        "weights_tag = sanitize(ENCODER_WEIGHTS) if ENCODER_WEIGHTS is not None else \"none\"\n",
        "atlas_tag = \"atlas\" if USE_ATLAS else \"img\"\n",
        "\n",
        "run_tag = f\"deeplabv3plus_{encoder_tag}_{weights_tag}_{atlas_tag}\"\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(False)\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    \"\"\"Dataset that loads MRI, tumor mask, and optional atlas regions per patient.\"\"\"\n",
        "\n",
        "    def __init__(self, metadata_df_path, data_root, use_atlas=True, exclude_ids=None, transform=None):\n",
        "        import pickle, os, numpy as np, pandas as pd\n",
        "\n",
        "        # Load metadata dataframe\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        # Optionally exclude some patient IDs\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = [\"PatientID_0191\"]\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        # Collect patient IDs that have all required files\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            mri_p = os.path.join(self.data_root, pid, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(self.data_root, pid, f\"{pid}_tumor.npy\")\n",
        "\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(self.data_root, pid, f\"{pid}_regions.npy\")\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p) and os.path.isfile(reg_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "            else:\n",
        "                if os.path.isfile(mri_p) and os.path.isfile(tumor_p):\n",
        "                    self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        \"\"\"Simple min-max normalization to [0, 1].\"\"\"\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        return (x - mn) / (mx - mn) if mx > mn else np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Load and return one sample (dict) for a patient.\"\"\"\n",
        "        import os, numpy as np\n",
        "\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        # Load MRI and tumor mask\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "        # Normalize MRI and binarize tumor mask\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        # Optionally load regions/atlas\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "            regions = self._minmax(regions)\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "def image_only_collate_fn(batch, use_atlas=True):\n",
        "    \"\"\"Custom collate: stack MRI (+ optional regions) and tumor into tensors.\"\"\"\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        # Concatenate MRI and regions as channels\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": [it[\"patient_id\"] for it in batch]}\n",
        "\n",
        "class SubsetByPIDs(Dataset):\n",
        "    \"\"\"Wrap a dataset but keep only a subset of patient IDs.\"\"\"\n",
        "\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        # Map patient IDs to indices\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Load client-specific train/val patient IDs\n",
        "cdir = os.path.join(CLIENT_DIR, f\"client_{CLIENT_ID}\")\n",
        "with open(os.path.join(cdir, \"train_pids.json\"), \"r\") as f:\n",
        "    train_pids = json.load(f)\n",
        "with open(os.path.join(cdir, \"val_pids.json\"), \"r\") as f:\n",
        "    val_pids = json.load(f)\n",
        "\n",
        "# Build full dataset and then client subsets\n",
        "full_ds = ImageOnlyGliomaDataset(\n",
        "    METADATA_DF_PATH,\n",
        "    DATA_ROOT,\n",
        "    use_atlas=USE_ATLAS,\n",
        "    exclude_ids=[\"PatientID_0191\"],\n",
        ")\n",
        "train_dataset = SubsetByPIDs(full_ds, train_pids)\n",
        "val_dataset = SubsetByPIDs(full_ds, val_pids)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        "    worker_init_fn=worker_init_fn,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        "    worker_init_fn=worker_init_fn,\n",
        ")\n",
        "\n",
        "print(f\"Loaded client_{CLIENT_ID}: train patients={len(train_dataset)}, val patients={len(val_dataset)}\")\n",
        "\n",
        "# UNet model (from segmentation_models_pytorch)\n",
        "in_channels = 2 if USE_ATLAS else 1\n",
        "model = smp.DeepLabV3Plus(\n",
        "    encoder_name=ENCODER_NAME,\n",
        "    encoder_weights=ENCODER_WEIGHTS,\n",
        "    in_channels=in_channels,\n",
        "    classes=1,\n",
        ").to(device)\n",
        "\n",
        "# Loss, optimizer, scheduler, and AMP scaler\n",
        "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer, start_factor=1.0, end_factor=0.0, total_iters=EPOCHS\n",
        ")\n",
        "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
        "\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    \"\"\"Compute Dice, IoU, and pixel accuracy.\"\"\"\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "\n",
        "    inter = (y_true * y_pred).sum()\n",
        "    dice = (2.0 * inter) / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "\n",
        "    # IoU with sklearn, fallback if it fails\n",
        "    try:\n",
        "        iou = jaccard_score(y_true, y_pred, average=\"binary\")\n",
        "    except Exception:\n",
        "        union = y_true.sum() + y_pred.sum() - inter + 1e-8\n",
        "        iou = inter / union\n",
        "\n",
        "    acc = (y_true == y_pred).mean()\n",
        "    return float(dice), float(iou), float(acc)\n",
        "\n",
        "def plot_prediction(sample_imgs, save_path):\n",
        "    \"\"\"Plot MRI (+ optional regions), GT, and prediction for one batch.\"\"\"\n",
        "    if \"regions\" in sample_imgs:\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
        "    else:\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # MRI\n",
        "    axs[0].imshow(sample_imgs[\"mri\"][0, 0], cmap=\"gray\")\n",
        "    axs[0].set_title(\"MRI\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    col = 1\n",
        "\n",
        "    # Regions (if available)\n",
        "    if \"regions\" in sample_imgs:\n",
        "        axs[col].imshow(sample_imgs[\"regions\"][0, 0], cmap=\"gray\")\n",
        "        axs[col].set_title(\"Regions\")\n",
        "        axs[col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "    # Ground truth\n",
        "    axs[col].imshow(sample_imgs[\"y_true\"][0, 0], cmap=\"gray\")\n",
        "    axs[col].set_title(\"Ground Truth\")\n",
        "    axs[col].axis(\"off\")\n",
        "    col += 1\n",
        "\n",
        "    # Prediction\n",
        "    axs[col].imshow(sample_imgs[\"y_pred\"][0, 0], cmap=\"gray\")\n",
        "    axs[col].set_title(\"Predicted\")\n",
        "    axs[col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics(history, save_path):\n",
        "    \"\"\"Plot training and validation curves for loss and metrics.\"\"\"\n",
        "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss\")\n",
        "\n",
        "    # Dice\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs, history[\"train_dice\"], label=\"Train Dice\")\n",
        "    plt.plot(epochs, history[\"val_dice\"], label=\"Val Dice\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Dice\")\n",
        "\n",
        "    # IoU\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(epochs, history[\"train_iou\"], label=\"Train IoU\")\n",
        "    plt.plot(epochs, history[\"val_iou\"], label=\"Val IoU\")\n",
        "    plt.legend()\n",
        "    plt.title(\"IoU\")\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
        "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Accuracy\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, scaler):\n",
        "    \"\"\"One training epoch over the dataloader.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Mixed precision forward pass\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n",
        "            preds = model(x)\n",
        "            loss = criterion(preds, y)\n",
        "\n",
        "        # Backward with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        # Convert predictions to binary and compute metrics\n",
        "        preds_prob = (torch.sigmoid(preds).detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (y.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, dataloader, criterion, keep_last_batch=True):\n",
        "    \"\"\"Evaluation loop over the validation dataloader.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "    last_batch_imgs = None\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        preds = model(x)\n",
        "        loss = criterion(preds, y)\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        preds_prob = (torch.sigmoid(preds).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "        d, i, a = calc_metrics(y_np, preds_prob)\n",
        "\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "\n",
        "        # Optionally keep last batch for visualization\n",
        "        if keep_last_batch:\n",
        "            ch0 = x[:, 0:1].cpu().numpy()\n",
        "            imgs = {\"mri\": ch0, \"y_true\": y.cpu().numpy(), \"y_pred\": preds_prob}\n",
        "            if x.shape[1] == 2:\n",
        "                ch1 = x[:, 1:2].cpu().numpy()\n",
        "                imgs[\"regions\"] = ch1\n",
        "            last_batch_imgs = imgs\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n, total_acc / n, last_batch_imgs\n",
        "\n",
        "def infer_and_visualize_best(\n",
        "    model,\n",
        "    val_dataset,\n",
        "    use_atlas: bool,\n",
        "    out_dir: str,\n",
        "    client_id: int,\n",
        "    best_ckpt_path: str,\n",
        "    k_samples: int = 3,\n",
        "    threshold: float = 0.5,\n",
        "):\n",
        "    \"\"\"Load best checkpoint, run inference on a few validation samples, and save visualizations.\"\"\"\n",
        "    import random\n",
        "\n",
        "    # Make sampling deterministic\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    if os.path.isfile(best_ckpt_path):\n",
        "        model.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "        model.eval()\n",
        "        print(f\"[Best Model] Loaded: {best_ckpt_path}\\n\")\n",
        "    else:\n",
        "        print(f\"[Best Model] Missing checkpoint: {best_ckpt_path}\\n\")\n",
        "        return\n",
        "\n",
        "    k = min(k_samples, len(val_dataset))\n",
        "    if k == 0:\n",
        "        print(\"[Best Model] Empty val dataset.\\n\")\n",
        "        return\n",
        "\n",
        "    # Deterministic random subset of validation indices\n",
        "    idxs = random.sample(range(len(val_dataset)), k)\n",
        "\n",
        "    def _predict_one(sample):\n",
        "        \"\"\"Run model on one sample and return inputs and binarized prediction.\"\"\"\n",
        "        mri = torch.tensor(sample[\"mri\"]).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            regs = torch.tensor(sample[\"regions\"]).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "            x = torch.cat([mri, regs], dim=1)\n",
        "        else:\n",
        "            x = mri\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prob = torch.sigmoid(model(x)).cpu().numpy()\n",
        "            pred_bin = (prob > threshold).astype(np.uint8)\n",
        "\n",
        "        return x.cpu().numpy(), pred_bin\n",
        "\n",
        "    saved_paths = []\n",
        "\n",
        "    # Save individual sample figures\n",
        "    for i, idx in enumerate(idxs, 1):\n",
        "        sample = val_dataset[idx]\n",
        "        pid = sample.get(\"patient_id\", f\"val_{idx}\")\n",
        "        x_np, pred_bin = _predict_one(sample)\n",
        "\n",
        "        imgs = {\n",
        "            \"mri\": x_np[:, 0:1],\n",
        "            \"y_true\": np.expand_dims(\n",
        "                np.expand_dims(sample[\"tumor\"], 0), 0\n",
        "            ).astype(np.float32),\n",
        "            \"y_pred\": pred_bin.astype(np.float32),\n",
        "        }\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            imgs[\"regions\"] = x_np[:, 1:2]\n",
        "\n",
        "        out_path = os.path.join(\n",
        "            out_dir, f\"best_val_sample_{i}_client{client_id}_{pid}.png\"\n",
        "        )\n",
        "        plot_prediction(imgs, out_path)\n",
        "        saved_paths.append(out_path)\n",
        "\n",
        "    print(\"[Best Model] Saved individual figures:\")\n",
        "    for p in saved_paths:\n",
        "        print(\" -\", p)\n",
        "    print()\n",
        "\n",
        "    # Save grid figure\n",
        "    cols = 4 if use_atlas else 3\n",
        "    fig, axs = plt.subplots(k, cols, figsize=(5 * cols, 4 * k))\n",
        "\n",
        "    if k == 1:\n",
        "        axs = np.expand_dims(axs, 0)\n",
        "\n",
        "    for row, idx in enumerate(idxs):\n",
        "        sample = val_dataset[idx]\n",
        "        x_np, pred_bin = _predict_one(sample)\n",
        "\n",
        "        mri = x_np[0, 0]\n",
        "        gt = sample[\"tumor\"]\n",
        "        col = 0\n",
        "\n",
        "        axs[row, col].imshow(mri, cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"MRI\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "        if use_atlas and (\"regions\" in sample):\n",
        "            regs = x_np[0, 1]\n",
        "            axs[row, col].imshow(regs, cmap=\"gray\")\n",
        "            axs[row, col].set_title(\"Regions\")\n",
        "            axs[row, col].axis(\"off\")\n",
        "            col += 1\n",
        "\n",
        "        axs[row, col].imshow(gt, cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"Ground Truth\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "        col += 1\n",
        "\n",
        "        axs[row, col].imshow(pred_bin[0, 0], cmap=\"gray\")\n",
        "        axs[row, col].set_title(\"Predicted (τ=0.5)\")\n",
        "        axs[row, col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    grid_path = os.path.join(out_dir, f\"best_model_val_grid_{run_tag}_client{client_id}.png\")\n",
        "    plt.savefig(grid_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(f\"[Best Model] Saved grid -> {grid_path}\\n\")\n",
        "\n",
        "# History containers for training curves\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_dice\": [],\n",
        "    \"train_iou\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_dice\": [],\n",
        "    \"val_iou\": [],\n",
        "    \"val_acc\": [],\n",
        "}\n",
        "\n",
        "# Tracking best validation metrics\n",
        "best_val_iou = 0.0\n",
        "best_val_dice = -float(\"inf\")\n",
        "best_val_loss = float(\"inf\")\n",
        "best_path = os.path.join(OUT_MODELS_DIR, f\"best_{run_tag}_client{CLIENT_ID}.pth\")\n",
        "\n",
        "log_rows = []\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # Train one epoch\n",
        "    trL, trD, trI, trA = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion, scaler\n",
        "    )\n",
        "    # Validate\n",
        "    vaL, vaD, vaI, vaA, _ = eval_one_epoch(\n",
        "        model, val_loader, criterion, keep_last_batch=True\n",
        "    )\n",
        "\n",
        "    # Update scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save metrics for plots\n",
        "    history[\"train_loss\"].append(trL)\n",
        "    history[\"train_dice\"].append(trD)\n",
        "    history[\"train_iou\"].append(trI)\n",
        "    history[\"train_acc\"].append(trA)\n",
        "\n",
        "    history[\"val_loss\"].append(vaL)\n",
        "    history[\"val_dice\"].append(vaD)\n",
        "    history[\"val_iou\"].append(vaI)\n",
        "    history[\"val_acc\"].append(vaA)\n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch:03d}/{EPOCHS}] \"\n",
        "        f\"Train — Loss {trL:.4f} | Dice {trD:.4f} | IoU {trI:.4f} | Accuracy {trA:.4f} || \"\n",
        "        f\"Val — Loss {vaL:.4f} | Dice {vaD:.4f} | IoU {vaI:.4f} | Accuracy {vaA:.4f}\\n\"\n",
        "    )\n",
        "\n",
        "    # Save checkpoint if Dice improves and loss decreases\n",
        "    saved_ckpt = False\n",
        "    if (vaD > best_val_dice) and (vaL < best_val_loss):\n",
        "        best_val_dice = vaD\n",
        "        best_val_loss = vaL\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        saved_ckpt = True\n",
        "        print(\n",
        "            f\"Saved best model (Val Dice↑ {best_val_dice:.4f} & Val Loss↓ {best_val_loss:.4f}) -> {best_path}\\n\"\n",
        "        )\n",
        "\n",
        "    # Log row for CSV\n",
        "    log_rows.append(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": trL,\n",
        "            \"train_dice\": trD,\n",
        "            \"train_iou\": trI,\n",
        "            \"train_acc\": trA,\n",
        "            \"val_loss\": vaL,\n",
        "            \"val_dice\": vaD,\n",
        "            \"val_iou\": vaI,\n",
        "            \"val_acc\": vaA,\n",
        "            \"saved_ckpt\": saved_ckpt,\n",
        "            \"marker\": \"X\" if saved_ckpt else \"\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Save metrics as CSV\n",
        "metrics_csv = os.path.join(OUT_GRAPHS_DIR, f\"metrics_{run_tag}_client{CLIENT_ID}.csv\")\n",
        "pd.DataFrame(log_rows).to_csv(metrics_csv, index=False)\n",
        "print(f\"[Log] Wrote per-epoch metrics CSV -> {metrics_csv}\\n\")\n",
        "\n",
        "# Plot training curves (tagged)\n",
        "curves_path = os.path.join(OUT_GRAPHS_DIR, f\"training_curves_{run_tag}_client{CLIENT_ID}.png\")\n",
        "plot_metrics(history, curves_path)\n",
        "\n",
        "# Run inference with best model and visualize a few validation samples\n",
        "infer_and_visualize_best(\n",
        "    model=model,\n",
        "    val_dataset=val_dataset,\n",
        "    use_atlas=USE_ATLAS,\n",
        "    out_dir=OUT_GRAPHS_DIR,\n",
        "    client_id=CLIENT_ID,\n",
        "    best_ckpt_path=best_path,\n",
        "    k_samples=3,\n",
        "    threshold=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdquMfwqMDg4"
      },
      "source": [
        "**<h2>Ensemble<h2>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmoBrDCRS57T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import segmentation_models_pytorch as smp\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEED = 42\n",
        "USE_ATLAS = True\n",
        "THRESHOLD = 0.5\n",
        "K_SAMPLES = 3\n",
        "\n",
        "OUT_BASE = \"AITDM\"\n",
        "OUT_GRAPHS_DIR = os.path.join(OUT_BASE, \"Graphs\")\n",
        "os.makedirs(OUT_GRAPHS_DIR, exist_ok=True)\n",
        "\n",
        "OUT_MODELS_UNET_DIR = os.path.join(OUT_BASE, \"Models\", \"UNet_ImageOnly\")\n",
        "CKPT_RESNET50 = os.path.join(OUT_MODELS_UNET_DIR, \"best_unet_resnet50_imagenet_atlas_client0.pth\")\n",
        "CKPT_MITB3 = os.path.join(OUT_MODELS_UNET_DIR, \"best_unet_mit_b3_imagenet_atlas_client0.pth\")\n",
        "\n",
        "OUT_MODELS_DLV3P_DIR = os.path.join(OUT_BASE, \"Models\", \"DeepLabV3Plus_ImageOnly\")\n",
        "CKPT_DLV3P = os.path.join(\n",
        "    OUT_MODELS_DLV3P_DIR,\n",
        "    \"best_deeplabv3plus_timm-mobilenetv3_small_100_imagenet_atlas_client0.pth\",\n",
        ")\n",
        "\n",
        "ENS_WEIGHTS = [2.5 / 10, 2.5 / 10, 5 / 10]\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "\n",
        "    inter = (y_true * y_pred).sum()\n",
        "    dice = (2.0 * inter) / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "\n",
        "    try:\n",
        "        iou = jaccard_score(y_true, y_pred, average=\"binary\")\n",
        "    except Exception:\n",
        "        union = y_true.sum() + y_pred.sum() - inter + 1e-8\n",
        "        iou = inter / union\n",
        "\n",
        "    acc = (y_true == y_pred).mean()\n",
        "    return float(dice), float(iou), float(acc)\n",
        "\n",
        "\n",
        "def plot_prediction(imgs, save_path, title=None):\n",
        "    has_regions = \"regions\" in imgs\n",
        "    cols = 4 if has_regions else 3\n",
        "    fig, axs = plt.subplots(1, cols, figsize=(5 * cols, 5))\n",
        "\n",
        "    axs[0].imshow(imgs[\"mri\"][0, 0], cmap=\"gray\")\n",
        "    axs[0].set_title(\"MRI\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    c = 1\n",
        "    if has_regions:\n",
        "        axs[c].imshow(imgs[\"regions\"][0, 0], cmap=\"gray\")\n",
        "        axs[c].set_title(\"Regions\")\n",
        "        axs[c].axis(\"off\")\n",
        "        c += 1\n",
        "\n",
        "    axs[c].imshow(imgs[\"y_true\"][0, 0], cmap=\"gray\")\n",
        "    axs[c].set_title(\"Ground Truth\")\n",
        "    axs[c].axis(\"off\")\n",
        "    c += 1\n",
        "\n",
        "    axs[c].imshow(imgs[\"y_pred\"][0, 0], cmap=\"gray\")\n",
        "    axs[c].set_title(f\"Ensemble (τ={THRESHOLD})\")\n",
        "    axs[c].axis(\"off\")\n",
        "\n",
        "    if title:\n",
        "        fig.suptitle(title, y=1.02)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def build_unet(encoder_name, encoder_weights=\"imagenet\", in_channels=2, classes=1):\n",
        "    return smp.Unet(\n",
        "        encoder_name=encoder_name,\n",
        "        encoder_weights=encoder_weights,\n",
        "        in_channels=in_channels,\n",
        "        classes=classes,\n",
        "    )\n",
        "\n",
        "\n",
        "def build_deeplabv3p(encoder_name, encoder_weights=\"imagenet\", in_channels=2, classes=1):\n",
        "    return smp.DeepLabV3Plus(\n",
        "        encoder_name=encoder_name,\n",
        "        encoder_weights=encoder_weights,\n",
        "        in_channels=in_channels,\n",
        "        classes=classes,\n",
        "    )\n",
        "\n",
        "\n",
        "def load_model_unet(encoder_name, ckpt_path, in_channels):\n",
        "    assert os.path.isfile(ckpt_path), f\"Missing checkpoint: {ckpt_path}\"\n",
        "    m = build_unet(encoder_name, \"imagenet\", in_channels=in_channels, classes=1).to(DEVICE)\n",
        "    m.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n",
        "    m.eval()\n",
        "    return m\n",
        "\n",
        "\n",
        "def load_model_dlv3p(encoder_name, ckpt_path, in_channels):\n",
        "    assert os.path.isfile(ckpt_path), f\"Missing checkpoint: {ckpt_path}\"\n",
        "    m = build_deeplabv3p(encoder_name, \"imagenet\", in_channels=in_channels, classes=1).to(DEVICE)\n",
        "    m.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n",
        "    m.eval()\n",
        "    return m\n",
        "\n",
        "\n",
        "in_channels = 2 if USE_ATLAS else 1\n",
        "model_r50 = load_model_unet(\"resnet50\", CKPT_RESNET50, in_channels=in_channels)\n",
        "model_mit3 = load_model_unet(\"mit_b3\", CKPT_MITB3, in_channels=in_channels)\n",
        "model_dlv3p = load_model_dlv3p(\"timm-mobilenetv3_small_100\", CKPT_DLV3P, in_channels=in_channels)\n",
        "\n",
        "MODELS = [model_r50, model_mit3, model_dlv3p]\n",
        "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ensemble_forward_logits_multi(x, models, weights, target_hw=None):\n",
        "    # Weighted sum of logits; resize to target_hw if needed\n",
        "    w = np.array(weights, dtype=np.float32)\n",
        "    w = w / (w.sum() + 1e-8)\n",
        "\n",
        "    logits_sum = None\n",
        "    for mi, wi in zip(models, w):\n",
        "        li = mi(x)\n",
        "        if target_hw is not None and li.shape[-2:] != target_hw:\n",
        "            li = F.interpolate(li, size=target_hw, mode=\"bilinear\", align_corners=False)\n",
        "        logits_sum = li * float(wi) if logits_sum is None else logits_sum + li * float(wi)\n",
        "\n",
        "    return logits_sum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch_ensemble(dataloader, models, weights, threshold=0.5, criterion=None, keep_last_batch=True):\n",
        "    # Metrics are computed per-batch, then averaged across batches\n",
        "    total_loss = total_dice = total_iou = total_acc = 0.0\n",
        "    last_batch_imgs = None\n",
        "    n = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[\"x\"].to(DEVICE)\n",
        "        y = batch[\"y\"].to(DEVICE)\n",
        "\n",
        "        logits = ensemble_forward_logits_multi(x, models=models, weights=weights, target_hw=y.shape[-2:])\n",
        "\n",
        "        if criterion is not None:\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += float(loss.item())\n",
        "\n",
        "        preds_bin = (torch.sigmoid(logits).detach().cpu().numpy() > threshold).astype(np.uint8)\n",
        "        y_np = (y.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        d, i, a = calc_metrics(y_np, preds_bin)\n",
        "        total_dice += d\n",
        "        total_iou += i\n",
        "        total_acc += a\n",
        "        n += 1\n",
        "\n",
        "        if keep_last_batch:\n",
        "            ch0 = x[:, 0:1].detach().cpu().numpy()\n",
        "            imgs = {\"mri\": ch0, \"y_true\": y.detach().cpu().numpy(), \"y_pred\": preds_bin}\n",
        "            if x.shape[1] == 2:\n",
        "                imgs[\"regions\"] = x[:, 1:2].detach().cpu().numpy()\n",
        "            last_batch_imgs = imgs\n",
        "\n",
        "    mean_loss = (total_loss / n) if (criterion is not None and n > 0) else None\n",
        "    mean_dice = total_dice / max(n, 1)\n",
        "    mean_iou = total_iou / max(n, 1)\n",
        "    mean_acc = total_acc / max(n, 1)\n",
        "\n",
        "    return mean_loss, mean_dice, mean_iou, mean_acc, last_batch_imgs\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ensemble_infer_and_visualize(val_dataset, out_dir, models, weights, k_samples=3, threshold=0.5):\n",
        "    # Visualization only (random K patients)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    k = min(k_samples, len(val_dataset))\n",
        "    if k == 0:\n",
        "        print(\"Empty val_dataset.\")\n",
        "        return\n",
        "\n",
        "    set_seed(SEED)\n",
        "    idxs = random.sample(range(len(val_dataset)), k)\n",
        "    per_sample = []\n",
        "\n",
        "    for i, idx in enumerate(idxs, 1):\n",
        "        sample = val_dataset[idx]\n",
        "        pid = sample.get(\"patient_id\", f\"val_{idx}\")\n",
        "\n",
        "        mri = torch.tensor(sample[\"mri\"]).unsqueeze(0).unsqueeze(0).float()\n",
        "        y = torch.tensor(sample[\"tumor\"]).unsqueeze(0).unsqueeze(0).float()\n",
        "\n",
        "        if USE_ATLAS and (\"regions\" in sample):\n",
        "            reg = torch.tensor(sample[\"regions\"]).unsqueeze(0).unsqueeze(0).float()\n",
        "            x = torch.cat([mri, reg], dim=1)\n",
        "        else:\n",
        "            x = mri\n",
        "\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        logits = ensemble_forward_logits_multi(x, models=models, weights=weights, target_hw=y.shape[-2:])\n",
        "        pred_bin = (torch.sigmoid(logits).cpu().numpy() > threshold).astype(np.uint8)\n",
        "        y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        d, iou, acc = calc_metrics(y_np, pred_bin)\n",
        "\n",
        "        x_np = x.detach().cpu().numpy()\n",
        "        imgs = {\"mri\": x_np[:, 0:1], \"y_true\": y.detach().cpu().numpy(), \"y_pred\": pred_bin.astype(np.float32)}\n",
        "        if USE_ATLAS and x_np.shape[1] == 2:\n",
        "            imgs[\"regions\"] = x_np[:, 1:2]\n",
        "\n",
        "        out_path = os.path.join(out_dir, f\"ensemble3_val_sample_{i}_{pid}.png\")\n",
        "        plot_prediction(imgs, out_path, title=f\"{pid} | Dice={d:.4f} IoU={iou:.4f} Acc={acc:.4f}\")\n",
        "        per_sample.append({\"pid\": pid, \"dice\": d, \"iou\": iou, \"acc\": acc, \"path\": out_path})\n",
        "\n",
        "    print(\"[Ensemble-3] Saved individual figures:\")\n",
        "    for r in per_sample:\n",
        "        print(f\" - {r['pid']}: Dice={r['dice']:.4f} IoU={r['iou']:.4f} Acc={r['acc']:.4f} -> {r['path']}\")\n",
        "\n",
        "    cols = 4 if USE_ATLAS else 3\n",
        "    fig, axs = plt.subplots(k, cols, figsize=(5 * cols, 4 * k))\n",
        "    if k == 1:\n",
        "        axs = np.expand_dims(axs, 0)\n",
        "\n",
        "    for row, idx in enumerate(idxs):\n",
        "        sample = val_dataset[idx]\n",
        "\n",
        "        mri = torch.tensor(sample[\"mri\"]).unsqueeze(0).unsqueeze(0).float()\n",
        "        y = torch.tensor(sample[\"tumor\"]).unsqueeze(0).unsqueeze(0).float()\n",
        "\n",
        "        if USE_ATLAS and (\"regions\" in sample):\n",
        "            reg = torch.tensor(sample[\"regions\"]).unsqueeze(0).unsqueeze(0).float()\n",
        "            x = torch.cat([mri, reg], dim=1)\n",
        "        else:\n",
        "            x = mri\n",
        "\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        logits = ensemble_forward_logits_multi(x, models=models, weights=weights, target_hw=y.shape[-2:])\n",
        "        pred_bin = (torch.sigmoid(logits).cpu().numpy() > threshold).astype(np.uint8)\n",
        "        y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        d, _, _ = calc_metrics(y_np, pred_bin)\n",
        "        x_np = x.detach().cpu().numpy()\n",
        "\n",
        "        c = 0\n",
        "        axs[row, c].imshow(x_np[0, 0], cmap=\"gray\")\n",
        "        axs[row, c].set_title(\"MRI\")\n",
        "        axs[row, c].axis(\"off\")\n",
        "        c += 1\n",
        "\n",
        "        if USE_ATLAS and x_np.shape[1] == 2:\n",
        "            axs[row, c].imshow(x_np[0, 1], cmap=\"gray\")\n",
        "            axs[row, c].set_title(\"Regions\")\n",
        "            axs[row, c].axis(\"off\")\n",
        "            c += 1\n",
        "\n",
        "        axs[row, c].imshow(y_np[0, 0], cmap=\"gray\")\n",
        "        axs[row, c].set_title(\"GT\")\n",
        "        axs[row, c].axis(\"off\")\n",
        "        c += 1\n",
        "\n",
        "        axs[row, c].imshow(pred_bin[0, 0], cmap=\"gray\")\n",
        "        axs[row, c].set_title(f\"Ens τ={threshold}\\nDice={d:.3f}\")\n",
        "        axs[row, c].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    wtag = \"-\".join([f\"{w:.2f}\" for w in (np.array(weights) / (np.sum(weights) + 1e-8))])\n",
        "    grid_path = os.path.join(out_dir, f\"ensemble3_val_grid_tau{threshold}_w{wtag}.png\")\n",
        "    plt.savefig(grid_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(f\"[Ensemble-3] Saved grid -> {grid_path}\")\n",
        "\n",
        "\n",
        "# Assumes val_loader and val_dataset already exist in your notebook\n",
        "ens_loss, ens_d, ens_i, ens_a, last_imgs = eval_one_epoch_ensemble(\n",
        "    dataloader=val_loader,\n",
        "    models=MODELS,\n",
        "    weights=ENS_WEIGHTS,\n",
        "    threshold=THRESHOLD,\n",
        "    criterion=criterion,\n",
        "    keep_last_batch=True,\n",
        ")\n",
        "\n",
        "print(f\"[Ensemble-3 Val] Loss {ens_loss:.4f} | Dice {ens_d:.4f} | IoU {ens_i:.4f} | Acc {ens_a:.4f}\")\n",
        "\n",
        "if last_imgs is not None:\n",
        "    out_path = os.path.join(OUT_GRAPHS_DIR, f\"ensemble3_last_batch_tau{THRESHOLD}.png\")\n",
        "    plot_prediction(last_imgs, out_path, title=\"Ensemble-3 - last val batch\")\n",
        "\n",
        "ensemble_infer_and_visualize(\n",
        "    val_dataset=val_dataset,\n",
        "    out_dir=OUT_GRAPHS_DIR,\n",
        "    models=MODELS,\n",
        "    weights=ENS_WEIGHTS,\n",
        "    k_samples=K_SAMPLES,\n",
        "    threshold=THRESHOLD,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pf52xcpQyUg"
      },
      "source": [
        "# **M2 - FL with ensemble**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPgflPCuQ5vh",
        "outputId": "da63e704-a183-407e-8861-e78da0fc41ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting seg_data.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile seg_data.py\n",
        "import os, pickle, numpy as np, torch\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchio as tio\n",
        "\n",
        "# Global paths and configuration\n",
        "DATA_ROOT = \"/content/Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "USE_ATLAS = True\n",
        "EXCLUDE_IDS = [\"PatientID_0191\"]\n",
        "\n",
        "# Dataset that loads MRI, tumor mask and optional atlas for each patient\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        metadata_df_path,\n",
        "        data_root,\n",
        "        use_atlas=False,\n",
        "        exclude_ids=None,\n",
        "        transform=None,\n",
        "    ):\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = []\n",
        "\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            base = os.path.join(self.data_root, pid)\n",
        "            mri_p = os.path.join(base, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(base, f\"{pid}_tumor.npy\")\n",
        "\n",
        "            is_valid = os.path.isfile(mri_p) and os.path.isfile(tumor_p)\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(base, f\"{pid}_regions.npy\")\n",
        "                is_valid = is_valid and os.path.isfile(reg_p)\n",
        "\n",
        "            if is_valid:\n",
        "                self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        if mx > mn:\n",
        "            return (x - mn) / (mx - mn)\n",
        "        return np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    def _to_torchio_format(self, arr):\n",
        "        \"\"\"\n",
        "        Convertește (H, W) -> (1, H, W, 1) pentru procesare internă TorchIO.\n",
        "        \"\"\"\n",
        "        if arr.ndim == 2:\n",
        "            return arr[np.newaxis, ..., np.newaxis]\n",
        "        return arr\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "\n",
        "        regions = None\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        if regions is not None:\n",
        "            regions = self._minmax(regions)\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            subject_dict = {\n",
        "                'mri': tio.ScalarImage(tensor=self._to_torchio_format(mri)),\n",
        "                'tumor': tio.LabelMap(tensor=self._to_torchio_format(tumor)),\n",
        "            }\n",
        "            if regions is not None:\n",
        "                subject_dict['regions'] = tio.ScalarImage(tensor=self._to_torchio_format(regions))\n",
        "\n",
        "            subject = tio.Subject(subject_dict)\n",
        "\n",
        "            subject = self.transform(subject)\n",
        "\n",
        "            out_mri = subject['mri'].data[0, ..., 0].numpy()\n",
        "            out_tumor = subject['tumor'].data[0, ..., 0].numpy()\n",
        "            sample = {\n",
        "                \"patient_id\": pid,\n",
        "                \"mri\": out_mri,       # Shape: (240, 240)\n",
        "                \"tumor\": out_tumor    # Shape: (240, 240)\n",
        "            }\n",
        "\n",
        "            if regions is not None:\n",
        "                out_regions = subject['regions'].data[0, ..., 0].numpy()\n",
        "                sample[\"regions\"] = out_regions # Shape: (240, 240)\n",
        "\n",
        "            return sample\n",
        "\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        if self.use_atlas:\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "# Collate function to build batched tensors and patient ID list\n",
        "def image_only_collate_fn(batch, use_atlas=USE_ATLAS):\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": [it[\"patient_id\"] for it in batch]}\n",
        "\n",
        "# Dataset wrapper that restricts to a subset of patient IDs\n",
        "class SubsetByPIDs(Dataset):\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Compute Dice, IoU and accuracy for binary masks\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "\n",
        "    inter = (y_true & y_pred).sum()\n",
        "    dice = (2.0 * inter) / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "    union = y_true.sum() + y_pred.sum() - inter + 1e-8\n",
        "    iou = inter / union\n",
        "    acc = (y_true == y_pred).mean()\n",
        "\n",
        "    return float(dice), float(iou), float(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3xGGSblAMp7",
        "outputId": "d8a14e44-2ba8-4efc-8c5f-7da03b79a01a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting fl_client.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile fl_client.py\n",
        "import os\n",
        "os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":4096:8\")\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import flwr as fl\n",
        "import copy\n",
        "import segmentation_models_pytorch as smp\n",
        "import random\n",
        "import torchio as tio\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from seg_data import (\n",
        "    ImageOnlyGliomaDataset,\n",
        "    SubsetByPIDs,\n",
        "    image_only_collate_fn,\n",
        "    calc_metrics,\n",
        "    DATA_ROOT,\n",
        "    METADATA_DF_PATH,\n",
        "    USE_ATLAS,\n",
        ")\n",
        "\n",
        "CLIENT_DIR = \"/content/client\"\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "DEFAULT_MODEL_NAME = \"unet\"\n",
        "DEFAULT_ENCODER_NAME = \"timm-mobilenetv3_small_100\"\n",
        "DEFAULT_ENCODER_WEIGHTS = \"imagenet\"\n",
        "TRANSFORMS = None\n",
        "\n",
        "\n",
        "def _run_name(model_name: str, encoder_name: str) -> str:\n",
        "    return f\"{model_name}__{encoder_name}\".replace(\"/\", \"-\")\n",
        "\n",
        "\n",
        "def seed_everything(seed: int, deterministic: bool = True) -> None:\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    try:\n",
        "        torch.set_float32_matmul_precision(\"high\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    if deterministic:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id: int) -> None:\n",
        "    worker_seed = (torch.initial_seed() + worker_id) % (2**32)\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def log_transfer_metrics(file_path, cid, rnd, incoming, outgoing, overhead):\n",
        "    \"\"\"Functie helper pentru a salva metricile de transfer in fisier.\"\"\"\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    msg = (f\"Client {cid} Round {rnd}: \"\n",
        "           f\"Incoming {incoming/1024:.2f} KB | \"\n",
        "           f\"Outgoing {outgoing/1024:.2f} KB | \"\n",
        "           f\"Overhead: {overhead:.6f}s\\n\")\n",
        "\n",
        "\n",
        "    with open(file_path, \"a\") as f:\n",
        "        f.write(msg)\n",
        "\n",
        "\n",
        "def get_model(\n",
        "    model_name=DEFAULT_MODEL_NAME,\n",
        "    encoder_name=DEFAULT_ENCODER_NAME,\n",
        "    encoder_weights=DEFAULT_ENCODER_WEIGHTS,\n",
        "):\n",
        "    in_ch = 2 if USE_ATLAS else 1\n",
        "    mn = model_name.lower()\n",
        "\n",
        "    if mn == \"unet\":\n",
        "        model = smp.Unet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    elif mn in [\"deeplabv3plus\", \"deeplabv3+\", \"dlv3p\"]:\n",
        "        model = smp.DeepLabV3Plus(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_name={model_name}. Use 'unet' or 'deeplabv3plus'.\")\n",
        "\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "\n",
        "def get_loaders(cid: int, base_seed: int, transforms):\n",
        "    full = ImageOnlyGliomaDataset(\n",
        "        METADATA_DF_PATH,\n",
        "        DATA_ROOT,\n",
        "        use_atlas=USE_ATLAS,\n",
        "        exclude_ids=[\"PatientID_0191\"],\n",
        "        transform=transforms,\n",
        "    )\n",
        "\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"train_pids.json\")) as f:\n",
        "        tr_p = json.load(f)\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"val_pids.json\")) as f:\n",
        "        va_p = json.load(f)\n",
        "\n",
        "    ds_tr = SubsetByPIDs(full, tr_p)\n",
        "    ds_va = SubsetByPIDs(full, va_p)\n",
        "\n",
        "    g_tr = torch.Generator().manual_seed(base_seed + 12345)\n",
        "    g_va = torch.Generator().manual_seed(base_seed + 67890)\n",
        "\n",
        "    ld_tr = DataLoader(\n",
        "        ds_tr,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g_tr,\n",
        "        persistent_workers=(NUM_WORKERS > 0),\n",
        "    )\n",
        "\n",
        "    ld_va = DataLoader(\n",
        "        ds_va,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g_va,\n",
        "        persistent_workers=(NUM_WORKERS > 0),\n",
        "    )\n",
        "\n",
        "    return ld_tr, ld_va, len(ds_tr), len(ds_va)\n",
        "\n",
        "\n",
        "def get_parameters(model):\n",
        "    return [p.detach().cpu().numpy() for _, p in model.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(model, params):\n",
        "    sd = model.state_dict()\n",
        "    for k, v in zip(sd.keys(), params):\n",
        "        sd[k] = torch.tensor(v)\n",
        "    model.load_state_dict(sd, strict=True)\n",
        "\n",
        "\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "dice_loss = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "\n",
        "\n",
        "def criterion(pred, y):\n",
        "    return 0.5 * bce(pred, y) + 0.5 * dice_loss(pred, y)\n",
        "\n",
        "\n",
        "def maybe_save_best(run_dir, cid, val_loss, val_dice, best_epoch, rnd, model):\n",
        "    ckpt_dir = os.path.join(run_dir, \"checkpoints\")\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "    best_json = os.path.join(ckpt_dir, f\"client_{cid}_best.json\")\n",
        "    best_pt = os.path.join(ckpt_dir, f\"client_{cid}_best.pt\")\n",
        "\n",
        "    prev = {\"val_loss\": float(\"inf\"), \"val_dice\": -1.0}\n",
        "    if os.path.isfile(best_json):\n",
        "        try:\n",
        "            with open(best_json, \"r\") as f:\n",
        "                prev = json.load(f)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    improved = (val_loss < prev.get(\"val_loss\", float(\"inf\"))) and (val_dice > prev.get(\"val_dice\", -1.0))\n",
        "    if improved:\n",
        "        torch.save(model.state_dict(), best_pt)\n",
        "        with open(best_json, \"w\") as f:\n",
        "            json.dump(\n",
        "                {\n",
        "                    \"round\": int(rnd),\n",
        "                    \"epoch\": int(best_epoch),\n",
        "                    \"val_loss\": float(val_loss),\n",
        "                    \"val_dice\": float(val_dice),\n",
        "                },\n",
        "                f,\n",
        "            )\n",
        "\n",
        "\n",
        "class SegClient(fl.client.NumPyClient):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cid: int,\n",
        "        model_name=DEFAULT_MODEL_NAME,\n",
        "        encoder_name=DEFAULT_ENCODER_NAME,\n",
        "        encoder_weights=DEFAULT_ENCODER_WEIGHTS,\n",
        "    ):\n",
        "        self.cid = int(cid)\n",
        "        self.model_name = model_name\n",
        "        self.encoder_name = encoder_name\n",
        "        self.encoder_weights = encoder_weights\n",
        "\n",
        "        self.base_seed = SEED + self.cid\n",
        "        seed_everything(self.base_seed, deterministic=True)\n",
        "\n",
        "        self.run_name = _run_name(model_name, encoder_name)\n",
        "        self.run_dir = os.path.join(\"AITDM\", self.run_name)\n",
        "\n",
        "        self.model = get_model(model_name, encoder_name, encoder_weights)\n",
        "        if self.cid != 2:\n",
        "            self.train_loader, self.val_loader, self.ntr, self.nva = get_loaders(self.cid, self.base_seed, transforms=TRANSFORMS)\n",
        "        else:\n",
        "            self.train_loader, self.val_loader, self.ntr, self.nva = get_loaders(self.cid, self.base_seed, transforms=TRANSFORMS)\n",
        "\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.model)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # --- MEASURE INCOMING ---\n",
        "        incoming_size = sum([p.nbytes for p in parameters])\n",
        "\n",
        "        set_parameters(self.model, parameters)\n",
        "\n",
        "        epochs = int(config.get(\"local_epochs\", 1))\n",
        "        lr = float(config.get(\"lr\", 1e-3))\n",
        "        rnd = int(config.get(\"round\", 0))\n",
        "\n",
        "        opt = optim.AdamW(self.model.parameters(), lr=lr)\n",
        "        scaler = torch.amp.GradScaler(\"cuda\", enabled=(DEVICE.type == \"cuda\"))\n",
        "\n",
        "        best_state = None\n",
        "        best_val_loss = float(\"inf\")\n",
        "        best_val_dice = -1.0\n",
        "        best_epoch_idx = -1\n",
        "        epoch_logs = []\n",
        "\n",
        "        for epoch_idx in range(1, epochs + 1):\n",
        "            self.model.train()\n",
        "            tot_tr_loss = tot_tr_d = tot_tr_i = tot_tr_a = 0.0\n",
        "            nb_tr = 0\n",
        "\n",
        "            for batch in self.train_loader:\n",
        "                x = batch[\"x\"].to(DEVICE)\n",
        "                y = batch[\"y\"].to(DEVICE)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "\n",
        "                with torch.amp.autocast(\"cuda\", enabled=(DEVICE.type == \"cuda\")):\n",
        "                    pred = self.model(x)\n",
        "                    loss = criterion(pred, y)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    y_hat = (torch.sigmoid(pred).detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    y_np = (y.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                tot_tr_loss += float(loss.item())\n",
        "                tot_tr_d += d\n",
        "                tot_tr_i += i\n",
        "                tot_tr_a += a\n",
        "                nb_tr += 1\n",
        "\n",
        "            nb_tr = max(nb_tr, 1)\n",
        "            epoch_tr_loss = tot_tr_loss / nb_tr\n",
        "            epoch_tr_dice = tot_tr_d / nb_tr\n",
        "            epoch_tr_iou = tot_tr_i / nb_tr\n",
        "            epoch_tr_acc = tot_tr_a / nb_tr\n",
        "\n",
        "            self.model.eval()\n",
        "            tot_val_loss = tot_val_d = tot_val_i = tot_val_a = 0.0\n",
        "            nb_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in self.val_loader:\n",
        "                    x = batch[\"x\"].to(DEVICE)\n",
        "                    y = batch[\"y\"].to(DEVICE)\n",
        "                    pred = self.model(x)\n",
        "\n",
        "                    v_loss = float(criterion(pred, y).item())\n",
        "                    y_hat = (torch.sigmoid(pred).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                    tot_val_loss += v_loss\n",
        "                    tot_val_d += d\n",
        "                    tot_val_i += i\n",
        "                    tot_val_a += a\n",
        "                    nb_val += 1\n",
        "\n",
        "            nb_val = max(nb_val, 1)\n",
        "            epoch_val_loss = tot_val_loss / nb_val\n",
        "            epoch_val_dice = tot_val_d / nb_val\n",
        "            epoch_val_iou = tot_val_i / nb_val\n",
        "            epoch_val_acc = tot_val_a / nb_val\n",
        "\n",
        "            epoch_logs.append(\n",
        "                {\n",
        "                    \"epoch\": int(epoch_idx),\n",
        "                    \"train_loss\": float(epoch_tr_loss),\n",
        "                    \"train_dice\": float(epoch_tr_dice),\n",
        "                    \"train_iou\": float(epoch_tr_iou),\n",
        "                    \"train_acc\": float(epoch_tr_acc),\n",
        "                    \"val_loss\": float(epoch_val_loss),\n",
        "                    \"val_dice\": float(epoch_val_dice),\n",
        "                    \"val_iou\": float(epoch_val_iou),\n",
        "                    \"val_acc\": float(epoch_val_acc),\n",
        "                }\n",
        "            )\n",
        "\n",
        "            if (epoch_val_loss < best_val_loss) and (epoch_val_dice > best_val_dice):\n",
        "                best_val_loss = epoch_val_loss\n",
        "                best_val_dice = epoch_val_dice\n",
        "                best_state = copy.deepcopy(self.model.state_dict())\n",
        "                best_epoch_idx = epoch_idx\n",
        "\n",
        "        if best_state is not None:\n",
        "            self.model.load_state_dict(best_state)\n",
        "\n",
        "        for ep in epoch_logs:\n",
        "            ep[\"best_epoch\"] = (ep[\"epoch\"] == best_epoch_idx)\n",
        "\n",
        "        train_metrics = {\n",
        "            \"cid\": int(self.cid),\n",
        "            \"best_epoch\": int(best_epoch_idx),\n",
        "            \"best_val_loss\": float(best_val_loss),\n",
        "            \"best_val_dice\": float(best_val_dice),\n",
        "            \"per_epoch\": json.dumps(epoch_logs),\n",
        "            \"run_name\": self.run_name,\n",
        "            \"model_name\": self.model_name,\n",
        "            \"encoder_name\": self.encoder_name,\n",
        "        }\n",
        "\n",
        "        maybe_save_best(self.run_dir, self.cid, best_val_loss, best_val_dice, best_epoch_idx, rnd, self.model)\n",
        "\n",
        "        # --- PREPARE & MEASURE OUTGOING ---\n",
        "        out_params = get_parameters(self.model)\n",
        "\n",
        "\n",
        "        start_overhead = time.time()\n",
        "        final_params_to_send = out_params\n",
        "        end_overhead = time.time()\n",
        "\n",
        "        outgoing_size = sum([p.nbytes for p in final_params_to_send])\n",
        "\n",
        "        print(f\"Client {self.cid} Round {rnd}: Incoming {incoming_size/1024:.2f} KB | Outgoing {outgoing_size/1024:.2f} KB | Overhead: {end_overhead - start_overhead:.6f}s\")\n",
        "        log_file_path = os.path.join(self.run_dir, f\"client_{self.cid}_transfer_log.txt\")\n",
        "        log_transfer_metrics(log_file_path, self.cid, rnd, incoming_size, outgoing_size, end_overhead - start_overhead)\n",
        "\n",
        "        return final_params_to_send, self.ntr, train_metrics\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        self.model.eval()\n",
        "\n",
        "        tot_loss = tot_d = tot_i = tot_a = 0.0\n",
        "        nb = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_loader:\n",
        "                x = batch[\"x\"].to(DEVICE)\n",
        "                y = batch[\"y\"].to(DEVICE)\n",
        "                pred = self.model(x)\n",
        "\n",
        "                loss = float(criterion(pred, y).item())\n",
        "                y_hat = (torch.sigmoid(pred).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                tot_loss += loss\n",
        "                tot_d += d\n",
        "                tot_i += i\n",
        "                tot_a += a\n",
        "                nb += 1\n",
        "\n",
        "        nb = max(nb, 1)\n",
        "        metrics = {\n",
        "            \"loss\": tot_loss / nb,\n",
        "            \"dice\": tot_d / nb,\n",
        "            \"iou\": tot_i / nb,\n",
        "            \"acc\": tot_a / nb,\n",
        "            \"cid\": int(self.cid),\n",
        "            \"run_name\": self.run_name,\n",
        "        }\n",
        "\n",
        "        return metrics[\"loss\"], self.nva, metrics\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--cid\", type=int, required=True)\n",
        "    parser.add_argument(\"--server\", default=\"0.0.0.0:8080\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    fl.client.start_numpy_client(\n",
        "        server_address=args.server,\n",
        "        client=SegClient(args.cid),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38AkBD0Kb16I",
        "outputId": "ff8aa6fa-5322-4a31-bc1c-533649bfeade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting fl_sim_colab.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile fl_sim_colab.py\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import torch\n",
        "import flwr as fl\n",
        "import time\n",
        "from flwr.common import FitIns\n",
        "import torchio as tio\n",
        "from fl_client import SegClient\n",
        "\n",
        "import logging\n",
        "import warnings\n",
        "logging.getLogger(\"flwr\").setLevel(logging.ERROR)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def ensure_csv(path: str, header: list[str]):\n",
        "    if not os.path.isfile(path):\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, \"w\", newline=\"\") as f:\n",
        "            csv.writer(f).writerow(header)\n",
        "\n",
        "\n",
        "def append_row(path: str, row: list):\n",
        "    with open(path, \"a\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow(row)\n",
        "\n",
        "\n",
        "def log_server_metrics(file_path, rnd, duration):\n",
        "    \"\"\"Functie helper pentru logare timp agregare server in fisier.\"\"\"\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    msg = f\"Round {rnd} Aggregation Time: {duration:.4f} seconds\\n\"\n",
        "\n",
        "    with open(file_path, \"a\") as f:\n",
        "        f.write(msg)\n",
        "\n",
        "\n",
        "class PerClientLoggingFedAvg(fl.server.strategy.FedAvg):\n",
        "    def __init__(self, metrics_dir: str, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.metrics_dir = metrics_dir\n",
        "        self.header = [\n",
        "            \"round\",\"epoch\",\"train_loss\",\"train_dice\",\"train_iou\",\"train_acc\",\n",
        "            \"val_loss\",\"val_dice\",\"val_iou\",\"val_acc\",\"best_epoch\",\n",
        "        ]\n",
        "\n",
        "    def configure_fit(self, server_round, parameters, client_manager):\n",
        "        items = super().configure_fit(server_round, parameters, client_manager)\n",
        "        out = []\n",
        "        for it in items:\n",
        "            if isinstance(it, tuple):\n",
        "                client, fitins = it\n",
        "            else:\n",
        "                client, fitins = None, it\n",
        "\n",
        "            cfg = dict(fitins.config)\n",
        "            cfg[\"round\"] = server_round\n",
        "            new_fitins = FitIns(fitins.parameters, cfg)\n",
        "            out.append((client, new_fitins) if client is not None else new_fitins)\n",
        "        return out\n",
        "\n",
        "    def aggregate_fit(self, rnd, results, failures):\n",
        "        # --- START TIMER ---\n",
        "        start_time = time.time()\n",
        "\n",
        "        agg = super().aggregate_fit(rnd, results, failures)\n",
        "\n",
        "        # --- END TIMER ---\n",
        "        end_time = time.time()\n",
        "\n",
        "        print(f\"Round {rnd} Aggregation Time: {end_time - start_time:.4f} seconds\")\n",
        "        log_file_path = os.path.join(self.metrics_dir, \"server_aggregation_log.txt\")\n",
        "        log_server_metrics(log_file_path, rnd, end_time - start_time)\n",
        "\n",
        "        for client_proxy, fit_res in results:\n",
        "            m = fit_res.metrics or {}\n",
        "            cid = str(m.get(\"cid\", client_proxy.cid))\n",
        "\n",
        "            client_csv = os.path.join(self.metrics_dir, f\"metrics_client_{cid}.csv\")\n",
        "            ensure_csv(client_csv, self.header)\n",
        "\n",
        "            best_epoch = int(m.get(\"best_epoch\", -1))\n",
        "            per_epoch_raw = m.get(\"per_epoch\", \"[]\")\n",
        "\n",
        "            try:\n",
        "                per_epoch = json.loads(per_epoch_raw)\n",
        "            except Exception:\n",
        "                per_epoch = []\n",
        "\n",
        "            for ep in per_epoch:\n",
        "                epoch = ep.get(\"epoch\", \"\")\n",
        "                row = [\n",
        "                    rnd,\n",
        "                    epoch,\n",
        "                    ep.get(\"train_loss\", \"\"),\n",
        "                    ep.get(\"train_dice\", \"\"),\n",
        "                    ep.get(\"train_iou\", \"\"),\n",
        "                    ep.get(\"train_acc\", \"\"),\n",
        "                    ep.get(\"val_loss\", \"\"),\n",
        "                    ep.get(\"val_dice\", \"\"),\n",
        "                    ep.get(\"val_iou\", \"\"),\n",
        "                    ep.get(\"val_acc\", \"\"),\n",
        "                    \"x\" if int(epoch) == best_epoch else \"\",\n",
        "                ]\n",
        "                append_row(client_csv, row)\n",
        "\n",
        "        return agg\n",
        "\n",
        "\n",
        "def run_one_experiment(model_name: str, encoder_name: str, num_rounds=5, local_epochs=5, lr=1e-3):\n",
        "    run_name = f\"{model_name}__{encoder_name}\".replace(\"/\", \"-\")\n",
        "    base_dir = os.path.join(\"AITDM\", run_name)\n",
        "    metrics_dir = os.path.join(base_dir, \"metrics\")\n",
        "    os.makedirs(metrics_dir, exist_ok=True)\n",
        "\n",
        "    def client_fn(cid: str):\n",
        "        return SegClient(int(cid), model_name=model_name, encoder_name=encoder_name).to_client()\n",
        "\n",
        "    strategy = PerClientLoggingFedAvg(\n",
        "        metrics_dir=metrics_dir,\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=1.0,\n",
        "        min_fit_clients=3,\n",
        "        min_evaluate_clients=3,\n",
        "        min_available_clients=3,\n",
        "        on_fit_config_fn=lambda rnd: {\"local_epochs\": local_epochs, \"lr\": lr},\n",
        "    )\n",
        "\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0 if use_gpu else 0.0}\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=3,\n",
        "        config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "        strategy=strategy,\n",
        "        client_resources=client_resources,\n",
        "        ray_init_args={\"include_dashboard\": False},\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    experiments = [\n",
        "        (\"unet\", \"resnet50\"),\n",
        "        (\"unet\", \"mit_b3\"),\n",
        "        (\"deeplabv3plus\", \"timm-mobilenetv3_small_100\"),\n",
        "    ]\n",
        "\n",
        "    for model_name, encoder_name in experiments:\n",
        "        print(f\"\\n=== Running: {model_name} + {encoder_name} ===\")\n",
        "        start_time = time.time()\n",
        "        run_one_experiment(model_name, encoder_name, num_rounds=15, local_epochs=10, lr=1e-3)\n",
        "        run_time = time.time() - start_time\n",
        "        print(f\"Experiment completed in {run_time:.2f} seconds.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWdBLMGZQbPJ",
        "outputId": "faa894d2-b301-4c98-ffe8-815875bd72ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Running: unet + resnet50 ===\n",
            "2026-01-16 15:38:33.168056: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-16 15:38:33.185939: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768577913.207091    5124 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768577913.213619    5124 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768577913.230077    5124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768577913.230105    5124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768577913.230108    5124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768577913.230110    5124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-16 15:38:33.234941: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "2026-01-16 15:38:41,275\tINFO worker.py:2012 -- Started a local Ray instance.\n",
            "\u001b[36m(pid=5425)\u001b[0m 2026-01-16 15:38:46.251905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=5425)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=5425)\u001b[0m E0000 00:00:1768577926.272580    5425 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=5425)\u001b[0m E0000 00:00:1768577926.278999    5425 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=5425)\u001b[0m W0000 00:00:1768577926.294844    5425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=5425)\u001b[0m W0000 00:00:1768577926.294898    5425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=5425)\u001b[0m W0000 00:00:1768577926.294901    5425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=5425)\u001b[0m W0000 00:00:1768577926.294903    5425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=5425)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=5425)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=5425)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=5425)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=5425)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   _C._set_float32_matmul_precision(precision)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 1: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(pid=gcs_server)\u001b[0m [2026-01-16 15:39:08,749 E 5222 5222] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 1: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[33m(raylet)\u001b[0m [2026-01-16 15:39:11,209 E 5355 5355] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m [2026-01-16 15:39:14,379 E 5425 5473] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "[2026-01-16 15:39:15,216 E 5124 5416] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 1: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000002s\n",
            "Round 1 Aggregation Time: 0.4919 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(pid=5423)\u001b[0m [2026-01-16 15:39:15,203 E 5423 6029] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 11x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 2: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 2: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 2: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 2 Aggregation Time: 0.4451 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 3: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 3: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 3: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 3 Aggregation Time: 0.3975 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 4: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 4: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 4: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 4 Aggregation Time: 0.3798 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 5: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 5: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 5: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 5 Aggregation Time: 0.3820 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 6: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 6: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 6: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 6 Aggregation Time: 0.4003 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 7: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 7: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 7: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 7 Aggregation Time: 0.3867 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 8: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 8: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 8: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 8 Aggregation Time: 0.3964 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 9: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 9: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 9: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 9 Aggregation Time: 0.3876 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 10: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000000s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 10: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 10: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 10 Aggregation Time: 0.3960 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 11: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 11: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 11: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000002s\n",
            "Round 11 Aggregation Time: 0.3835 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 12: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 12: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 12: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 12 Aggregation Time: 0.3853 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 13: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 13: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 13: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 13 Aggregation Time: 0.3976 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 14: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 14: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 14: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 14 Aggregation Time: 0.3768 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 1 Round 15: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 0 Round 15: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m Client 2 Round 15: Incoming 127239.06 KB | Outgoing 127239.06 KB | Overhead: 0.000001s\n",
            "Round 15 Aggregation Time: 0.3786 seconds\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=5425) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=5425)\u001b[0m   return data.pin_memory(device)\n",
            "Experiment completed in 413.30 seconds.\n",
            "\n",
            "\n",
            "=== Running: unet + mit_b3 ===\n",
            "2026-01-16 15:45:28,917\tINFO worker.py:2012 -- Started a local Ray instance.\n",
            "\u001b[36m(pid=9347)\u001b[0m 2026-01-16 15:45:33.668178: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=9347)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=9347)\u001b[0m E0000 00:00:1768578333.689431    9347 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=9347)\u001b[0m E0000 00:00:1768578333.695964    9347 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=9347)\u001b[0m W0000 00:00:1768578333.712629    9347 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=9347)\u001b[0m W0000 00:00:1768578333.712662    9347 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=9347)\u001b[0m W0000 00:00:1768578333.712664    9347 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=9347)\u001b[0m W0000 00:00:1768578333.712667    9347 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=9347)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=9347)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=9347)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=9347)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=9347)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   _C._set_float32_matmul_precision(precision)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(pid=gcs_server)\u001b[0m [2026-01-16 15:45:56,325 E 9167 9167] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[33m(raylet)\u001b[0m [2026-01-16 15:45:58,853 E 9285 9285] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m [2026-01-16 15:46:02,331 E 9347 9405] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "[2026-01-16 15:46:03,056 E 5124 9345] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 1: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(pid=9350)\u001b[0m [2026-01-16 15:46:03,044 E 9350 9935] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 1: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 1: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 1 Aggregation Time: 0.6651 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 2: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 2: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000002s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 2: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 2 Aggregation Time: 0.5588 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 3: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 3: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 3: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 3 Aggregation Time: 0.5747 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 4: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 4: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 4: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 4 Aggregation Time: 0.6562 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 5: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 5: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 5: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 5 Aggregation Time: 0.5840 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 6: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 6: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 6: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 6 Aggregation Time: 0.5691 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 7: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 7: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 7: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 7 Aggregation Time: 0.5722 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 8: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 8: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 8: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 8 Aggregation Time: 0.5694 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 9: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 9: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 9: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000002s\n",
            "Round 9 Aggregation Time: 0.5590 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 10: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 10: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 10: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 10 Aggregation Time: 0.5684 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 11: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 11: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 11: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 11 Aggregation Time: 0.5632 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 12: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000002s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 12: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 12: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 12 Aggregation Time: 0.5700 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 13: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 13: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 13: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 13 Aggregation Time: 0.5713 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 14: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 14: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 14: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 14 Aggregation Time: 0.5603 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 0 Round 15: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 1 Round 15: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m Client 2 Round 15: Incoming 184967.64 KB | Outgoing 184967.64 KB | Overhead: 0.000001s\n",
            "Round 15 Aggregation Time: 0.5709 seconds\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=9347) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=9347)\u001b[0m   return data.pin_memory(device)\n",
            "Experiment completed in 1153.31 seconds.\n",
            "\n",
            "\n",
            "=== Running: deeplabv3plus + timm-mobilenetv3_small_100 ===\n",
            "2026-01-16 16:04:42,517\tINFO worker.py:2012 -- Started a local Ray instance.\n",
            "\u001b[36m(pid=16430)\u001b[0m 2026-01-16 16:04:47.312919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=16430)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=16430)\u001b[0m E0000 00:00:1768579487.334598   16430 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=16430)\u001b[0m E0000 00:00:1768579487.341037   16430 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=16430)\u001b[0m W0000 00:00:1768579487.358267   16430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=16430)\u001b[0m W0000 00:00:1768579487.358317   16430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=16430)\u001b[0m W0000 00:00:1768579487.358319   16430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=16430)\u001b[0m W0000 00:00:1768579487.358321   16430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=16430)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=16430)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=16430)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=16430)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=16430)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   _C._set_float32_matmul_precision(precision)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(pid=gcs_server)\u001b[0m [2026-01-16 16:05:09,825 E 16253 16253] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m '(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 24f91f91-104b-440c-a838-e092dcde984a)')' thrown while requesting HEAD https://huggingface.co/timm/tf_mobilenetv3_small_100.in1k/resolve/main/model.safetensors\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Retrying in 1s [Retry 1/5].\n",
            "\u001b[33m(raylet)\u001b[0m [2026-01-16 16:05:12,453 E 16369 16369] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m [2026-01-16 16:05:15,832 E 16430 16487] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "[2026-01-16 16:05:16,712 E 5124 16429] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(pid=16432)\u001b[0m [2026-01-16 16:05:16,674 E 16432 17005] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 1: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m '(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 5babba66-01e6-4152-99f3-fab74a668796)')' thrown while requesting HEAD https://huggingface.co/timm/tf_mobilenetv3_small_100.in1k/resolve/main/model.safetensors\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Retrying in 1s [Retry 1/5].\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 1: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 1: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "Round 1 Aggregation Time: 0.0772 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 2: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 2: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 2: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "Round 2 Aggregation Time: 0.0760 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 3: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 3: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 3: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "Round 3 Aggregation Time: 0.0744 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 4: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 4: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 4: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "Round 4 Aggregation Time: 0.0726 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m '(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: b65b211b-ecfa-4d70-a6a3-7b756fe01e59)')' thrown while requesting HEAD https://huggingface.co/timm/tf_mobilenetv3_small_100.in1k/resolve/main/model.safetensors\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Retrying in 1s [Retry 1/5].\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 5: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 5: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m '(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 89e48303-ebde-47d1-a833-8d4ad25c80fc)')' thrown while requesting HEAD https://huggingface.co/timm/tf_mobilenetv3_small_100.in1k/resolve/main/model.safetensors\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Retrying in 1s [Retry 1/5].\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 5: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "Round 5 Aggregation Time: 0.0777 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m '(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: d8447023-ff32-4150-8af6-caf27c02b0a6)')' thrown while requesting HEAD https://huggingface.co/timm/tf_mobilenetv3_small_100.in1k/resolve/main/model.safetensors\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Retrying in 1s [Retry 1/5].\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 6: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 6: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 6: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "Round 6 Aggregation Time: 0.0710 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 7: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 7: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 7: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "Round 7 Aggregation Time: 0.0729 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 8: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 8: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 8: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "Round 8 Aggregation Time: 0.0742 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 9: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 9: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 9: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "Round 9 Aggregation Time: 0.0739 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 10: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 10: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 10: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "Round 10 Aggregation Time: 0.0748 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 11: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 11: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 11: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "Round 11 Aggregation Time: 0.0739 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 12: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 12: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 12: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "Round 12 Aggregation Time: 0.0733 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 13: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 13: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 13: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "Round 13 Aggregation Time: 0.0758 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 14: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 14: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 14: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "Round 14 Aggregation Time: 0.0745 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 0 Round 15: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000001s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 2 Round 15: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Client 1 Round 15: Incoming 8505.40 KB | Outgoing 8505.40 KB | Overhead: 0.000000s\n",
            "Round 15 Aggregation Time: 0.0814 seconds\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=16430) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=16430)\u001b[0m   return data.pin_memory(device)\n",
            "Experiment completed in 479.87 seconds.\n",
            "\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/AITDM/client_0/*\n",
        "!rm -rf /content/AITDM/client_1/*\n",
        "!rm -rf /content/AITDM/client_2/*\n",
        "!rm -rf /content/AITDM/deeplabv3plus__timm-mobilenetv3_small_100/checkpoints/*\n",
        "!rm -rf /content/AITDM/unet__resnet50/checkpoints/*\n",
        "!rm -rf /content/AITDM/unet__mit_b3/checkpoints/*\n",
        "!rm -rf /content/AITDM/deeplabv3plus__timm-mobilenetv3_small_100/metrics/*\n",
        "!rm -rf /content/AITDM/unet__resnet50/metrics/*\n",
        "!rm -rf /content/AITDM/unet__mit_b3/metrics/*\n",
        "!python fl_sim_colab.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2mAaqi34g92"
      },
      "outputs": [],
      "source": [
        "import os, json, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import segmentation_models_pytorch as smp\n",
        "import logging\n",
        "from fl_client import TRANSFORMS\n",
        "\n",
        "from seg_data import (\n",
        "    ImageOnlyGliomaDataset,\n",
        "    SubsetByPIDs,\n",
        "    image_only_collate_fn,\n",
        "    DATA_ROOT,\n",
        "    METADATA_DF_PATH,\n",
        "    USE_ATLAS,\n",
        "    calc_metrics,\n",
        ")\n",
        "\n",
        "logging.getLogger(\"timm.models._builder\").setLevel(logging.ERROR)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEED = 42\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "CLIENT_DIR = \"/content/client\"\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "ENSEMBLE_CFGS = [\n",
        "    (\"unet\", \"resnet50\"),\n",
        "    (\"unet\", \"mit_b3\"),\n",
        "    (\"deeplabv3plus\", \"timm-mobilenetv3_small_100\"),\n",
        "]\n",
        "\n",
        "WEIGHT_MODE = \"power\"\n",
        "WEIGHT_POWER = 14.0\n",
        "WEIGHT_EPS = 1e-6\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "dice_loss = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "\n",
        "\n",
        "def criterion(logits, y):\n",
        "    return 0.5 * bce(logits, y) + 0.5 * dice_loss(logits, y)\n",
        "\n",
        "\n",
        "def get_val_loader(cid: int):\n",
        "    full = ImageOnlyGliomaDataset(\n",
        "        METADATA_DF_PATH, DATA_ROOT, use_atlas=USE_ATLAS, exclude_ids=[\"PatientID_0191\"]\n",
        "    )\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"val_pids.json\")) as f:\n",
        "        va_p = json.load(f)\n",
        "\n",
        "    ds_va = SubsetByPIDs(full, va_p)\n",
        "    g = torch.Generator().manual_seed(SEED)\n",
        "\n",
        "    ld_va = torch.utils.data.DataLoader(\n",
        "        ds_va,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        generator=g,\n",
        "    )\n",
        "    return ld_va, len(ds_va)\n",
        "\n",
        "\n",
        "def run_name(model_name: str, encoder_name: str) -> str:\n",
        "    return f\"{model_name}__{encoder_name}\".replace(\"/\", \"-\")\n",
        "\n",
        "\n",
        "def build_model(model_name: str, encoder_name: str, encoder_weights=\"imagenet\"):\n",
        "    in_ch = 2 if USE_ATLAS else 1\n",
        "    mn = model_name.lower()\n",
        "\n",
        "    if mn == \"unet\":\n",
        "        m = smp.Unet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    elif mn in [\"deeplabv3plus\", \"deeplabv3+\", \"dlv3p\"]:\n",
        "        m = smp.DeepLabV3Plus(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_name={model_name}\")\n",
        "\n",
        "    return m.to(DEVICE)\n",
        "\n",
        "\n",
        "def ckpt_path(model_name: str, encoder_name: str, cid: int) -> str:\n",
        "    rn = run_name(model_name, encoder_name)\n",
        "    return os.path.join(\"AITDM\", rn, \"checkpoints\", f\"client_{cid}_best.pt\")\n",
        "\n",
        "\n",
        "def best_json_path(model_name: str, encoder_name: str, cid: int) -> str:\n",
        "    rn = run_name(model_name, encoder_name)\n",
        "    return os.path.join(\"AITDM\", rn, \"checkpoints\", f\"client_{cid}_best.json\")\n",
        "\n",
        "\n",
        "def load_model(model_name: str, encoder_name: str, cid: int):\n",
        "    path = ckpt_path(model_name, encoder_name, cid)\n",
        "    if not os.path.isfile(path):\n",
        "        raise FileNotFoundError(f\"Missing checkpoint: {path}\")\n",
        "    m = build_model(model_name, encoder_name).to(DEVICE)\n",
        "    sd = torch.load(path, map_location=\"cpu\")\n",
        "    m.load_state_dict(sd, strict=True)\n",
        "    m.eval()\n",
        "    return m\n",
        "\n",
        "\n",
        "def load_best_val_dice(model_name: str, encoder_name: str, cid: int) -> float:\n",
        "    p = best_json_path(model_name, encoder_name, cid)\n",
        "    if not os.path.isfile(p):\n",
        "        raise FileNotFoundError(f\"Missing best json: {p}\")\n",
        "    with open(p, \"r\") as f:\n",
        "        j = json.load(f)\n",
        "    return float(j.get(\"val_dice\", 0.0))\n",
        "\n",
        "\n",
        "def get_client_weights(cid: int, cfgs, mode=\"power\", power=2.0, eps=1e-6):\n",
        "    dices = [load_best_val_dice(mn, enc, cid) for (mn, enc) in cfgs]\n",
        "    d = np.array(dices, dtype=np.float32)\n",
        "\n",
        "    if mode == \"linear\":\n",
        "        raw = np.clip(d, 0.0, None)\n",
        "    elif mode == \"power\":\n",
        "        raw = np.power(np.clip(d, 0.0, None), power)\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'linear' or 'power'\")\n",
        "\n",
        "    raw = raw + eps\n",
        "    w = raw / raw.sum()\n",
        "    return w.tolist(), dices\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ensemble_forward_logits(x, models, weights, target_hw=None):\n",
        "    w = np.array(weights, dtype=np.float32)\n",
        "    w = w / (w.sum() + 1e-8)\n",
        "\n",
        "    logits_sum = None\n",
        "    for mi, wi in zip(models, w):\n",
        "        li = mi(x)\n",
        "        if target_hw is not None and li.shape[-2:] != target_hw:\n",
        "            li = F.interpolate(li, size=target_hw, mode=\"bilinear\", align_corners=False)\n",
        "        logits_sum = li * float(wi) if logits_sum is None else logits_sum + li * float(wi)\n",
        "    return logits_sum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_ensemble_on_client(cid: int, threshold=0.5):\n",
        "    val_loader, nva = get_val_loader(cid)\n",
        "    models = [load_model(mn, enc, cid) for (mn, enc) in ENSEMBLE_CFGS]\n",
        "\n",
        "    weights, best_dices = get_client_weights(\n",
        "        cid, ENSEMBLE_CFGS, mode=WEIGHT_MODE, power=WEIGHT_POWER, eps=WEIGHT_EPS\n",
        "    )\n",
        "\n",
        "    tot_loss = tot_d = tot_i = tot_a = 0.0\n",
        "    nb = 0\n",
        "\n",
        "    for batch in val_loader:\n",
        "        x = batch[\"x\"].to(DEVICE)\n",
        "        y = batch[\"y\"].to(DEVICE)\n",
        "\n",
        "        logits = ensemble_forward_logits(x, models=models, weights=weights, target_hw=y.shape[-2:])\n",
        "        loss = float(criterion(logits, y).item())\n",
        "\n",
        "        preds_bin = (torch.sigmoid(logits).cpu().numpy() > threshold).astype(np.uint8)\n",
        "        y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        d, i, a = calc_metrics(y_np, preds_bin)\n",
        "\n",
        "        tot_loss += loss\n",
        "        tot_d += d\n",
        "        tot_i += i\n",
        "        tot_a += a\n",
        "        nb += 1\n",
        "\n",
        "    nb = max(nb, 1)\n",
        "    return {\n",
        "        \"cid\": int(cid),\n",
        "        \"nva\": int(nva),\n",
        "        \"loss\": tot_loss / nb,\n",
        "        \"dice\": tot_d / nb,\n",
        "        \"iou\": tot_i / nb,\n",
        "        \"acc\": tot_a / nb,\n",
        "        \"weights\": weights,\n",
        "        \"best_dices\": best_dices,\n",
        "    }\n",
        "\n",
        "\n",
        "def log_client_metrics(file_path, r, bd, ww):\n",
        "\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    log_message = (\n",
        "        f\"Client {r['cid']} (n={r['nva']}): \"\n",
        "        f\"loss={r['loss']:.4f} dice={r['dice']:.4f} iou={r['iou']:.4f} acc={r['acc']:.4f}\\n\"\n",
        "        f\"  best_dice={['%.4f' % x for x in bd]} -> weights={['%.3f' % x for x in ww]}\\n\"\n",
        "    )\n",
        "\n",
        "    print(log_message, end='')\n",
        "\n",
        "    with open(file_path, \"a\") as f:\n",
        "        f.write(log_message)\n",
        "\n",
        "def main():\n",
        "    print(f\"[Ensemble-3 | threshold={THRESHOLD} | weight_mode={WEIGHT_MODE} | power={WEIGHT_POWER}]\\n\")\n",
        "    for cid in [0, 1, 2]:\n",
        "        r = eval_ensemble_on_client(cid, threshold=THRESHOLD)\n",
        "        bd = r[\"best_dices\"]\n",
        "        ww = r[\"weights\"]\n",
        "        log_client_metrics(os.path.join('/content/AITDM', f\"client_{cid}\", \"val_metrics_ensemble.txt\"), r, bd, ww)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxMOzehOSxst"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/drive/MyDrive/AITDM\n",
        "!cp -rf /content/AITDM /content/drive/MyDrive/AITDM/NORMAL_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPzGIFl30B5A"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUCW2dYor366"
      },
      "source": [
        "# **M2 - FL with ensemble and quantization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5G6IR_OsH96"
      },
      "outputs": [],
      "source": [
        "%%writefile seg_data.py\n",
        "import os, pickle, numpy as np, torch\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchio as tio\n",
        "\n",
        "# Global paths and configuration\n",
        "DATA_ROOT = \"/content/Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "USE_ATLAS = True\n",
        "EXCLUDE_IDS = [\"PatientID_0191\"]\n",
        "\n",
        "# Dataset that loads MRI, tumor mask and optional atlas for each patient\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        metadata_df_path,\n",
        "        data_root,\n",
        "        use_atlas=False,\n",
        "        exclude_ids=None,\n",
        "        transform=None,\n",
        "    ):\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = []\n",
        "\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            base = os.path.join(self.data_root, pid)\n",
        "            mri_p = os.path.join(base, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(base, f\"{pid}_tumor.npy\")\n",
        "\n",
        "            is_valid = os.path.isfile(mri_p) and os.path.isfile(tumor_p)\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(base, f\"{pid}_regions.npy\")\n",
        "                is_valid = is_valid and os.path.isfile(reg_p)\n",
        "\n",
        "            if is_valid:\n",
        "                self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        if mx > mn:\n",
        "            return (x - mn) / (mx - mn)\n",
        "        return np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    def _to_torchio_format(self, arr):\n",
        "        \"\"\"\n",
        "        Convertește (H, W) -> (1, H, W, 1) pentru procesare internă TorchIO.\n",
        "        \"\"\"\n",
        "        if arr.ndim == 2:\n",
        "            return arr[np.newaxis, ..., np.newaxis]\n",
        "        return arr\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "\n",
        "        regions = None\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        if regions is not None:\n",
        "            regions = self._minmax(regions)\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            subject_dict = {\n",
        "                'mri': tio.ScalarImage(tensor=self._to_torchio_format(mri)),\n",
        "                'tumor': tio.LabelMap(tensor=self._to_torchio_format(tumor)),\n",
        "            }\n",
        "            if regions is not None:\n",
        "                subject_dict['regions'] = tio.ScalarImage(tensor=self._to_torchio_format(regions))\n",
        "\n",
        "            subject = tio.Subject(subject_dict)\n",
        "\n",
        "            subject = self.transform(subject)\n",
        "\n",
        "            out_mri = subject['mri'].data[0, ..., 0].numpy()\n",
        "            out_tumor = subject['tumor'].data[0, ..., 0].numpy()\n",
        "            sample = {\n",
        "                \"patient_id\": pid,\n",
        "                \"mri\": out_mri,       # Shape: (240, 240)\n",
        "                \"tumor\": out_tumor    # Shape: (240, 240)\n",
        "            }\n",
        "\n",
        "            if regions is not None:\n",
        "                out_regions = subject['regions'].data[0, ..., 0].numpy()\n",
        "                sample[\"regions\"] = out_regions # Shape: (240, 240)\n",
        "\n",
        "            return sample\n",
        "\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        if self.use_atlas:\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "# Collate function to build batched tensors and patient ID list\n",
        "def image_only_collate_fn(batch, use_atlas=USE_ATLAS):\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": [it[\"patient_id\"] for it in batch]}\n",
        "\n",
        "# Dataset wrapper that restricts to a subset of patient IDs\n",
        "class SubsetByPIDs(Dataset):\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Compute Dice, IoU and accuracy for binary masks\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "\n",
        "    inter = (y_true & y_pred).sum()\n",
        "    dice = (2.0 * inter) / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "    union = y_true.sum() + y_pred.sum() - inter + 1e-8\n",
        "    iou = inter / union\n",
        "    acc = (y_true == y_pred).mean()\n",
        "\n",
        "    return float(dice), float(iou), float(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvA2PtWhsIvh"
      },
      "outputs": [],
      "source": [
        "%%writefile fl_client.py\n",
        "import os\n",
        "os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":4096:8\")\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import flwr as fl\n",
        "import copy\n",
        "import segmentation_models_pytorch as smp\n",
        "import random\n",
        "import torchio as tio\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from seg_data import (\n",
        "    ImageOnlyGliomaDataset,\n",
        "    SubsetByPIDs,\n",
        "    image_only_collate_fn,\n",
        "    calc_metrics,\n",
        "    DATA_ROOT,\n",
        "    METADATA_DF_PATH,\n",
        "    USE_ATLAS,\n",
        ")\n",
        "\n",
        "CLIENT_DIR = \"/content/client\"\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "DEFAULT_MODEL_NAME = \"unet\"\n",
        "DEFAULT_ENCODER_NAME = \"timm-mobilenetv3_small_100\"\n",
        "DEFAULT_ENCODER_WEIGHTS = \"imagenet\"\n",
        "TRANSFORMS = None\n",
        "\n",
        "\n",
        "def _run_name(model_name: str, encoder_name: str) -> str:\n",
        "    return f\"{model_name}__{encoder_name}\".replace(\"/\", \"-\")\n",
        "\n",
        "\n",
        "def seed_everything(seed: int, deterministic: bool = True) -> None:\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    try:\n",
        "        torch.set_float32_matmul_precision(\"high\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    if deterministic:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id: int) -> None:\n",
        "    worker_seed = (torch.initial_seed() + worker_id) % (2**32)\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def log_transfer_metrics(file_path, cid, rnd, incoming, outgoing, overhead):\n",
        "    \"\"\"Functie helper pentru a salva metricile de transfer in fisier.\"\"\"\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    msg = (f\"Client {cid} Round {rnd}: \"\n",
        "           f\"Incoming {incoming/1024:.2f} KB | \"\n",
        "           f\"Outgoing {outgoing/1024:.2f} KB | \"\n",
        "           f\"Overhead: {overhead:.6f}s\\n\")\n",
        "\n",
        "    with open(file_path, \"a\") as f:\n",
        "        f.write(msg)\n",
        "\n",
        "\n",
        "def get_model(\n",
        "    model_name=DEFAULT_MODEL_NAME,\n",
        "    encoder_name=DEFAULT_ENCODER_NAME,\n",
        "    encoder_weights=DEFAULT_ENCODER_WEIGHTS,\n",
        "):\n",
        "    in_ch = 2 if USE_ATLAS else 1\n",
        "    mn = model_name.lower()\n",
        "\n",
        "    if mn == \"unet\":\n",
        "        model = smp.Unet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    elif mn in [\"deeplabv3plus\", \"deeplabv3+\", \"dlv3p\"]:\n",
        "        model = smp.DeepLabV3Plus(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_name={model_name}. Use 'unet' or 'deeplabv3plus'.\")\n",
        "\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "\n",
        "def get_loaders(cid: int, base_seed: int, transforms):\n",
        "    full = ImageOnlyGliomaDataset(\n",
        "        METADATA_DF_PATH,\n",
        "        DATA_ROOT,\n",
        "        use_atlas=USE_ATLAS,\n",
        "        exclude_ids=[\"PatientID_0191\"],\n",
        "        transform=transforms,\n",
        "    )\n",
        "\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"train_pids.json\")) as f:\n",
        "        tr_p = json.load(f)\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"val_pids.json\")) as f:\n",
        "        va_p = json.load(f)\n",
        "\n",
        "    ds_tr = SubsetByPIDs(full, tr_p)\n",
        "    ds_va = SubsetByPIDs(full, va_p)\n",
        "\n",
        "    g_tr = torch.Generator().manual_seed(base_seed + 12345)\n",
        "    g_va = torch.Generator().manual_seed(base_seed + 67890)\n",
        "\n",
        "    ld_tr = DataLoader(\n",
        "        ds_tr,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g_tr,\n",
        "        persistent_workers=(NUM_WORKERS > 0),\n",
        "    )\n",
        "\n",
        "    ld_va = DataLoader(\n",
        "        ds_va,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g_va,\n",
        "        persistent_workers=(NUM_WORKERS > 0),\n",
        "    )\n",
        "\n",
        "    return ld_tr, ld_va, len(ds_tr), len(ds_va)\n",
        "\n",
        "\n",
        "def get_parameters(model):\n",
        "    return [p.detach().cpu().numpy() for _, p in model.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(model, params):\n",
        "    sd = model.state_dict()\n",
        "    for k, v in zip(sd.keys(), params):\n",
        "        sd[k] = torch.tensor(v).float()\n",
        "    model.load_state_dict(sd, strict=True)\n",
        "\n",
        "\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "dice_loss = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "\n",
        "\n",
        "def criterion(pred, y):\n",
        "    return 0.5 * bce(pred, y) + 0.5 * dice_loss(pred, y)\n",
        "\n",
        "\n",
        "def maybe_save_best(run_dir, cid, val_loss, val_dice, best_epoch, rnd, model):\n",
        "    ckpt_dir = os.path.join(run_dir, \"checkpoints\")\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "    best_json = os.path.join(ckpt_dir, f\"client_{cid}_best.json\")\n",
        "    best_pt = os.path.join(ckpt_dir, f\"client_{cid}_best.pt\")\n",
        "\n",
        "    prev = {\"val_loss\": float(\"inf\"), \"val_dice\": -1.0}\n",
        "    if os.path.isfile(best_json):\n",
        "        try:\n",
        "            with open(best_json, \"r\") as f:\n",
        "                prev = json.load(f)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    improved = (val_loss < prev.get(\"val_loss\", float(\"inf\"))) and (val_dice > prev.get(\"val_dice\", -1.0))\n",
        "    if improved:\n",
        "        torch.save(model.state_dict(), best_pt)\n",
        "        with open(best_json, \"w\") as f:\n",
        "            json.dump(\n",
        "                {\n",
        "                    \"round\": int(rnd),\n",
        "                    \"epoch\": int(best_epoch),\n",
        "                    \"val_loss\": float(val_loss),\n",
        "                    \"val_dice\": float(val_dice),\n",
        "                },\n",
        "                f,\n",
        "            )\n",
        "\n",
        "\n",
        "class SegClient(fl.client.NumPyClient):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cid: int,\n",
        "        model_name=DEFAULT_MODEL_NAME,\n",
        "        encoder_name=DEFAULT_ENCODER_NAME,\n",
        "        encoder_weights=DEFAULT_ENCODER_WEIGHTS,\n",
        "    ):\n",
        "        self.cid = int(cid)\n",
        "        self.model_name = model_name\n",
        "        self.encoder_name = encoder_name\n",
        "        self.encoder_weights = encoder_weights\n",
        "\n",
        "        self.base_seed = SEED + self.cid\n",
        "        seed_everything(self.base_seed, deterministic=True)\n",
        "\n",
        "        self.run_name = _run_name(model_name, encoder_name)\n",
        "        self.run_dir = os.path.join(\"AITDM\", self.run_name)\n",
        "\n",
        "        self.model = get_model(model_name, encoder_name, encoder_weights)\n",
        "        if self.cid != 2:\n",
        "            self.train_loader, self.val_loader, self.ntr, self.nva = get_loaders(self.cid, self.base_seed, transforms=TRANSFORMS)\n",
        "        else:\n",
        "            self.train_loader, self.val_loader, self.ntr, self.nva = get_loaders(self.cid, self.base_seed, transforms=TRANSFORMS)\n",
        "\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.model)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "\n",
        "        incoming_size = sum([p.nbytes for p in parameters])\n",
        "\n",
        "        set_parameters(self.model, parameters)\n",
        "\n",
        "        epochs = int(config.get(\"local_epochs\", 1))\n",
        "        lr = float(config.get(\"lr\", 1e-3))\n",
        "        rnd = int(config.get(\"round\", 0))\n",
        "\n",
        "        opt = optim.AdamW(self.model.parameters(), lr=lr)\n",
        "        scaler = torch.amp.GradScaler(\"cuda\", enabled=(DEVICE.type == \"cuda\"))\n",
        "\n",
        "        best_state = None\n",
        "        best_val_loss = float(\"inf\")\n",
        "        best_val_dice = -1.0\n",
        "        best_epoch_idx = -1\n",
        "        epoch_logs = []\n",
        "\n",
        "        for epoch_idx in range(1, epochs + 1):\n",
        "            self.model.train()\n",
        "            tot_tr_loss = tot_tr_d = tot_tr_i = tot_tr_a = 0.0\n",
        "            nb_tr = 0\n",
        "\n",
        "            for batch in self.train_loader:\n",
        "                x = batch[\"x\"].to(DEVICE)\n",
        "                y = batch[\"y\"].to(DEVICE)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "\n",
        "                with torch.amp.autocast(\"cuda\", enabled=(DEVICE.type == \"cuda\")):\n",
        "                    pred = self.model(x)\n",
        "                    loss = criterion(pred, y)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    y_hat = (torch.sigmoid(pred).detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    y_np = (y.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                tot_tr_loss += float(loss.item())\n",
        "                tot_tr_d += d\n",
        "                tot_tr_i += i\n",
        "                tot_tr_a += a\n",
        "                nb_tr += 1\n",
        "\n",
        "            nb_tr = max(nb_tr, 1)\n",
        "            epoch_tr_loss = tot_tr_loss / nb_tr\n",
        "            epoch_tr_dice = tot_tr_d / nb_tr\n",
        "            epoch_tr_iou = tot_tr_i / nb_tr\n",
        "            epoch_tr_acc = tot_tr_a / nb_tr\n",
        "\n",
        "            self.model.eval()\n",
        "            tot_val_loss = tot_val_d = tot_val_i = tot_val_a = 0.0\n",
        "            nb_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in self.val_loader:\n",
        "                    x = batch[\"x\"].to(DEVICE)\n",
        "                    y = batch[\"y\"].to(DEVICE)\n",
        "                    pred = self.model(x)\n",
        "\n",
        "                    v_loss = float(criterion(pred, y).item())\n",
        "                    y_hat = (torch.sigmoid(pred).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                    tot_val_loss += v_loss\n",
        "                    tot_val_d += d\n",
        "                    tot_val_i += i\n",
        "                    tot_val_a += a\n",
        "                    nb_val += 1\n",
        "\n",
        "            nb_val = max(nb_val, 1)\n",
        "            epoch_val_loss = tot_val_loss / nb_val\n",
        "            epoch_val_dice = tot_val_d / nb_val\n",
        "            epoch_val_iou = tot_val_i / nb_val\n",
        "            epoch_val_acc = tot_val_a / nb_val\n",
        "\n",
        "            epoch_logs.append(\n",
        "                {\n",
        "                    \"epoch\": int(epoch_idx),\n",
        "                    \"train_loss\": float(epoch_tr_loss),\n",
        "                    \"train_dice\": float(epoch_tr_dice),\n",
        "                    \"train_iou\": float(epoch_tr_iou),\n",
        "                    \"train_acc\": float(epoch_tr_acc),\n",
        "                    \"val_loss\": float(epoch_val_loss),\n",
        "                    \"val_dice\": float(epoch_val_dice),\n",
        "                    \"val_iou\": float(epoch_val_iou),\n",
        "                    \"val_acc\": float(epoch_val_acc),\n",
        "                }\n",
        "            )\n",
        "\n",
        "            if (epoch_val_loss < best_val_loss) and (epoch_val_dice > best_val_dice):\n",
        "                best_val_loss = epoch_val_loss\n",
        "                best_val_dice = epoch_val_dice\n",
        "                best_state = copy.deepcopy(self.model.state_dict())\n",
        "                best_epoch_idx = epoch_idx\n",
        "\n",
        "        if best_state is not None:\n",
        "            self.model.load_state_dict(best_state)\n",
        "\n",
        "        for ep in epoch_logs:\n",
        "            ep[\"best_epoch\"] = (ep[\"epoch\"] == best_epoch_idx)\n",
        "\n",
        "        train_metrics = {\n",
        "            \"cid\": int(self.cid),\n",
        "            \"best_epoch\": int(best_epoch_idx),\n",
        "            \"best_val_loss\": float(best_val_loss),\n",
        "            \"best_val_dice\": float(best_val_dice),\n",
        "            \"per_epoch\": json.dumps(epoch_logs),\n",
        "            \"run_name\": self.run_name,\n",
        "            \"model_name\": self.model_name,\n",
        "            \"encoder_name\": self.encoder_name,\n",
        "        }\n",
        "\n",
        "        maybe_save_best(self.run_dir, self.cid, best_val_loss, best_val_dice, best_epoch_idx, rnd, self.model)\n",
        "\n",
        "        out_params = get_parameters(self.model)\n",
        "\n",
        "        start_overhead = time.time()\n",
        "\n",
        "        final_params_to_send = [p.astype(np.float16) for p in out_params]\n",
        "\n",
        "        end_overhead = time.time()\n",
        "\n",
        "        outgoing_size = sum([p.nbytes for p in final_params_to_send])\n",
        "\n",
        "        print(f\"Client {self.cid} Round {rnd}: Incoming {incoming_size/1024:.2f} KB | Outgoing {outgoing_size/1024:.2f} KB | Overhead: {end_overhead - start_overhead:.6f}s\")\n",
        "        log_file_path = os.path.join(self.run_dir, f\"client_{self.cid}_transfer_log.txt\")\n",
        "        log_transfer_metrics(log_file_path, self.cid, rnd, incoming_size, outgoing_size, end_overhead - start_overhead)\n",
        "\n",
        "        return final_params_to_send, self.ntr, train_metrics\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        self.model.eval()\n",
        "\n",
        "        tot_loss = tot_d = tot_i = tot_a = 0.0\n",
        "        nb = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_loader:\n",
        "                x = batch[\"x\"].to(DEVICE)\n",
        "                y = batch[\"y\"].to(DEVICE)\n",
        "                pred = self.model(x)\n",
        "\n",
        "                loss = float(criterion(pred, y).item())\n",
        "                y_hat = (torch.sigmoid(pred).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                tot_loss += loss\n",
        "                tot_d += d\n",
        "                tot_i += i\n",
        "                tot_a += a\n",
        "                nb += 1\n",
        "\n",
        "        nb = max(nb, 1)\n",
        "        metrics = {\n",
        "            \"loss\": tot_loss / nb,\n",
        "            \"dice\": tot_d / nb,\n",
        "            \"iou\": tot_i / nb,\n",
        "            \"acc\": tot_a / nb,\n",
        "            \"cid\": int(self.cid),\n",
        "            \"run_name\": self.run_name,\n",
        "        }\n",
        "\n",
        "        return metrics[\"loss\"], self.nva, metrics\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--cid\", type=int, required=True)\n",
        "    parser.add_argument(\"--server\", default=\"0.0.0.0:8080\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    fl.client.start_numpy_client(\n",
        "        server_address=args.server,\n",
        "        client=SegClient(args.cid),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho89pIJWsNXs"
      },
      "outputs": [],
      "source": [
        "%%writefile fl_sim_colab.py\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import torch\n",
        "import flwr as fl\n",
        "import time\n",
        "import numpy as np\n",
        "from flwr.common import FitIns, parameters_to_ndarrays, ndarrays_to_parameters\n",
        "from fl_client import SegClient\n",
        "\n",
        "import logging\n",
        "import warnings\n",
        "logging.getLogger(\"flwr\").setLevel(logging.ERROR)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def ensure_csv(path: str, header: list[str]):\n",
        "    if not os.path.isfile(path):\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, \"w\", newline=\"\") as f:\n",
        "            csv.writer(f).writerow(header)\n",
        "\n",
        "\n",
        "def append_row(path: str, row: list):\n",
        "    with open(path, \"a\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow(row)\n",
        "\n",
        "\n",
        "def log_server_metrics(file_path, rnd, duration, result_size):\n",
        "    \"\"\"Logheaza timpul si marimea pachetului trimis de server (Downlink).\"\"\"\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    size_kb = result_size / 1024.0 if result_size > 0 else 0\n",
        "    msg = f\"Round {rnd}: Aggregation Time: {duration:.4f}s | Downlink Payload: {size_kb:.2f} KB\\n\"\n",
        "\n",
        "    with open(file_path, \"a\") as f:\n",
        "        f.write(msg)\n",
        "\n",
        "\n",
        "class PerClientLoggingFedAvg(fl.server.strategy.FedAvg):\n",
        "    def __init__(self, metrics_dir: str, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.metrics_dir = metrics_dir\n",
        "        self.header = [\n",
        "            \"round\",\"epoch\",\"train_loss\",\"train_dice\",\"train_iou\",\"train_acc\",\n",
        "            \"val_loss\",\"val_dice\",\"val_iou\",\"val_acc\",\"best_epoch\",\n",
        "        ]\n",
        "\n",
        "    def configure_fit(self, server_round, parameters, client_manager):\n",
        "        items = super().configure_fit(server_round, parameters, client_manager)\n",
        "        out = []\n",
        "        for it in items:\n",
        "            if isinstance(it, tuple):\n",
        "                client, fitins = it\n",
        "            else:\n",
        "                client, fitins = None, it\n",
        "\n",
        "            cfg = dict(fitins.config)\n",
        "            cfg[\"round\"] = server_round\n",
        "            new_fitins = FitIns(fitins.parameters, cfg)\n",
        "            out.append((client, new_fitins) if client is not None else new_fitins)\n",
        "        return out\n",
        "\n",
        "    def aggregate_fit(self, rnd, results, failures):\n",
        "        start_time = time.time()\n",
        "\n",
        "        agg_result = super().aggregate_fit(rnd, results, failures)\n",
        "\n",
        "        final_params = None\n",
        "        agg_metrics = {}\n",
        "        downlink_size_bytes = 0\n",
        "\n",
        "        if agg_result is not None:\n",
        "            agg_params, agg_metrics = agg_result\n",
        "\n",
        "            ndarrays = parameters_to_ndarrays(agg_params)\n",
        "\n",
        "            ndarrays_fp16 = [val.astype(np.float16) for val in ndarrays]\n",
        "\n",
        "            final_params = ndarrays_to_parameters(ndarrays_fp16)\n",
        "\n",
        "            downlink_size_bytes = sum([len(t) for t in final_params.tensors])\n",
        "\n",
        "            agg_result = (final_params, agg_metrics)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        print(f\"Round {rnd} Server: Aggregation {end_time - start_time:.4f}s | Downlink size: {downlink_size_bytes/1024:.2f} KB\")\n",
        "\n",
        "        log_file_path = os.path.join(self.metrics_dir, \"server_aggregation_log.txt\")\n",
        "        log_server_metrics(log_file_path, rnd, end_time - start_time, downlink_size_bytes)\n",
        "\n",
        "        for client_proxy, fit_res in results:\n",
        "            m = fit_res.metrics or {}\n",
        "            cid = str(m.get(\"cid\", client_proxy.cid))\n",
        "\n",
        "            client_csv = os.path.join(self.metrics_dir, f\"metrics_client_{cid}.csv\")\n",
        "            ensure_csv(client_csv, self.header)\n",
        "\n",
        "            best_epoch = int(m.get(\"best_epoch\", -1))\n",
        "            per_epoch_raw = m.get(\"per_epoch\", \"[]\")\n",
        "\n",
        "            try:\n",
        "                per_epoch = json.loads(per_epoch_raw)\n",
        "            except Exception:\n",
        "                per_epoch = []\n",
        "\n",
        "            for ep in per_epoch:\n",
        "                epoch = ep.get(\"epoch\", \"\")\n",
        "                row = [\n",
        "                    rnd,\n",
        "                    epoch,\n",
        "                    ep.get(\"train_loss\", \"\"),\n",
        "                    ep.get(\"train_dice\", \"\"),\n",
        "                    ep.get(\"train_iou\", \"\"),\n",
        "                    ep.get(\"train_acc\", \"\"),\n",
        "                    ep.get(\"val_loss\", \"\"),\n",
        "                    ep.get(\"val_dice\", \"\"),\n",
        "                    ep.get(\"val_iou\", \"\"),\n",
        "                    ep.get(\"val_acc\", \"\"),\n",
        "                    \"x\" if int(epoch) == best_epoch else \"\",\n",
        "                ]\n",
        "                append_row(client_csv, row)\n",
        "\n",
        "        return agg_result\n",
        "\n",
        "\n",
        "def run_one_experiment(model_name: str, encoder_name: str, num_rounds=5, local_epochs=5, lr=1e-3):\n",
        "    run_name = f\"{model_name}__{encoder_name}\".replace(\"/\", \"-\")\n",
        "    base_dir = os.path.join(\"AITDM\", run_name)\n",
        "    metrics_dir = os.path.join(base_dir, \"metrics\")\n",
        "    os.makedirs(metrics_dir, exist_ok=True)\n",
        "\n",
        "    def client_fn(cid: str):\n",
        "        return SegClient(int(cid), model_name=model_name, encoder_name=encoder_name).to_client()\n",
        "\n",
        "    strategy = PerClientLoggingFedAvg(\n",
        "        metrics_dir=metrics_dir,\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=1.0,\n",
        "        min_fit_clients=3,\n",
        "        min_evaluate_clients=3,\n",
        "        min_available_clients=3,\n",
        "        on_fit_config_fn=lambda rnd: {\"local_epochs\": local_epochs, \"lr\": lr},\n",
        "    )\n",
        "\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0 if use_gpu else 0.0}\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=3,\n",
        "        config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "        strategy=strategy,\n",
        "        client_resources=client_resources,\n",
        "        ray_init_args={\"include_dashboard\": False},\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    experiments = [\n",
        "        (\"unet\", \"resnet50\"),\n",
        "        (\"unet\", \"mit_b3\"),\n",
        "        (\"deeplabv3plus\", \"timm-mobilenetv3_small_100\"),\n",
        "    ]\n",
        "\n",
        "    for model_name, encoder_name in experiments:\n",
        "        print(f\"\\n=== Running: {model_name} + {encoder_name} ===\")\n",
        "        start_time = time.time()\n",
        "        run_one_experiment(model_name, encoder_name, num_rounds=15, local_epochs=10, lr=1e-3)\n",
        "        run_time = time.time() - start_time\n",
        "        print(f\"Experiment completed in {run_time:.2f} seconds.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wYnrOrhHsl8z",
        "outputId": "42e8a581-209d-4c19-f590-4921b0e5478a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Running: unet + resnet50 ===\n",
            "2026-01-16 16:21:39.174276: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-16 16:21:39.192008: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768580499.213809    3890 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768580499.220357    3890 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768580499.237091    3890 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768580499.237124    3890 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768580499.237126    3890 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768580499.237129    3890 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-16 16:21:39.242032: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "2026-01-16 16:21:48,116\tINFO worker.py:2012 -- Started a local Ray instance.\n",
            "\u001b[36m(pid=4233)\u001b[0m 2026-01-16 16:21:52.731370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=4233)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=4233)\u001b[0m E0000 00:00:1768580512.752130    4233 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=4233)\u001b[0m E0000 00:00:1768580512.758498    4233 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=4233)\u001b[0m W0000 00:00:1768580512.774639    4233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=4233)\u001b[0m W0000 00:00:1768580512.774666    4233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=4233)\u001b[0m W0000 00:00:1768580512.774668    4233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=4233)\u001b[0m W0000 00:00:1768580512.774670    4233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=4233)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=4233)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=4233)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=4233)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=4233)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   _C._set_float32_matmul_precision(precision)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(pid=gcs_server)\u001b[0m [2026-01-16 16:22:15,290 E 4033 4033] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 1: Incoming 127239.06 KB | Outgoing 63619.41 KB | Overhead: 0.198197s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[33m(raylet)\u001b[0m [2026-01-16 16:22:18,053 E 4168 4168] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 1: Incoming 127239.06 KB | Outgoing 63619.41 KB | Overhead: 0.227577s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m [2026-01-16 16:22:21,480 E 4233 4367] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "[2026-01-16 16:22:22,088 E 3890 4229] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 1: Incoming 127239.06 KB | Outgoing 63619.41 KB | Overhead: 0.225120s\n",
            "Round 1 Server: Aggregation 2.2381s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(pid=4238)\u001b[0m [2026-01-16 16:22:22,069 E 4238 4822] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 11x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 2: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.225784s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 2: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.225050s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 2: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.229671s\n",
            "Round 2 Server: Aggregation 2.1102s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 3: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.231765s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 3: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.225102s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 3: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.231151s\n",
            "Round 3 Server: Aggregation 2.1117s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 4: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.226256s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 4: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.228958s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 4: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.226164s\n",
            "Round 4 Server: Aggregation 2.1149s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 5: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.227918s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 5: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.220665s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 5: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.231587s\n",
            "Round 5 Server: Aggregation 2.0824s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 6: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.227761s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 6: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.222803s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 6: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.228299s\n",
            "Round 6 Server: Aggregation 2.0987s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 7: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.224229s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 7: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.218897s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 7: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.224204s\n",
            "Round 7 Server: Aggregation 2.0723s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 8: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.223618s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 8: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.223321s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 8: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.222703s\n",
            "Round 8 Server: Aggregation 2.0603s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 9: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.227692s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 9: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.223421s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 9: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.222147s\n",
            "Round 9 Server: Aggregation 2.0597s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 10: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.223223s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 10: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.225964s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 10: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.222407s\n",
            "Round 10 Server: Aggregation 2.0611s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 11: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.224859s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 11: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.221827s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 11: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.222261s\n",
            "Round 11 Server: Aggregation 2.0476s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 12: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.221705s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 12: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.227161s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 12: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.227573s\n",
            "Round 12 Server: Aggregation 2.0581s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 13: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.226061s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 13: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.221943s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 13: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.224923s\n",
            "Round 13 Server: Aggregation 2.0653s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 14: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.222584s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 14: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.225337s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 14: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.223266s\n",
            "Round 14 Server: Aggregation 2.0585s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 1 Round 15: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.221902s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 2 Round 15: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.222346s\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m Client 0 Round 15: Incoming 63619.41 KB | Outgoing 63619.41 KB | Overhead: 0.222099s\n",
            "Round 15 Server: Aggregation 2.0649s | Downlink size: 63666.91 KB\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=4233) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   self.pid = os.fork()\n",
            "Experiment completed in 432.97 seconds.\n",
            "\n",
            "\n",
            "=== Running: unet + mit_b3 ===\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=4233)\u001b[0m   return data.pin_memory(device)\n",
            "2026-01-16 16:28:54,496\tINFO worker.py:2012 -- Started a local Ray instance.\n",
            "\u001b[36m(pid=8351)\u001b[0m 2026-01-16 16:28:59.061696: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=8351)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=8351)\u001b[0m E0000 00:00:1768580939.083278    8351 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=8351)\u001b[0m E0000 00:00:1768580939.089906    8351 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=8351)\u001b[0m W0000 00:00:1768580939.107787    8351 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=8351)\u001b[0m W0000 00:00:1768580939.107822    8351 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=8351)\u001b[0m W0000 00:00:1768580939.107825    8351 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=8351)\u001b[0m W0000 00:00:1768580939.107827    8351 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=8351)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=8351)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=8351)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=8351)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=8351)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   _C._set_float32_matmul_precision(precision)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(pid=gcs_server)\u001b[0m [2026-01-16 16:29:22,075 E 8165 8165] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[33m(raylet)\u001b[0m [2026-01-16 16:29:24,431 E 8279 8279] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m [2026-01-16 16:29:27,823 E 8351 8399] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "[2026-01-16 16:29:28,454 E 3890 8339] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 1: Incoming 184967.64 KB | Outgoing 92483.80 KB | Overhead: 0.276853s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(pid=8348)\u001b[0m [2026-01-16 16:29:28,418 E 8348 8887] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 1: Incoming 184967.64 KB | Outgoing 92483.80 KB | Overhead: 0.281965s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 1: Incoming 184967.64 KB | Outgoing 92483.80 KB | Overhead: 0.278015s\n",
            "Round 1 Server: Aggregation 3.0092s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 2: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.312921s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 2: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.320662s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 2: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.312077s\n",
            "Round 2 Server: Aggregation 2.9302s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 3: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.315553s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 3: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.313432s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 3: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.312903s\n",
            "Round 3 Server: Aggregation 2.9321s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 4: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.313735s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 4: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.311264s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 4: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.312050s\n",
            "Round 4 Server: Aggregation 2.9408s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 5: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.315667s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 5: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.321809s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 5: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.314324s\n",
            "Round 5 Server: Aggregation 2.9321s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 6: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.310207s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 6: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.315132s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 6: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.316282s\n",
            "Round 6 Server: Aggregation 2.9091s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 7: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.306241s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 7: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.309597s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 7: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.314704s\n",
            "Round 7 Server: Aggregation 2.9213s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 8: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.313866s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 8: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.318694s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 8: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.313275s\n",
            "Round 8 Server: Aggregation 2.9431s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 9: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.322865s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 9: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.315874s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 9: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.317168s\n",
            "Round 9 Server: Aggregation 2.9439s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 10: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.311755s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 10: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.312905s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 10: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.312047s\n",
            "Round 10 Server: Aggregation 2.9328s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 11: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.312576s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 11: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.315126s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 11: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.312853s\n",
            "Round 11 Server: Aggregation 2.9199s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 12: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.312523s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 12: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.318599s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 12: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.311833s\n",
            "Round 12 Server: Aggregation 2.9127s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 13: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.324664s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 13: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.316389s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 13: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.314935s\n",
            "Round 13 Server: Aggregation 2.8972s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 14: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.315140s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 14: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.320045s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 14: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.315012s\n",
            "Round 14 Server: Aggregation 2.9409s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 0 Round 15: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.308943s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 2 Round 15: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.313934s\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m Client 1 Round 15: Incoming 92483.80 KB | Outgoing 92483.80 KB | Overhead: 0.313323s\n",
            "Round 15 Server: Aggregation 2.9318s | Downlink size: 92563.05 KB\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=8351) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=8351)\u001b[0m   return data.pin_memory(device)\n",
            "Experiment completed in 1178.17 seconds.\n",
            "\n",
            "\n",
            "=== Running: deeplabv3plus + timm-mobilenetv3_small_100 ===\n",
            "2026-01-16 16:48:32,800\tINFO worker.py:2012 -- Started a local Ray instance.\n",
            "\u001b[36m(pid=15686)\u001b[0m 2026-01-16 16:48:37.560232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=15686)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=15686)\u001b[0m E0000 00:00:1768582117.582386   15686 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=15686)\u001b[0m E0000 00:00:1768582117.589136   15686 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=15686)\u001b[0m W0000 00:00:1768582117.607099   15686 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=15686)\u001b[0m W0000 00:00:1768582117.607130   15686 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=15686)\u001b[0m W0000 00:00:1768582117.607133   15686 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=15686)\u001b[0m W0000 00:00:1768582117.607135   15686 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=15686)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=15686)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=15686)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=15686)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=15686)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   _C._set_float32_matmul_precision(precision)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(pid=gcs_server)\u001b[0m [2026-01-16 16:49:00,338 E 15501 15501] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[33m(raylet)\u001b[0m [2026-01-16 16:49:02,738 E 15617 15617] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m [2026-01-16 16:49:06,380 E 15686 15762] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "[2026-01-16 16:49:06,952 E 3890 15677] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 1: Incoming 8505.40 KB | Outgoing 4252.62 KB | Overhead: 0.014018s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(pid=15687)\u001b[0m [2026-01-16 16:49:06,939 E 15687 16289] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 1: Incoming 8505.40 KB | Outgoing 4252.62 KB | Overhead: 0.012548s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 1: Incoming 8505.40 KB | Outgoing 4252.62 KB | Overhead: 0.013817s\n",
            "Round 1 Server: Aggregation 0.2126s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 2: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012772s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 2: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012617s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 2: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012721s\n",
            "Round 2 Server: Aggregation 0.2015s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 3: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.016921s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 3: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012278s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 3: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012820s\n",
            "Round 3 Server: Aggregation 0.2032s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 4: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012574s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 4: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.013085s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 4: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012913s\n",
            "Round 4 Server: Aggregation 0.2068s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 5: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.013472s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 5: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012733s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 5: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012426s\n",
            "Round 5 Server: Aggregation 0.2020s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 6: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012918s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 6: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012640s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 6: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012611s\n",
            "Round 6 Server: Aggregation 0.2004s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 7: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012385s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 7: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012767s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 7: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012933s\n",
            "Round 7 Server: Aggregation 0.2026s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 8: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012756s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 8: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.013222s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 8: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012503s\n",
            "Round 8 Server: Aggregation 0.2056s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 9: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012284s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 9: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012615s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 9: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012638s\n",
            "Round 9 Server: Aggregation 0.1994s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 10: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012427s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 10: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012128s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 10: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012444s\n",
            "Round 10 Server: Aggregation 0.2106s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 11: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012770s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 11: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.013166s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 11: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012534s\n",
            "Round 11 Server: Aggregation 0.2035s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 12: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.013288s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 12: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.013373s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 12: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.014212s\n",
            "Round 12 Server: Aggregation 0.2095s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 13: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012560s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 13: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012753s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 13: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.013053s\n",
            "Round 13 Server: Aggregation 0.2052s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 14: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012439s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 14: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012441s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 14: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.013322s\n",
            "Round 14 Server: Aggregation 0.2021s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 2 Round 15: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.013116s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 1 Round 15: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012748s\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Client 0 Round 15: Incoming 4252.62 KB | Outgoing 4252.62 KB | Overhead: 0.012482s\n",
            "Round 15 Server: Aggregation 0.2084s | Downlink size: 4290.24 KB\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/encoders/__init__.py:73: DeprecationWarning: `timm-` encoders are deprecated and will be removed in the future. Please use `tu-` equivalent encoders instead (see 'Timm encoders' section in the documentation).\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=15686) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
            "\u001b[36m(ClientAppActor pid=15686)\u001b[0m   return data.pin_memory(device)\n",
            "Experiment completed in 357.00 seconds.\n",
            "\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/AITDM/client_0/*\n",
        "!rm -rf /content/AITDM/client_1/*\n",
        "!rm -rf /content/AITDM/client_2/*\n",
        "!rm -rf /content/AITDM/deeplabv3plus__timm-mobilenetv3_small_100/checkpoints/*\n",
        "!rm -rf /content/AITDM/unet__resnet50/checkpoints/*\n",
        "!rm -rf /content/AITDM/unet__mit_b3/checkpoints/*\n",
        "!rm -rf /content/AITDM/deeplabv3plus__timm-mobilenetv3_small_100/metrics/*\n",
        "!rm -rf /content/AITDM/unet__resnet50/metrics/*\n",
        "!rm -rf /content/AITDM/unet__mit_b3/metrics/*\n",
        "!python fl_sim_colab.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgkFTz0zsRHV"
      },
      "outputs": [],
      "source": [
        "import os, json, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import segmentation_models_pytorch as smp\n",
        "import logging\n",
        "from fl_client import TRANSFORMS\n",
        "\n",
        "from seg_data import (\n",
        "    ImageOnlyGliomaDataset,\n",
        "    SubsetByPIDs,\n",
        "    image_only_collate_fn,\n",
        "    DATA_ROOT,\n",
        "    METADATA_DF_PATH,\n",
        "    USE_ATLAS,\n",
        "    calc_metrics,\n",
        ")\n",
        "\n",
        "logging.getLogger(\"timm.models._builder\").setLevel(logging.ERROR)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEED = 42\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "CLIENT_DIR = \"/content/client\"\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "ENSEMBLE_CFGS = [\n",
        "    (\"unet\", \"resnet50\"),\n",
        "    (\"unet\", \"mit_b3\"),\n",
        "    (\"deeplabv3plus\", \"timm-mobilenetv3_small_100\"),\n",
        "]\n",
        "\n",
        "WEIGHT_MODE = \"power\"\n",
        "WEIGHT_POWER = 14.0\n",
        "WEIGHT_EPS = 1e-6\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "dice_loss = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "\n",
        "\n",
        "def criterion(logits, y):\n",
        "    return 0.5 * bce(logits, y) + 0.5 * dice_loss(logits, y)\n",
        "\n",
        "\n",
        "def get_val_loader(cid: int):\n",
        "    full = ImageOnlyGliomaDataset(\n",
        "        METADATA_DF_PATH, DATA_ROOT, use_atlas=USE_ATLAS, exclude_ids=[\"PatientID_0191\"]\n",
        "    )\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"val_pids.json\")) as f:\n",
        "        va_p = json.load(f)\n",
        "\n",
        "    ds_va = SubsetByPIDs(full, va_p)\n",
        "    g = torch.Generator().manual_seed(SEED)\n",
        "\n",
        "    ld_va = torch.utils.data.DataLoader(\n",
        "        ds_va,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        generator=g,\n",
        "    )\n",
        "    return ld_va, len(ds_va)\n",
        "\n",
        "\n",
        "def run_name(model_name: str, encoder_name: str) -> str:\n",
        "    return f\"{model_name}__{encoder_name}\".replace(\"/\", \"-\")\n",
        "\n",
        "\n",
        "def build_model(model_name: str, encoder_name: str, encoder_weights=\"imagenet\"):\n",
        "    in_ch = 2 if USE_ATLAS else 1\n",
        "    mn = model_name.lower()\n",
        "\n",
        "    if mn == \"unet\":\n",
        "        m = smp.Unet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    elif mn in [\"deeplabv3plus\", \"deeplabv3+\", \"dlv3p\"]:\n",
        "        m = smp.DeepLabV3Plus(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_name={model_name}\")\n",
        "\n",
        "    return m.to(DEVICE)\n",
        "\n",
        "\n",
        "def ckpt_path(model_name: str, encoder_name: str, cid: int) -> str:\n",
        "    rn = run_name(model_name, encoder_name)\n",
        "    return os.path.join(\"AITDM\", rn, \"checkpoints\", f\"client_{cid}_best.pt\")\n",
        "\n",
        "\n",
        "def best_json_path(model_name: str, encoder_name: str, cid: int) -> str:\n",
        "    rn = run_name(model_name, encoder_name)\n",
        "    return os.path.join(\"AITDM\", rn, \"checkpoints\", f\"client_{cid}_best.json\")\n",
        "\n",
        "\n",
        "def load_model(model_name: str, encoder_name: str, cid: int):\n",
        "    path = ckpt_path(model_name, encoder_name, cid)\n",
        "    if not os.path.isfile(path):\n",
        "        raise FileNotFoundError(f\"Missing checkpoint: {path}\")\n",
        "    m = build_model(model_name, encoder_name).to(DEVICE)\n",
        "    sd = torch.load(path, map_location=\"cpu\")\n",
        "    m.load_state_dict(sd, strict=True)\n",
        "    m.eval()\n",
        "    return m\n",
        "\n",
        "\n",
        "def load_best_val_dice(model_name: str, encoder_name: str, cid: int) -> float:\n",
        "    p = best_json_path(model_name, encoder_name, cid)\n",
        "    if not os.path.isfile(p):\n",
        "        raise FileNotFoundError(f\"Missing best json: {p}\")\n",
        "    with open(p, \"r\") as f:\n",
        "        j = json.load(f)\n",
        "    return float(j.get(\"val_dice\", 0.0))\n",
        "\n",
        "\n",
        "def get_client_weights(cid: int, cfgs, mode=\"power\", power=2.0, eps=1e-6):\n",
        "    dices = [load_best_val_dice(mn, enc, cid) for (mn, enc) in cfgs]\n",
        "    d = np.array(dices, dtype=np.float32)\n",
        "\n",
        "    if mode == \"linear\":\n",
        "        raw = np.clip(d, 0.0, None)\n",
        "    elif mode == \"power\":\n",
        "        raw = np.power(np.clip(d, 0.0, None), power)\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'linear' or 'power'\")\n",
        "\n",
        "    raw = raw + eps\n",
        "    w = raw / raw.sum()\n",
        "    return w.tolist(), dices\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ensemble_forward_logits(x, models, weights, target_hw=None):\n",
        "    w = np.array(weights, dtype=np.float32)\n",
        "    w = w / (w.sum() + 1e-8)\n",
        "\n",
        "    logits_sum = None\n",
        "    for mi, wi in zip(models, w):\n",
        "        li = mi(x)\n",
        "        if target_hw is not None and li.shape[-2:] != target_hw:\n",
        "            li = F.interpolate(li, size=target_hw, mode=\"bilinear\", align_corners=False)\n",
        "        logits_sum = li * float(wi) if logits_sum is None else logits_sum + li * float(wi)\n",
        "    return logits_sum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_ensemble_on_client(cid: int, threshold=0.5):\n",
        "    val_loader, nva = get_val_loader(cid)\n",
        "    models = [load_model(mn, enc, cid) for (mn, enc) in ENSEMBLE_CFGS]\n",
        "\n",
        "    weights, best_dices = get_client_weights(\n",
        "        cid, ENSEMBLE_CFGS, mode=WEIGHT_MODE, power=WEIGHT_POWER, eps=WEIGHT_EPS\n",
        "    )\n",
        "\n",
        "    tot_loss = tot_d = tot_i = tot_a = 0.0\n",
        "    nb = 0\n",
        "\n",
        "    for batch in val_loader:\n",
        "        x = batch[\"x\"].to(DEVICE)\n",
        "        y = batch[\"y\"].to(DEVICE)\n",
        "\n",
        "        logits = ensemble_forward_logits(x, models=models, weights=weights, target_hw=y.shape[-2:])\n",
        "        loss = float(criterion(logits, y).item())\n",
        "\n",
        "        preds_bin = (torch.sigmoid(logits).cpu().numpy() > threshold).astype(np.uint8)\n",
        "        y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        d, i, a = calc_metrics(y_np, preds_bin)\n",
        "\n",
        "        tot_loss += loss\n",
        "        tot_d += d\n",
        "        tot_i += i\n",
        "        tot_a += a\n",
        "        nb += 1\n",
        "\n",
        "    nb = max(nb, 1)\n",
        "    return {\n",
        "        \"cid\": int(cid),\n",
        "        \"nva\": int(nva),\n",
        "        \"loss\": tot_loss / nb,\n",
        "        \"dice\": tot_d / nb,\n",
        "        \"iou\": tot_i / nb,\n",
        "        \"acc\": tot_a / nb,\n",
        "        \"weights\": weights,\n",
        "        \"best_dices\": best_dices,\n",
        "    }\n",
        "\n",
        "\n",
        "def log_client_metrics(file_path, r, bd, ww):\n",
        "\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    log_message = (\n",
        "        f\"Client {r['cid']} (n={r['nva']}): \"\n",
        "        f\"loss={r['loss']:.4f} dice={r['dice']:.4f} iou={r['iou']:.4f} acc={r['acc']:.4f}\\n\"\n",
        "        f\"  best_dice={['%.4f' % x for x in bd]} -> weights={['%.3f' % x for x in ww]}\\n\"\n",
        "    )\n",
        "\n",
        "    print(log_message, end='')\n",
        "\n",
        "    with open(file_path, \"a\") as f:\n",
        "        f.write(log_message)\n",
        "\n",
        "def main():\n",
        "    print(f\"[Ensemble-3 | threshold={THRESHOLD} | weight_mode={WEIGHT_MODE} | power={WEIGHT_POWER}]\\n\")\n",
        "    for cid in [0, 1, 2]:\n",
        "        r = eval_ensemble_on_client(cid, threshold=THRESHOLD)\n",
        "        bd = r[\"best_dices\"]\n",
        "        ww = r[\"weights\"]\n",
        "        log_client_metrics(os.path.join('/content/AITDM', f\"client_{cid}\", \"val_metrics_ensemble.txt\"), r, bd, ww)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shmBX33rsW2J"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/drive/MyDrive/AITDM\n",
        "!cp -rf /content/AITDM /content/drive/MyDrive/AITDM/QUANT_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNd0J5c_sqsQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el0NG8Q3rV-j"
      },
      "source": [
        "# **M2 - FL with ensemble and Top-K Sparsification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eX2ZIrirgTh"
      },
      "outputs": [],
      "source": [
        "%%writefile seg_data.py\n",
        "import os, pickle, numpy as np, torch\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchio as tio\n",
        "\n",
        "# Global paths and configuration\n",
        "DATA_ROOT = \"/content/Preprocessed-Data\"\n",
        "METADATA_DF_PATH = \"cleaned_df.pkl\"\n",
        "USE_ATLAS = True\n",
        "EXCLUDE_IDS = [\"PatientID_0191\"]\n",
        "\n",
        "# Dataset that loads MRI, tumor mask and optional atlas for each patient\n",
        "class ImageOnlyGliomaDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        metadata_df_path,\n",
        "        data_root,\n",
        "        use_atlas=False,\n",
        "        exclude_ids=None,\n",
        "        transform=None,\n",
        "    ):\n",
        "        with open(metadata_df_path, \"rb\") as f:\n",
        "            df = pickle.load(f)\n",
        "\n",
        "        if exclude_ids is None:\n",
        "            exclude_ids = []\n",
        "\n",
        "        self.df = df[~df[\"Patient_ID\"].isin(exclude_ids)].reset_index(drop=True)\n",
        "        self.data_root = data_root\n",
        "        self.use_atlas = use_atlas\n",
        "        self.transform = transform\n",
        "\n",
        "        self.patient_ids = []\n",
        "        for pid in sorted(self.df[\"Patient_ID\"].tolist()):\n",
        "            base = os.path.join(self.data_root, pid)\n",
        "            mri_p = os.path.join(base, f\"{pid}_mri.npy\")\n",
        "            tumor_p = os.path.join(base, f\"{pid}_tumor.npy\")\n",
        "\n",
        "            is_valid = os.path.isfile(mri_p) and os.path.isfile(tumor_p)\n",
        "            if self.use_atlas:\n",
        "                reg_p = os.path.join(base, f\"{pid}_regions.npy\")\n",
        "                is_valid = is_valid and os.path.isfile(reg_p)\n",
        "\n",
        "            if is_valid:\n",
        "                self.patient_ids.append(pid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def _minmax(x):\n",
        "        x = x.astype(np.float32)\n",
        "        mn, mx = np.min(x), np.max(x)\n",
        "        if mx > mn:\n",
        "            return (x - mn) / (mx - mn)\n",
        "        return np.zeros_like(x, dtype=np.float32)\n",
        "\n",
        "    def _to_torchio_format(self, arr):\n",
        "        \"\"\"\n",
        "        Convertește (H, W) -> (1, H, W, 1) pentru procesare internă TorchIO.\n",
        "        \"\"\"\n",
        "        if arr.ndim == 2:\n",
        "            return arr[np.newaxis, ..., np.newaxis]\n",
        "        return arr\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pid = self.patient_ids[idx]\n",
        "        base = os.path.join(self.data_root, pid)\n",
        "\n",
        "        mri = np.load(os.path.join(base, f\"{pid}_mri.npy\")).astype(np.float32)\n",
        "        tumor = np.load(os.path.join(base, f\"{pid}_tumor.npy\")).astype(np.float32)\n",
        "\n",
        "\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "\n",
        "        regions = None\n",
        "        if self.use_atlas:\n",
        "            regions = np.load(os.path.join(base, f\"{pid}_regions.npy\")).astype(np.float32)\n",
        "\n",
        "        mri = self._minmax(mri)\n",
        "        tumor = (tumor > 0.5).astype(np.float32)\n",
        "\n",
        "        if regions is not None:\n",
        "            regions = self._minmax(regions)\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            subject_dict = {\n",
        "                'mri': tio.ScalarImage(tensor=self._to_torchio_format(mri)),\n",
        "                'tumor': tio.LabelMap(tensor=self._to_torchio_format(tumor)),\n",
        "            }\n",
        "            if regions is not None:\n",
        "                subject_dict['regions'] = tio.ScalarImage(tensor=self._to_torchio_format(regions))\n",
        "\n",
        "            subject = tio.Subject(subject_dict)\n",
        "\n",
        "            subject = self.transform(subject)\n",
        "\n",
        "            out_mri = subject['mri'].data[0, ..., 0].numpy()\n",
        "            out_tumor = subject['tumor'].data[0, ..., 0].numpy()\n",
        "            sample = {\n",
        "                \"patient_id\": pid,\n",
        "                \"mri\": out_mri,       # Shape: (240, 240)\n",
        "                \"tumor\": out_tumor    # Shape: (240, 240)\n",
        "            }\n",
        "\n",
        "            if regions is not None:\n",
        "                out_regions = subject['regions'].data[0, ..., 0].numpy()\n",
        "                sample[\"regions\"] = out_regions # Shape: (240, 240)\n",
        "\n",
        "            return sample\n",
        "\n",
        "        sample = {\"patient_id\": pid, \"mri\": mri, \"tumor\": tumor}\n",
        "\n",
        "        if self.use_atlas:\n",
        "            sample[\"regions\"] = regions\n",
        "\n",
        "        return sample\n",
        "\n",
        "# Collate function to build batched tensors and patient ID list\n",
        "def image_only_collate_fn(batch, use_atlas=USE_ATLAS):\n",
        "    mri = torch.stack([torch.tensor(it[\"mri\"]) for it in batch]).unsqueeze(1)\n",
        "    y = torch.stack([torch.tensor(it[\"tumor\"]) for it in batch]).unsqueeze(1)\n",
        "\n",
        "    if use_atlas:\n",
        "        regs = torch.stack([torch.tensor(it[\"regions\"]) for it in batch]).unsqueeze(1)\n",
        "        x = torch.cat([mri.float(), regs.float()], dim=1)\n",
        "    else:\n",
        "        x = mri.float()\n",
        "\n",
        "    return {\"x\": x, \"y\": y.float(), \"pid\": [it[\"patient_id\"] for it in batch]}\n",
        "\n",
        "# Dataset wrapper that restricts to a subset of patient IDs\n",
        "class SubsetByPIDs(Dataset):\n",
        "    def __init__(self, full_dataset: ImageOnlyGliomaDataset, pid_list: List[str]):\n",
        "        self.ds = full_dataset\n",
        "        pid_to_idx = {pid: i for i, pid in enumerate(self.ds.patient_ids)}\n",
        "        self.indices = [pid_to_idx[p] for p in pid_list if p in pid_to_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.ds[self.indices[i]]\n",
        "\n",
        "# Compute Dice, IoU and accuracy for binary masks\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
        "\n",
        "    inter = (y_true & y_pred).sum()\n",
        "    dice = (2.0 * inter) / (y_true.sum() + y_pred.sum() + 1e-8)\n",
        "    union = y_true.sum() + y_pred.sum() - inter + 1e-8\n",
        "    iou = inter / union\n",
        "    acc = (y_true == y_pred).mean()\n",
        "\n",
        "    return float(dice), float(iou), float(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNt9AJ5jrmSb"
      },
      "outputs": [],
      "source": [
        "%%writefile fl_client.py\n",
        "import os\n",
        "os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":4096:8\")\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import flwr as fl\n",
        "import copy\n",
        "import segmentation_models_pytorch as smp\n",
        "import random\n",
        "import torchio as tio\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from seg_data import (\n",
        "    ImageOnlyGliomaDataset,\n",
        "    SubsetByPIDs,\n",
        "    image_only_collate_fn,\n",
        "    calc_metrics,\n",
        "    DATA_ROOT,\n",
        "    METADATA_DF_PATH,\n",
        "    USE_ATLAS,\n",
        ")\n",
        "\n",
        "CLIENT_DIR = \"/content/client\"\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42\n",
        "SPARSITY_RATE = 0.1\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "DEFAULT_MODEL_NAME = \"unet\"\n",
        "DEFAULT_ENCODER_NAME = \"timm-mobilenetv3_small_100\"\n",
        "DEFAULT_ENCODER_WEIGHTS = \"imagenet\"\n",
        "TRANSFORMS = None\n",
        "\n",
        "\n",
        "def _run_name(model_name: str, encoder_name: str) -> str:\n",
        "    return f\"{model_name}__{encoder_name}\".replace(\"/\", \"-\")\n",
        "\n",
        "\n",
        "def seed_everything(seed: int, deterministic: bool = True) -> None:\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    try:\n",
        "        torch.set_float32_matmul_precision(\"high\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    if deterministic:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id: int) -> None:\n",
        "    worker_seed = (torch.initial_seed() + worker_id) % (2**32)\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def log_transfer_metrics(file_path, cid, rnd, incoming, outgoing, overhead):\n",
        "    \"\"\"Functie helper pentru a salva metricile de transfer in fisier.\"\"\"\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    msg = (f\"Client {cid} Round {rnd}: \"\n",
        "           f\"Incoming {incoming/1024:.2f} KB | \"\n",
        "           f\"Outgoing (Actual Sparse Packet) {outgoing/1024:.2f} KB | \"\n",
        "           f\"Overhead: {overhead:.6f}s\\n\")\n",
        "\n",
        "    with open(file_path, \"a\") as f:\n",
        "        f.write(msg)\n",
        "\n",
        "\n",
        "def get_model(\n",
        "    model_name=DEFAULT_MODEL_NAME,\n",
        "    encoder_name=DEFAULT_ENCODER_NAME,\n",
        "    encoder_weights=DEFAULT_ENCODER_WEIGHTS,\n",
        "):\n",
        "    in_ch = 2 if USE_ATLAS else 1\n",
        "    mn = model_name.lower()\n",
        "\n",
        "    if mn == \"unet\":\n",
        "        model = smp.Unet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    elif mn in [\"deeplabv3plus\", \"deeplabv3+\", \"dlv3p\"]:\n",
        "        model = smp.DeepLabV3Plus(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_name={model_name}. Use 'unet' or 'deeplabv3plus'.\")\n",
        "\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "\n",
        "def get_loaders(cid: int, base_seed: int, transforms):\n",
        "    full = ImageOnlyGliomaDataset(\n",
        "        METADATA_DF_PATH,\n",
        "        DATA_ROOT,\n",
        "        use_atlas=USE_ATLAS,\n",
        "        exclude_ids=[\"PatientID_0191\"],\n",
        "        transform=transforms,\n",
        "    )\n",
        "\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"train_pids.json\")) as f:\n",
        "        tr_p = json.load(f)\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"val_pids.json\")) as f:\n",
        "        va_p = json.load(f)\n",
        "\n",
        "    ds_tr = SubsetByPIDs(full, tr_p)\n",
        "    ds_va = SubsetByPIDs(full, va_p)\n",
        "\n",
        "    g_tr = torch.Generator().manual_seed(base_seed + 12345)\n",
        "    g_va = torch.Generator().manual_seed(base_seed + 67890)\n",
        "\n",
        "    ld_tr = DataLoader(\n",
        "        ds_tr,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g_tr,\n",
        "        persistent_workers=(NUM_WORKERS > 0),\n",
        "    )\n",
        "\n",
        "    ld_va = DataLoader(\n",
        "        ds_va,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g_va,\n",
        "        persistent_workers=(NUM_WORKERS > 0),\n",
        "    )\n",
        "\n",
        "    return ld_tr, ld_va, len(ds_tr), len(ds_va)\n",
        "\n",
        "\n",
        "def get_parameters(model):\n",
        "    return [p.detach().cpu().numpy() for _, p in model.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(model, params):\n",
        "    sd = model.state_dict()\n",
        "    for k, v in zip(sd.keys(), params):\n",
        "        sd[k] = torch.tensor(v)\n",
        "    model.load_state_dict(sd, strict=True)\n",
        "\n",
        "\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "dice_loss = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "\n",
        "\n",
        "def criterion(pred, y):\n",
        "    return 0.5 * bce(pred, y) + 0.5 * dice_loss(pred, y)\n",
        "\n",
        "\n",
        "def maybe_save_best(run_dir, cid, val_loss, val_dice, best_epoch, rnd, model):\n",
        "    ckpt_dir = os.path.join(run_dir, \"checkpoints\")\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "    best_json = os.path.join(ckpt_dir, f\"client_{cid}_best.json\")\n",
        "    best_pt = os.path.join(ckpt_dir, f\"client_{cid}_best.pt\")\n",
        "\n",
        "    prev = {\"val_loss\": float(\"inf\"), \"val_dice\": -1.0}\n",
        "    if os.path.isfile(best_json):\n",
        "        try:\n",
        "            with open(best_json, \"r\") as f:\n",
        "                prev = json.load(f)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    improved = (val_loss < prev.get(\"val_loss\", float(\"inf\"))) and (val_dice > prev.get(\"val_dice\", -1.0))\n",
        "    if improved:\n",
        "        torch.save(model.state_dict(), best_pt)\n",
        "        with open(best_json, \"w\") as f:\n",
        "            json.dump(\n",
        "                {\n",
        "                    \"round\": int(rnd),\n",
        "                    \"epoch\": int(best_epoch),\n",
        "                    \"val_loss\": float(val_loss),\n",
        "                    \"val_dice\": float(val_dice),\n",
        "                },\n",
        "                f,\n",
        "            )\n",
        "\n",
        "\n",
        "class SegClient(fl.client.NumPyClient):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cid: int,\n",
        "        model_name=DEFAULT_MODEL_NAME,\n",
        "        encoder_name=DEFAULT_ENCODER_NAME,\n",
        "        encoder_weights=DEFAULT_ENCODER_WEIGHTS,\n",
        "    ):\n",
        "        self.cid = int(cid)\n",
        "        self.model_name = model_name\n",
        "        self.encoder_name = encoder_name\n",
        "        self.encoder_weights = encoder_weights\n",
        "\n",
        "        self.base_seed = SEED + self.cid\n",
        "        seed_everything(self.base_seed, deterministic=True)\n",
        "\n",
        "        self.run_name = _run_name(model_name, encoder_name)\n",
        "        self.run_dir = os.path.join(\"AITDM\", self.run_name)\n",
        "\n",
        "        self.model = get_model(model_name, encoder_name, encoder_weights)\n",
        "        if self.cid != 2:\n",
        "            self.train_loader, self.val_loader, self.ntr, self.nva = get_loaders(self.cid, self.base_seed, transforms=TRANSFORMS)\n",
        "        else:\n",
        "            self.train_loader, self.val_loader, self.ntr, self.nva = get_loaders(self.cid, self.base_seed, transforms=TRANSFORMS)\n",
        "\n",
        "        self.residual = [np.zeros_like(p) for p in get_parameters(self.model)]\n",
        "        self.sparsity_rate = SPARSITY_RATE\n",
        "\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.model)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # --- MEASURE INCOMING ---\n",
        "        incoming_size = sum([p.nbytes for p in parameters])\n",
        "\n",
        "        global_parameters = [np.copy(p) for p in parameters]\n",
        "\n",
        "        set_parameters(self.model, parameters)\n",
        "\n",
        "        epochs = int(config.get(\"local_epochs\", 1))\n",
        "        lr = float(config.get(\"lr\", 1e-3))\n",
        "        rnd = int(config.get(\"round\", 0))\n",
        "\n",
        "        opt = optim.AdamW(self.model.parameters(), lr=lr)\n",
        "        scaler = torch.amp.GradScaler(\"cuda\", enabled=(DEVICE.type == \"cuda\"))\n",
        "\n",
        "        best_state = None\n",
        "        best_val_loss = float(\"inf\")\n",
        "        best_val_dice = -1.0\n",
        "        best_epoch_idx = -1\n",
        "        epoch_logs = []\n",
        "\n",
        "        # --- TRAINING LOOP ---\n",
        "        for epoch_idx in range(1, epochs + 1):\n",
        "            self.model.train()\n",
        "            tot_tr_loss = tot_tr_d = tot_tr_i = tot_tr_a = 0.0\n",
        "            nb_tr = 0\n",
        "\n",
        "            for batch in self.train_loader:\n",
        "                x = batch[\"x\"].to(DEVICE)\n",
        "                y = batch[\"y\"].to(DEVICE)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "\n",
        "                with torch.amp.autocast(\"cuda\", enabled=(DEVICE.type == \"cuda\")):\n",
        "                    pred = self.model(x)\n",
        "                    loss = criterion(pred, y)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    y_hat = (torch.sigmoid(pred).detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    y_np = (y.detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                tot_tr_loss += float(loss.item())\n",
        "                tot_tr_d += d\n",
        "                tot_tr_i += i\n",
        "                tot_tr_a += a\n",
        "                nb_tr += 1\n",
        "\n",
        "            nb_tr = max(nb_tr, 1)\n",
        "            epoch_tr_loss = tot_tr_loss / nb_tr\n",
        "            epoch_tr_dice = tot_tr_d / nb_tr\n",
        "            epoch_tr_iou = tot_tr_i / nb_tr\n",
        "            epoch_tr_acc = tot_tr_a / nb_tr\n",
        "\n",
        "            self.model.eval()\n",
        "            tot_val_loss = tot_val_d = tot_val_i = tot_val_a = 0.0\n",
        "            nb_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in self.val_loader:\n",
        "                    x = batch[\"x\"].to(DEVICE)\n",
        "                    y = batch[\"y\"].to(DEVICE)\n",
        "                    pred = self.model(x)\n",
        "\n",
        "                    v_loss = float(criterion(pred, y).item())\n",
        "                    y_hat = (torch.sigmoid(pred).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                    d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                    tot_val_loss += v_loss\n",
        "                    tot_val_d += d\n",
        "                    tot_val_i += i\n",
        "                    tot_val_a += a\n",
        "                    nb_val += 1\n",
        "\n",
        "            nb_val = max(nb_val, 1)\n",
        "            epoch_val_loss = tot_val_loss / nb_val\n",
        "            epoch_val_dice = tot_val_d / nb_val\n",
        "            epoch_val_iou = tot_val_i / nb_val\n",
        "            epoch_val_acc = tot_val_a / nb_val\n",
        "\n",
        "            epoch_logs.append(\n",
        "                {\n",
        "                    \"epoch\": int(epoch_idx),\n",
        "                    \"train_loss\": float(epoch_tr_loss),\n",
        "                    \"train_dice\": float(epoch_tr_dice),\n",
        "                    \"train_iou\": float(epoch_tr_iou),\n",
        "                    \"train_acc\": float(epoch_tr_acc),\n",
        "                    \"val_loss\": float(epoch_val_loss),\n",
        "                    \"val_dice\": float(epoch_val_dice),\n",
        "                    \"val_iou\": float(epoch_val_iou),\n",
        "                    \"val_acc\": float(epoch_val_acc),\n",
        "                }\n",
        "            )\n",
        "\n",
        "            if (epoch_val_loss < best_val_loss) and (epoch_val_dice > best_val_dice):\n",
        "                best_val_loss = epoch_val_loss\n",
        "                best_val_dice = epoch_val_dice\n",
        "                best_state = copy.deepcopy(self.model.state_dict())\n",
        "                best_epoch_idx = epoch_idx\n",
        "\n",
        "        if best_state is not None:\n",
        "            self.model.load_state_dict(best_state)\n",
        "\n",
        "        for ep in epoch_logs:\n",
        "            ep[\"best_epoch\"] = (ep[\"epoch\"] == best_epoch_idx)\n",
        "\n",
        "        train_metrics = {\n",
        "            \"cid\": int(self.cid),\n",
        "            \"best_epoch\": int(best_epoch_idx),\n",
        "            \"best_val_loss\": float(best_val_loss),\n",
        "            \"best_val_dice\": float(best_val_dice),\n",
        "            \"per_epoch\": json.dumps(epoch_logs),\n",
        "            \"run_name\": self.run_name,\n",
        "            \"model_name\": self.model_name,\n",
        "            \"encoder_name\": self.encoder_name,\n",
        "        }\n",
        "\n",
        "        maybe_save_best(self.run_dir, self.cid, best_val_loss, best_val_dice, best_epoch_idx, rnd, self.model)\n",
        "\n",
        "        start_overhead = time.time()\n",
        "\n",
        "        trained_parameters = get_parameters(self.model)\n",
        "\n",
        "        parameters_to_send_flower = []\n",
        "        actual_transmission_size = 0\n",
        "\n",
        "        for i, (new_w, old_w, res) in enumerate(zip(trained_parameters, global_parameters, self.residual)):\n",
        "            update = new_w - old_w\n",
        "            accumulated_update = update + res\n",
        "\n",
        "            flat = accumulated_update.flatten()\n",
        "            k = int(flat.size * self.sparsity_rate)\n",
        "\n",
        "            if k > 0:\n",
        "                idx = np.argpartition(np.abs(flat), -k)[-k:]\n",
        "                threshold = np.min(np.abs(flat[idx]))\n",
        "            else:\n",
        "                threshold = np.inf\n",
        "\n",
        "            mask = np.abs(accumulated_update) >= threshold\n",
        "            sparse_update = accumulated_update * mask\n",
        "            self.residual[i] = accumulated_update - sparse_update\n",
        "\n",
        "\n",
        "            non_zero_values = sparse_update[mask]\n",
        "\n",
        "            non_zero_indices = np.where(mask.flatten())[0]\n",
        "\n",
        "            actual_transmission_size += non_zero_values.nbytes + non_zero_indices.nbytes\n",
        "\n",
        "\n",
        "            param_to_send = old_w + sparse_update\n",
        "            parameters_to_send_flower.append(param_to_send)\n",
        "\n",
        "        end_overhead = time.time()\n",
        "\n",
        "        # --- LOGGING ---\n",
        "        print(f\"Client {self.cid} Round {rnd}: Incoming {incoming_size/1024:.2f} KB | Outgoing (Packed Sparse) {actual_transmission_size/1024:.2f} KB | Overhead: {end_overhead - start_overhead:.6f}s\")\n",
        "\n",
        "        log_file_path = os.path.join(self.run_dir, f\"client_{self.cid}_transfer_log.txt\")\n",
        "        log_transfer_metrics(log_file_path, self.cid, rnd, incoming_size, actual_transmission_size, end_overhead - start_overhead)\n",
        "\n",
        "        return parameters_to_send_flower, self.ntr, train_metrics\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        self.model.eval()\n",
        "\n",
        "        tot_loss = tot_d = tot_i = tot_a = 0.0\n",
        "        nb = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_loader:\n",
        "                x = batch[\"x\"].to(DEVICE)\n",
        "                y = batch[\"y\"].to(DEVICE)\n",
        "                pred = self.model(x)\n",
        "\n",
        "                loss = float(criterion(pred, y).item())\n",
        "                y_hat = (torch.sigmoid(pred).cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "                d, i, a = calc_metrics(y_np, y_hat)\n",
        "\n",
        "                tot_loss += loss\n",
        "                tot_d += d\n",
        "                tot_i += i\n",
        "                tot_a += a\n",
        "                nb += 1\n",
        "\n",
        "        nb = max(nb, 1)\n",
        "        metrics = {\n",
        "            \"loss\": tot_loss / nb,\n",
        "            \"dice\": tot_d / nb,\n",
        "            \"iou\": tot_i / nb,\n",
        "            \"acc\": tot_a / nb,\n",
        "            \"cid\": int(self.cid),\n",
        "            \"run_name\": self.run_name,\n",
        "        }\n",
        "\n",
        "        return metrics[\"loss\"], self.nva, metrics\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--cid\", type=int, required=True)\n",
        "    parser.add_argument(\"--server\", default=\"0.0.0.0:8080\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    fl.client.start_numpy_client(\n",
        "        server_address=args.server,\n",
        "        client=SegClient(args.cid),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkJJe4fDrp6P"
      },
      "outputs": [],
      "source": [
        "%%writefile fl_sim_colab.py\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import torch\n",
        "import flwr as fl\n",
        "import time\n",
        "from flwr.common import FitIns\n",
        "import torchio as tio\n",
        "from fl_client import SegClient\n",
        "\n",
        "import logging\n",
        "import warnings\n",
        "logging.getLogger(\"flwr\").setLevel(logging.ERROR)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def ensure_csv(path: str, header: list[str]):\n",
        "    if not os.path.isfile(path):\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, \"w\", newline=\"\") as f:\n",
        "            csv.writer(f).writerow(header)\n",
        "\n",
        "\n",
        "def append_row(path: str, row: list):\n",
        "    with open(path, \"a\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow(row)\n",
        "\n",
        "\n",
        "def log_server_metrics(file_path, rnd, duration):\n",
        "    \"\"\"Functie helper pentru logare timp agregare server in fisier.\"\"\"\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    msg = f\"Round {rnd} Aggregation Time: {duration:.4f} seconds\\n\"\n",
        "\n",
        "    with open(file_path, \"a\") as f:\n",
        "        f.write(msg)\n",
        "\n",
        "\n",
        "class PerClientLoggingFedAvg(fl.server.strategy.FedAvg):\n",
        "    def __init__(self, metrics_dir: str, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.metrics_dir = metrics_dir\n",
        "        self.header = [\n",
        "            \"round\",\"epoch\",\"train_loss\",\"train_dice\",\"train_iou\",\"train_acc\",\n",
        "            \"val_loss\",\"val_dice\",\"val_iou\",\"val_acc\",\"best_epoch\",\n",
        "        ]\n",
        "\n",
        "    def configure_fit(self, server_round, parameters, client_manager):\n",
        "        items = super().configure_fit(server_round, parameters, client_manager)\n",
        "        out = []\n",
        "        for it in items:\n",
        "            if isinstance(it, tuple):\n",
        "                client, fitins = it\n",
        "            else:\n",
        "                client, fitins = None, it\n",
        "\n",
        "            cfg = dict(fitins.config)\n",
        "            cfg[\"round\"] = server_round\n",
        "            new_fitins = FitIns(fitins.parameters, cfg)\n",
        "            out.append((client, new_fitins) if client is not None else new_fitins)\n",
        "        return out\n",
        "\n",
        "    def aggregate_fit(self, rnd, results, failures):\n",
        "        # --- START TIMER ---\n",
        "        curr_cid = 0\n",
        "        total_uplink_bytes = 0\n",
        "        for client_proxy, fit_res in results:\n",
        "            client_bytes = sum(len(t) for t in fit_res.parameters.tensors)\n",
        "            total_uplink_bytes += client_bytes\n",
        "            print(f\"Client {curr_cid} has sent {client_bytes} bytes!\")\n",
        "            curr_cid += 1\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "\n",
        "        agg = super().aggregate_fit(rnd, results, failures)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        print(f\"Round {rnd} Aggregation Time: {end_time - start_time:.4f} seconds\")\n",
        "        log_file_path = os.path.join(self.metrics_dir, \"server_aggregation_log.txt\")\n",
        "        log_server_metrics(log_file_path, rnd, end_time - start_time)\n",
        "\n",
        "        for client_proxy, fit_res in results:\n",
        "            m = fit_res.metrics or {}\n",
        "            cid = str(m.get(\"cid\", client_proxy.cid))\n",
        "\n",
        "            client_csv = os.path.join(self.metrics_dir, f\"metrics_client_{cid}.csv\")\n",
        "            ensure_csv(client_csv, self.header)\n",
        "\n",
        "            best_epoch = int(m.get(\"best_epoch\", -1))\n",
        "            per_epoch_raw = m.get(\"per_epoch\", \"[]\")\n",
        "\n",
        "            try:\n",
        "                per_epoch = json.loads(per_epoch_raw)\n",
        "            except Exception:\n",
        "                per_epoch = []\n",
        "\n",
        "            for ep in per_epoch:\n",
        "                epoch = ep.get(\"epoch\", \"\")\n",
        "                row = [\n",
        "                    rnd,\n",
        "                    epoch,\n",
        "                    ep.get(\"train_loss\", \"\"),\n",
        "                    ep.get(\"train_dice\", \"\"),\n",
        "                    ep.get(\"train_iou\", \"\"),\n",
        "                    ep.get(\"train_acc\", \"\"),\n",
        "                    ep.get(\"val_loss\", \"\"),\n",
        "                    ep.get(\"val_dice\", \"\"),\n",
        "                    ep.get(\"val_iou\", \"\"),\n",
        "                    ep.get(\"val_acc\", \"\"),\n",
        "                    \"x\" if int(epoch) == best_epoch else \"\",\n",
        "                ]\n",
        "                append_row(client_csv, row)\n",
        "\n",
        "        return agg\n",
        "\n",
        "\n",
        "def run_one_experiment(model_name: str, encoder_name: str, num_rounds=5, local_epochs=5, lr=1e-3):\n",
        "    run_name = f\"{model_name}__{encoder_name}\".replace(\"/\", \"-\")\n",
        "    base_dir = os.path.join(\"AITDM\", run_name)\n",
        "    metrics_dir = os.path.join(base_dir, \"metrics\")\n",
        "    os.makedirs(metrics_dir, exist_ok=True)\n",
        "\n",
        "    def client_fn(cid: str):\n",
        "        return SegClient(int(cid), model_name=model_name, encoder_name=encoder_name).to_client()\n",
        "\n",
        "    strategy = PerClientLoggingFedAvg(\n",
        "        metrics_dir=metrics_dir,\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=1.0,\n",
        "        min_fit_clients=3,\n",
        "        min_evaluate_clients=3,\n",
        "        min_available_clients=3,\n",
        "        on_fit_config_fn=lambda rnd: {\"local_epochs\": local_epochs, \"lr\": lr},\n",
        "    )\n",
        "\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0 if use_gpu else 0.0}\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=3,\n",
        "        config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "        strategy=strategy,\n",
        "        client_resources=client_resources,\n",
        "        ray_init_args={\"include_dashboard\": False},\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    experiments = [\n",
        "        (\"unet\", \"resnet50\"),\n",
        "        (\"unet\", \"mit_b3\"),\n",
        "        (\"deeplabv3plus\", \"timm-mobilenetv3_small_100\"),\n",
        "    ]\n",
        "\n",
        "    for model_name, encoder_name in experiments:\n",
        "        print(f\"\\n=== Running: {model_name} + {encoder_name} ===\")\n",
        "        start_time = time.time()\n",
        "        run_one_experiment(model_name, encoder_name, num_rounds=15, local_epochs=10, lr=1e-3)\n",
        "        run_time = time.time() - start_time\n",
        "        print(f\"Total run time: {run_time:.2f} seconds\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WszVmborshC"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/AITDM/client_0/*\n",
        "!rm -rf /content/AITDM/client_1/*\n",
        "!rm -rf /content/AITDM/client_2/*\n",
        "!rm -rf /content/AITDM/deeplabv3plus__timm-mobilenetv3_small_100/checkpoints/*\n",
        "!rm -rf /content/AITDM/unet__resnet50/checkpoints/*\n",
        "!rm -rf /content/AITDM/unet__mit_b3/checkpoints/*\n",
        "!rm -rf /content/AITDM/deeplabv3plus__timm-mobilenetv3_small_100/metrics/*\n",
        "!rm -rf /content/AITDM/unet__resnet50/metrics/*\n",
        "!rm -rf /content/AITDM/unet__mit_b3/metrics/*\n",
        "!python fl_sim_colab.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7YHrNwervrA"
      },
      "outputs": [],
      "source": [
        "import os, json, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import segmentation_models_pytorch as smp\n",
        "import logging\n",
        "from fl_client import TRANSFORMS\n",
        "\n",
        "from seg_data import (\n",
        "    ImageOnlyGliomaDataset,\n",
        "    SubsetByPIDs,\n",
        "    image_only_collate_fn,\n",
        "    DATA_ROOT,\n",
        "    METADATA_DF_PATH,\n",
        "    USE_ATLAS,\n",
        "    calc_metrics,\n",
        ")\n",
        "\n",
        "logging.getLogger(\"timm.models._builder\").setLevel(logging.ERROR)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEED = 42\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "CLIENT_DIR = \"/content/client\"\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "ENSEMBLE_CFGS = [\n",
        "    (\"unet\", \"resnet50\"),\n",
        "    (\"unet\", \"mit_b3\"),\n",
        "    (\"deeplabv3plus\", \"timm-mobilenetv3_small_100\"),\n",
        "]\n",
        "\n",
        "WEIGHT_MODE = \"power\"\n",
        "WEIGHT_POWER = 14.0\n",
        "WEIGHT_EPS = 1e-6\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "dice_loss = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "\n",
        "\n",
        "def criterion(logits, y):\n",
        "    return 0.5 * bce(logits, y) + 0.5 * dice_loss(logits, y)\n",
        "\n",
        "\n",
        "def get_val_loader(cid: int):\n",
        "    full = ImageOnlyGliomaDataset(\n",
        "        METADATA_DF_PATH, DATA_ROOT, use_atlas=USE_ATLAS, exclude_ids=[\"PatientID_0191\"]\n",
        "    )\n",
        "    with open(os.path.join(CLIENT_DIR, f\"client_{cid}\", \"val_pids.json\")) as f:\n",
        "        va_p = json.load(f)\n",
        "\n",
        "    ds_va = SubsetByPIDs(full, va_p)\n",
        "    g = torch.Generator().manual_seed(SEED)\n",
        "\n",
        "    ld_va = torch.utils.data.DataLoader(\n",
        "        ds_va,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        collate_fn=lambda b: image_only_collate_fn(b, use_atlas=USE_ATLAS),\n",
        "        generator=g,\n",
        "    )\n",
        "    return ld_va, len(ds_va)\n",
        "\n",
        "\n",
        "def run_name(model_name: str, encoder_name: str) -> str:\n",
        "    return f\"{model_name}__{encoder_name}\".replace(\"/\", \"-\")\n",
        "\n",
        "\n",
        "def build_model(model_name: str, encoder_name: str, encoder_weights=\"imagenet\"):\n",
        "    in_ch = 2 if USE_ATLAS else 1\n",
        "    mn = model_name.lower()\n",
        "\n",
        "    if mn == \"unet\":\n",
        "        m = smp.Unet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    elif mn in [\"deeplabv3plus\", \"deeplabv3+\", \"dlv3p\"]:\n",
        "        m = smp.DeepLabV3Plus(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_ch,\n",
        "            classes=1,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_name={model_name}\")\n",
        "\n",
        "    return m.to(DEVICE)\n",
        "\n",
        "\n",
        "def ckpt_path(model_name: str, encoder_name: str, cid: int) -> str:\n",
        "    rn = run_name(model_name, encoder_name)\n",
        "    return os.path.join(\"AITDM\", rn, \"checkpoints\", f\"client_{cid}_best.pt\")\n",
        "\n",
        "\n",
        "def best_json_path(model_name: str, encoder_name: str, cid: int) -> str:\n",
        "    rn = run_name(model_name, encoder_name)\n",
        "    return os.path.join(\"AITDM\", rn, \"checkpoints\", f\"client_{cid}_best.json\")\n",
        "\n",
        "\n",
        "def load_model(model_name: str, encoder_name: str, cid: int):\n",
        "    path = ckpt_path(model_name, encoder_name, cid)\n",
        "    if not os.path.isfile(path):\n",
        "        raise FileNotFoundError(f\"Missing checkpoint: {path}\")\n",
        "    m = build_model(model_name, encoder_name).to(DEVICE)\n",
        "    sd = torch.load(path, map_location=\"cpu\")\n",
        "    m.load_state_dict(sd, strict=True)\n",
        "    m.eval()\n",
        "    return m\n",
        "\n",
        "\n",
        "def load_best_val_dice(model_name: str, encoder_name: str, cid: int) -> float:\n",
        "    p = best_json_path(model_name, encoder_name, cid)\n",
        "    if not os.path.isfile(p):\n",
        "        raise FileNotFoundError(f\"Missing best json: {p}\")\n",
        "    with open(p, \"r\") as f:\n",
        "        j = json.load(f)\n",
        "    return float(j.get(\"val_dice\", 0.0))\n",
        "\n",
        "\n",
        "def get_client_weights(cid: int, cfgs, mode=\"power\", power=2.0, eps=1e-6):\n",
        "    dices = [load_best_val_dice(mn, enc, cid) for (mn, enc) in cfgs]\n",
        "    d = np.array(dices, dtype=np.float32)\n",
        "\n",
        "    if mode == \"linear\":\n",
        "        raw = np.clip(d, 0.0, None)\n",
        "    elif mode == \"power\":\n",
        "        raw = np.power(np.clip(d, 0.0, None), power)\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'linear' or 'power'\")\n",
        "\n",
        "    raw = raw + eps\n",
        "    w = raw / raw.sum()\n",
        "    return w.tolist(), dices\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ensemble_forward_logits(x, models, weights, target_hw=None):\n",
        "    w = np.array(weights, dtype=np.float32)\n",
        "    w = w / (w.sum() + 1e-8)\n",
        "\n",
        "    logits_sum = None\n",
        "    for mi, wi in zip(models, w):\n",
        "        li = mi(x)\n",
        "        if target_hw is not None and li.shape[-2:] != target_hw:\n",
        "            li = F.interpolate(li, size=target_hw, mode=\"bilinear\", align_corners=False)\n",
        "        logits_sum = li * float(wi) if logits_sum is None else logits_sum + li * float(wi)\n",
        "    return logits_sum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_ensemble_on_client(cid: int, threshold=0.5):\n",
        "    val_loader, nva = get_val_loader(cid)\n",
        "    models = [load_model(mn, enc, cid) for (mn, enc) in ENSEMBLE_CFGS]\n",
        "\n",
        "    weights, best_dices = get_client_weights(\n",
        "        cid, ENSEMBLE_CFGS, mode=WEIGHT_MODE, power=WEIGHT_POWER, eps=WEIGHT_EPS\n",
        "    )\n",
        "\n",
        "    tot_loss = tot_d = tot_i = tot_a = 0.0\n",
        "    nb = 0\n",
        "\n",
        "    for batch in val_loader:\n",
        "        x = batch[\"x\"].to(DEVICE)\n",
        "        y = batch[\"y\"].to(DEVICE)\n",
        "\n",
        "        logits = ensemble_forward_logits(x, models=models, weights=weights, target_hw=y.shape[-2:])\n",
        "        loss = float(criterion(logits, y).item())\n",
        "\n",
        "        preds_bin = (torch.sigmoid(logits).cpu().numpy() > threshold).astype(np.uint8)\n",
        "        y_np = (y.cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        d, i, a = calc_metrics(y_np, preds_bin)\n",
        "\n",
        "        tot_loss += loss\n",
        "        tot_d += d\n",
        "        tot_i += i\n",
        "        tot_a += a\n",
        "        nb += 1\n",
        "\n",
        "    nb = max(nb, 1)\n",
        "    return {\n",
        "        \"cid\": int(cid),\n",
        "        \"nva\": int(nva),\n",
        "        \"loss\": tot_loss / nb,\n",
        "        \"dice\": tot_d / nb,\n",
        "        \"iou\": tot_i / nb,\n",
        "        \"acc\": tot_a / nb,\n",
        "        \"weights\": weights,\n",
        "        \"best_dices\": best_dices,\n",
        "    }\n",
        "\n",
        "\n",
        "def log_client_metrics(file_path, r, bd, ww):\n",
        "\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    log_message = (\n",
        "        f\"Client {r['cid']} (n={r['nva']}): \"\n",
        "        f\"loss={r['loss']:.4f} dice={r['dice']:.4f} iou={r['iou']:.4f} acc={r['acc']:.4f}\\n\"\n",
        "        f\"  best_dice={['%.4f' % x for x in bd]} -> weights={['%.3f' % x for x in ww]}\\n\"\n",
        "    )\n",
        "\n",
        "    print(log_message, end='')\n",
        "\n",
        "    with open(file_path, \"a\") as f:\n",
        "        f.write(log_message)\n",
        "\n",
        "def main():\n",
        "    print(f\"[Ensemble-3 | threshold={THRESHOLD} | weight_mode={WEIGHT_MODE} | power={WEIGHT_POWER}]\\n\")\n",
        "    for cid in [0, 1, 2]:\n",
        "        r = eval_ensemble_on_client(cid, threshold=THRESHOLD)\n",
        "        bd = r[\"best_dices\"]\n",
        "        ww = r[\"weights\"]\n",
        "        log_client_metrics(os.path.join('/content/AITDM', f\"client_{cid}\", \"val_metrics_ensemble.txt\"), r, bd, ww)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOw3IDc6rzkl"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/drive/MyDrive/AITDM\n",
        "!cp -rf /content/AITDM /content/drive/MyDrive/AITDM/TOPK_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnePTndar2g2"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZPPMQRF_PEA"
      },
      "outputs": [],
      "source": [
        "!zip -r ./experiments.zip /content/drive/MyDrive/AITDM -x \"*.pt\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6Nw80ekO7R0i",
        "RYfjGgr9E0Su",
        "JPU64UV3E4v9",
        "zeATNHiwE86m",
        "WzRm-EHu8iCx",
        "tXoXxVZ4Lig_"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}